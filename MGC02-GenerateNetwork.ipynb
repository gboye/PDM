{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Génération des réseaux de formes à partir des règles\n",
    "- Gén-1 : génération des formes à partir de l'échantillon lexical\n",
    "- Gén-2 : génération du réseau orienté à partir de Gén-1\n",
    "- Filt-1 : extraction du sous-réseau symétrique\n",
    "- Filt-2 : génération du réseau non-orienté correspondant à Filt-1\n",
    "- Filt-3 : extraction des cliques maximales\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importations\n",
    "- codecs pour les encodages\n",
    "- pandas et numpy pour les calculs sur tableaux\n",
    "- matplotlib pour les graphiques\n",
    "- itertools pour les itérateurs sophistiqués (paires sur liste, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "import codecs\n",
    "import features\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it\n",
    "import pickle\n",
    "import networkx as nx\n",
    "#%pylab inline\n",
    "#pd.options.display.mpl_style = 'default'\n",
    "debug=False\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.html.widgets import FloatProgress\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "def dateheure():\n",
    "    return datetime.datetime.utcnow().strftime('%y%m%d%H%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saut=\"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des matrices de traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features.add_config('bdlexique.ini')\n",
    "fs=features.FeatureSystem('phonemes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choix de l'échantillon et des règles\n",
    "- *sampleFile* est le nom de l'échantillon de départ\n",
    "- *analysisPrefix* est une partie du nom des règles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampleNumber=\"03-N\"\n",
    "sampleType=\"BRASS\"\n",
    "genFormeVotes=True\n",
    "genCliques=True\n",
    "listeFormesOutput=[\"FS\",\"FP\"]\n",
    "genDigraphe=False\n",
    "genGraphe=False\n",
    "#samplePrefix=\"MGC-150916-extend-%s-paradigmes\"%sampleNumber\n",
    "#samplePrefix=\"MGC-160104-%s-VerbesActions-SILVER\"%sampleNumber\n",
    "#samplePrefix=\"MGC-160104-%s-ext3-paradigmes\"%sampleNumber\n",
    "samplePrefix=\"MGC-160104-%s-ext3-160215-derivations-%s\"%(sampleNumber,sampleType)\n",
    "#samplePrefix=\"MGC-160104-%s-ext3-derivations-%s\"%(sampleNumber,sampleType)\n",
    "#samplePrefix=\"MGC-160104-derivation2-%s-SILVER\"%sampleNumber\n",
    "#samplePrefix=\"MGC-160215-DerivesExtraits\"\n",
    "#samplePrefix=\"MGC-160104-%s-basesDerives\"%sampleNumber\n",
    "sampleFile=samplePrefix+\".csv\"\n",
    "#goldFile=\"MGC-160104-01-N-VerbesActions-GOLD.csv\"\n",
    "#goldFile=\"MGC-160104-01-N-Gold.csv\"\n",
    "#analysisPrefix=\"MGC-150916-extend-%s\"%sampleNumber\n",
    "#analysisPrefix=\"MGC-160104-%s-VerbesActions-SILVER\"%sampleNumber\n",
    "#analysisPrefix=\"MGC-160104-%s-ext3-paradigmes\"%sampleNumber\n",
    "#analysisPrefix=\"MGC-160104-%s-ext3-derivations-%s\"%(sampleNumber,sampleType)\n",
    "#analysisPrefix=\"MGC-160104-derivation2-%s-SILVER\"%sampleNumber\n",
    "#analysisPrefix=\"MGC-160215-DerivesExtraits\"\n",
    "analysisPrefix=\"MGC-160104-%s-ext3-160215-derivations-%s\"%(sampleNumber,sampleType)\n",
    "logfile_name=analysisPrefix+samplePrefix+\".log\"\n",
    "logfile = codecs.open(\"2015-Data/\"+logfile_name,mode='w',encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des cases du paradigme"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "casesPrincipales= [\n",
    "        'inf', 'pi1S', 'pi2S', 'pi3S', 'pi1P', 'pi2P', 'pi3P', 'ii1S',\n",
    "        'ii2S', 'ii3S', 'ii1P', 'ii2P', 'ii3P', \n",
    "        'fi1S', 'fi2S', 'fi3S', 'fi1P', 'fi2P',\n",
    "        'fi3P', 'pI2S', 'pI1P', 'pI2P', 'ps1S', 'ps2S', 'ps3S', 'ps1P',\n",
    "        'ps2P', 'ps3P', \n",
    "        'pc1S', 'pc2S', 'pc3S', 'pc1P', 'pc2P', 'pc3P', 'pP',\n",
    "        'ppMS', 'ppMP', 'ppFS', 'ppFP'\n",
    "            ]\n",
    "casesSecondaires= [\n",
    "       'ai1S', 'ai2S', 'ai3S', 'ai1P', 'ai2P', 'ai3P', 'is1S', 'is2S', 'is3S', 'is1P', 'is2P', 'is3P'\n",
    "            ]\n",
    "casesTotales=casesPrincipales+casesSecondaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation du calcul des analogies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul de la différence entre deux formes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def diff(mot1,mot2):\n",
    "    result=[]\n",
    "    diff1=\"\"\n",
    "    diff2=\"\"\n",
    "    same=\"\"\n",
    "    vide=\".\"\n",
    "    lmax=max(len(mot1),len(mot2))\n",
    "    lmin=min(len(mot1),len(mot2))\n",
    "    for index in range(lmax):\n",
    "        if index < lmin:\n",
    "            if mot1[index]!=mot2[index]:\n",
    "                diff1+=mot1[index]\n",
    "                diff2+=mot2[index]\n",
    "                same+=vide\n",
    "            else:\n",
    "                same+=mot1[index]\n",
    "                diff1+=vide\n",
    "                diff2+=vide\n",
    "        elif index < len(mot1):\n",
    "            diff1+=mot1[index]\n",
    "        elif index < len(mot2):\n",
    "            diff2+=mot2[index]\n",
    "    diff1=diff1.lstrip(\".\")\n",
    "    diff2=diff2.lstrip(\".\")\n",
    "#    return (same,diff1,diff2,diff1+\"_\"+diff2)\n",
    "    return (diff1+\"-\"+diff2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accumulation des paires appartenant à un patron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rowDiff(row, patrons):\n",
    "    result=diff(row[0],row[1])\n",
    "    if not result in patrons:\n",
    "        patrons[result]=(formesPatron(),formesPatron())\n",
    "    patrons[result][0].ajouterFormes(row[0])\n",
    "    patrons[result][1].ajouterFormes(row[1])\n",
    "    return (result[0],result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation d'un patron en RegExp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def patron2regexp(morceaux):\n",
    "    result=\"^\"\n",
    "    for morceau in morceaux:\n",
    "        if morceau==\"*\":\n",
    "            result+=\"(.*)\"\n",
    "        elif len(morceau)>1:\n",
    "            result+=\"([\"+morceau+\"])\"\n",
    "        else:\n",
    "            result+=morceau\n",
    "    result+=\"$\"\n",
    "    result=result.replace(\")(\",\"\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Substitution de sortie \n",
    "???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remplacementSortie(sortie):\n",
    "    n=1\n",
    "    nsortie=\"\"\n",
    "    for lettre in sortie:\n",
    "        if lettre==\".\":\n",
    "            nsortie+=\"\\g<%d>\"%n\n",
    "            n+=1\n",
    "        else:\n",
    "            nsortie+=lettre\n",
    "    return nsortie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classe pour la gestion des patrons, des classes et des transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class paireClasses:\n",
    "    def __init__(self,case1,case2):\n",
    "        self.case1=case1\n",
    "        self.case2=case2\n",
    "        self.nom=case1+\"-\"+case2\n",
    "        self.classes1=classesPaire(case1,case2)\n",
    "        self.classes2=classesPaire(case2,case1)\n",
    "\n",
    "    def ajouterPatron(self,n,patron,motif):\n",
    "        if n==1:\n",
    "            self.classes1.ajouterPatron(patron,motif)\n",
    "        elif n==2:\n",
    "            self.classes2.ajouterPatron(patron,motif)\n",
    "        else:\n",
    "            print (\"le numéro de forme n'est pas dans [1,2]\",n,file=logfile)\n",
    "\n",
    "    def ajouterPaire(self,forme1,forme2):\n",
    "        self.classes1.ajouterPaire(forme1,forme2)\n",
    "        self.classes2.ajouterPaire(forme2,forme1)\n",
    "        \n",
    "    def calculerClasses(self):\n",
    "        return(self.classes1,self.classes2)\n",
    "\n",
    "    \n",
    "class classesPaire:\n",
    "    '''\n",
    "    Gestion des patrons, des classes et des transformations\n",
    "    \n",
    "    ajouterPatron : ajoute un patron et son motif associé (MGL)\n",
    "    ajouterPaire : ajoute une paire de formes, calcule la classe de la forme1 et la règle sélectionnée\n",
    "    sortirForme : cacule les formes de sortie correspondant à la forme1 avec leurs coefficients respectifs\n",
    "    '''\n",
    "    def __init__(self,case1,case2):\n",
    "        self.case1=case1\n",
    "        self.case2=case2\n",
    "        self.nom=case1+\"-\"+case2\n",
    "        self.classe={}\n",
    "        self.nbClasse={}\n",
    "        self.patrons={}\n",
    "        self.entree={}\n",
    "        self.sortie={}\n",
    "    \n",
    "    def ajouterPatron(self,patron,motif):\n",
    "        self.patrons[patron]=motif\n",
    "        (entree,sortie)=patron.split(\"-\")\n",
    "        self.entree[patron]=entree.replace(u\".\",u\"(.)\")\n",
    "        self.sortie[patron]=remplacementSortie(sortie)\n",
    "    \n",
    "    def ajouterPaire(self,forme1,forme2):\n",
    "        '''\n",
    "        on calcule la classe de la paire idClasseForme et la règle sélectionnée\n",
    "        on incrémente le compteur de la classe et celui de la règle sélectionnée à l'intérieur de la classe\n",
    "        '''\n",
    "        classeForme=[]\n",
    "        regleForme=\"\"\n",
    "        for patron in self.patrons:\n",
    "            if re.match(self.patrons[patron],forme1):\n",
    "                classeForme.append(patron)\n",
    "                '''\n",
    "                le +\"$\" permet de forcer l'alignement à droite pour les transformations suffixales\n",
    "                '''\n",
    "                if forme2==re.sub(self.entree[patron]+\"$\",self.sortie[patron],forme1):\n",
    "                    regleForme=patron\n",
    "        idClasseForme=\", \".join(classeForme)\n",
    "        if not idClasseForme in self.classe:\n",
    "            self.classe[idClasseForme]={}\n",
    "            self.nbClasse[idClasseForme]=0\n",
    "        if not regleForme in self.classe[idClasseForme]:\n",
    "            self.classe[idClasseForme][regleForme]=0\n",
    "        self.nbClasse[idClasseForme]+=1\n",
    "        self.classe[idClasseForme][regleForme]+=1\n",
    "\n",
    "    def sortirForme(self,forme):\n",
    "        classeForme=[]\n",
    "        sortieForme={}\n",
    "        for patron in self.patrons:\n",
    "            if re.match(self.patrons[patron],forme):\n",
    "                classeForme.append(patron)\n",
    "        if classeForme:\n",
    "            idClasseForme=\", \".join(classeForme)\n",
    "            if idClasseForme in self.nbClasse:\n",
    "                nTotal=self.nbClasse[idClasseForme]\n",
    "                for patron in self.classe[idClasseForme]:\n",
    "                    sortie=re.sub(self.entree[patron]+\"$\",self.sortie[patron],forme)\n",
    "                    sortieForme[sortie]=float(self.classe[idClasseForme][patron])/nTotal\n",
    "            else:\n",
    "                if debug:\n",
    "                    print (forme, file=logfile)\n",
    "                    print (\"pas de classe\",idClasseForme, file=logfile)\n",
    "                    print (\"%.2f par forme de sortie\" % (float(1)/len(classeForme)), file=logfile)\n",
    "                nTotal=len(classeForme)\n",
    "                for patron in classeForme:\n",
    "                    sortie=re.sub(self.entree[patron]+\"$\",self.sortie[patron],forme)\n",
    "                    sortieForme[sortie]=float(1)/nTotal\n",
    "        else:\n",
    "            print (forme, file=logfile) \n",
    "            print (\"pas de patron\", file=logfile)\n",
    "        return sortieForme\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appliquer la formule de calcul des différences entre chaines à chaque ligne\n",
    "\n",
    ">si il y a au moins une ligne\n",
    "\n",
    ">>on applique la différence à la ligne\n",
    "\n",
    ">>on calcule les deux patrons par suppression des points initiaux\n",
    "\n",
    ">>on renvoie le groupement par patrons (1&2)\n",
    "\n",
    ">sinon\n",
    "\n",
    ">>on renvoie le paradigme vide d'origine"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def OLDrapports(paradigme):\n",
    "    (case1,case2,lexeme)= paradigme.columns.values.tolist()\n",
    "    patrons=pairePatrons(case1,case2)\n",
    "    if len(paradigme)>0:\n",
    "#        for index, row in paradigme.iterrows():\n",
    "#            patrons.ajouterFormes(row[0],row[1],diff(row[0],row[1]))\n",
    "        paradigme.apply(lambda x: patrons.ajouterFormes(x[case1],x[case2],diff(x[case1],x[case2])), axis=1)\n",
    "        (regles1,regles2)=patrons.calculerGM()\n",
    "    return patrons.calculerGM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rapports(paradigme):\n",
    "    if len(paradigme.columns.values.tolist())==2:\n",
    "        (case1,lexeme)= paradigme.columns.values.tolist()\n",
    "        case2=case1\n",
    "    else:\n",
    "        (case1,case2,lexeme)= paradigme.columns.values.tolist()\n",
    "    patrons=pairePatrons(case1,case2)\n",
    "    classes=paireClasses(case1,case2)\n",
    "    if len(paradigme)>0:\n",
    "        paradigme.apply(lambda x: patrons.ajouterFormes(x[case1],x[case2],diff(x[case1],x[case2])), axis=1)\n",
    "        (regles1,regles2)=patrons.calculerGM()\n",
    "        for regle in regles1:\n",
    "            classes.ajouterPatron(1,regle,regles1[regle])\n",
    "        for regle in regles2:\n",
    "            classes.ajouterPatron(2,regle,regles2[regle])\n",
    "        paradigme.apply(lambda x: classes.ajouterPaire(x[case1],x[case2]), axis=1)\n",
    "    (classes1,classes2)=classes.calculerClasses()\n",
    "    return (classes1,classes2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dédoubler les lignes avec des surabondances dans *colonne*\n",
    ">identifier une ligne avec surabondance\n",
    "\n",
    ">>ajouter les lignes correspondant à chaque valeur\n",
    "\n",
    ">>ajouter le numéro de la ligne initiale dans les lignes à supprimer\n",
    "\n",
    ">supprimer les lignes avec surabondance\n",
    "\n",
    "NB : il faut préparer le tableau pour avoir une indexation qui permette l'ajout des valeurs individuelles et la suppression des lignes de surabondances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def splitCellMates(df,colonne):\n",
    "    '''\n",
    "    Calcul d'une dataframe sans surabondance par dédoublement des valeurs\n",
    "    '''\n",
    "    test=df.reset_index()\n",
    "    del test[\"index\"]\n",
    "    splitIndexes=[]\n",
    "    for index,ligne in test.iterrows():\n",
    "        if \",\" in ligne[colonne]:\n",
    "            valeurs=set(ligne[colonne].split(\",\"))\n",
    "            nouvelleLigne=ligne\n",
    "            for valeur in valeurs:\n",
    "                nouvelleLigne[colonne]=valeur\n",
    "                test=test.append(nouvelleLigne,ignore_index=True)\n",
    "            splitIndexes.append(index)\n",
    "    if splitIndexes:\n",
    "        test=test.drop(test.index[splitIndexes])\n",
    "    return test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paradigmes=pd.read_csv(\"2015-Data/\"+sampleFile,sep=\";\",encoding=\"utf8\")\n",
    "del paradigmes[u\"Unnamed: 0\"]\n",
    "paradigmes=paradigmes.dropna(axis=1,how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phonologicalMap=analysisPrefix[-2:]\n",
    "if debug: print(phonologicalMap)\n",
    "neutralisationsNORD=(u\"6û\",u\"9ê\")\n",
    "neutralisationsSUD=(u\"e2o\",u\"E9O\")\n",
    "if phonologicalMap==\"-N\":\n",
    "    neutralisations=neutralisationsNORD\n",
    "elif phonologicalMap==\"-S\":\n",
    "    neutralisations=neutralisationsSUD\n",
    "else:\n",
    "    neutralisations=(u\"\",u\"\")\n",
    "    phonologicalMap=(\"-X\")\n",
    "bdlexiqueIn = unicode(u\"èò\"+neutralisations[0])\n",
    "bdlexiqueNum = [ord(char) for char in bdlexiqueIn]\n",
    "neutreOut = unicode(u\"EO\"+neutralisations[1])\n",
    "neutralise = dict(zip(bdlexiqueNum, neutreOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recoder(chaine,table=neutralise):\n",
    "    if type(chaine)==str:\n",
    "        temp=unicode(chaine.decode('utf8')).translate(table)\n",
    "        result=temp.encode('utf8')\n",
    "    elif type(chaine)==unicode:\n",
    "        result=chaine.translate(table)\n",
    "    else:\n",
    "        result=chaine\n",
    "    return result"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "GOLD=pd.read_csv(\"2015-Data/\"+goldFile,sep=\";\",encoding=\"utf8\")\n",
    "del GOLD[u\"Unnamed: 0\"]\n",
    "goldCases=GOLD.columns.tolist()\n",
    "goldCases.remove(u\"lexeme\")\n",
    "for case in goldCases:\n",
    "    GOLD[case]=GOLD[case].apply(lambda x: recoder(x))\n",
    "    \n",
    "paradigmesGOLD=GOLD[paradigmes.columns.values.tolist()]\n",
    "#paradigmesGOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "goldCases=paradigmes.columns.tolist()\n",
    "goldCases.remove(\"lexeme\")\n",
    "#goldCases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sampleCases pour la liste des cases effectivement représentées dans le corpus de départ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampleCases=paradigmes.columns.values.tolist()\n",
    "sampleCases.remove(u\"lexeme\")\n",
    "#sampleCases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49817"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paradigmes.stack().value_counts(dropna=True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"2015-Data/\"+analysisPrefix+'-Regles.pkl', 'rb') as input:\n",
    "    resultatsLecture = pickle.load(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparer les cases analysées avec l'ensemble de toutes les cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analyseCases=list(set([case for (case,autre) in resultatsLecture.keys()]))\n",
    "if sorted(analyseCases)!=sorted(goldCases):\n",
    "    print (\"Attention l'analyse ne comprend pas toutes les cases\")\n",
    "    print (sorted(analyseCases))\n",
    "    print (sorted(goldCases))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class paradigmeDistribution:\n",
    "    '''\n",
    "    Gestion des distributions dans les cases du paradigme\n",
    "    '''\n",
    "\n",
    "    def __init__(self,lexeme):\n",
    "        self.lexeme=lexeme\n",
    "        self.formes={i:{} for i in analyseCases}\n",
    "\n",
    "    def ajouterFormes(self,case,formes,coef=1.0):\n",
    "        for forme in formes:\n",
    "            if not forme in self.formes[case]:\n",
    "                self.formes[case][forme]=0\n",
    "            self.formes[case][forme]+=formes[forme]*coef\n",
    "            \n",
    "    def normaliserDistributions(self,caseListe=analyseCases):\n",
    "        normalesDistributions={i:{} for i in caseListe}\n",
    "        for case in caseListe:\n",
    "            total=0\n",
    "            for element in self.formes[case]:\n",
    "                total+=self.formes[case][element]\n",
    "            for element in self.formes[case]:\n",
    "                normalesDistributions[case][element]=float(self.formes[case][element])/total\n",
    "        return normalesDistributions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generateForms(lexeme):\n",
    "    candidats=paradigmeDistribution(lexeme)\n",
    "    casesSamples=paradigmes[paradigmes[\"lexeme\"]==lexeme].columns[paradigmes[paradigmes[\"lexeme\"]==lexeme].notnull().iloc[0]].tolist()\n",
    "    casesSamples.remove(\"lexeme\")\n",
    "    for caseDepart in casesSamples:\n",
    "        formeDepart=paradigmes[paradigmes[\"lexeme\"]==lexeme][caseDepart].iloc[0]\n",
    "        if debug: print (caseDepart,formeDepart, file=logfile)\n",
    "#        if formeDepart!=\"nan\":\n",
    "        for case in analyseCases:\n",
    "            if debug: print (case, file=logfile)\n",
    "            if not isinstance(resultatsLecture[(caseDepart, case)],str):\n",
    "                if \",\" in formeDepart:\n",
    "                    formesDepart=formeDepart.split(\",\")\n",
    "                    coef=1.0/len(formesDepart)\n",
    "                    for element in formesDepart:\n",
    "                        candidats.ajouterFormes(case,resultatsLecture[(caseDepart, case)].sortirForme(element),coef)\n",
    "                else:\n",
    "                    candidats.ajouterFormes(case,resultatsLecture[(caseDepart, case)].sortirForme(formeDepart))\n",
    "            else: \n",
    "                if debug: print (\"str\", resultatsLecture[(caseDepart, case)], file=logfile)\n",
    "    return candidats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ajouterPoint(lexeme,forme,case,digraphe,graphe):\n",
    "    pointName=\"%s-%s-%s\"%(lexeme,forme,case)\n",
    "#    if not pointName in digraphe.nodes():\n",
    "    tam=case[:2]\n",
    "    if tam==\"in\": tam=\"inf\"\n",
    "    digraphe.add_node(pointName, tam='\"%s\"'%tam)\n",
    "    graphe.add_node(pointName, tam='\"%s\"'%tam)\n",
    "    return pointName\n",
    "\n",
    "def ajouterFleche(pointDepart,pointSortie,coef,digraphe,graphe):\n",
    "    digraphe.add_edge(pointDepart,pointSortie,weight=float(coef))\n",
    "    if digraphe.has_edge(pointSortie,pointDepart):\n",
    "        coefGraphe=float(digraphe.edge[pointSortie][pointDepart][\"weight\"]+coef)/2\n",
    "        graphe.add_edge(pointDepart,pointSortie,weight=coefGraphe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generateParadigms(generation1,genDigraphe=True):\n",
    "    lexeme=generation1.lexeme\n",
    "    distributionInitiale=generation1.normaliserDistributions()\n",
    "    candidats=paradigmeDistribution(lexeme)\n",
    "    digraphe=nx.DiGraph()\n",
    "    graphe=nx.Graph()    \n",
    "    for caseDepart in analyseCases:\n",
    "        for formeDepart in distributionInitiale[caseDepart]:\n",
    "            if formeDepart:\n",
    "                pointDepart=ajouterPoint(lexeme,formeDepart,caseDepart,digraphe,graphe)\n",
    "                coefDepart=distributionInitiale[caseDepart][formeDepart]\n",
    "                if debug: print (caseDepart,formeDepart, file=logfile)\n",
    "                for caseSortie in analyseCases:\n",
    "                    distributionSortieBrute=resultatsLecture[(caseDepart, caseSortie)].sortirForme(formeDepart)\n",
    "                    if distributionSortieBrute:\n",
    "                        if not genDigraphe:\n",
    "#                            print (\"brute\",distributionSortieBrute)\n",
    "                            distributionSortie={f:distributionSortieBrute[f] for f in distributionSortieBrute if f in distributionInitiale[caseSortie]}\n",
    "                        else:\n",
    "                            distributionSortie=distributionSortieBrute\n",
    "#                        print (\"filtre\",distributionSortie)\n",
    "#                        print (distributionInitiale[caseSortie])\n",
    "                        if debug: print (caseSortie,distributionSortie,distributionInitiale[caseDepart], file=logfile)\n",
    "                        candidats.ajouterFormes(caseSortie,distributionSortie,distributionInitiale[caseDepart][formeDepart])\n",
    "                        for formeSortie in distributionSortie:\n",
    "                            pointSortie=ajouterPoint(lexeme,formeSortie,caseSortie,digraphe,graphe)\n",
    "                            coefSortie=distributionSortie[formeSortie]\n",
    "                            ajouterFleche(pointDepart,pointSortie,float(coefDepart*coefSortie),digraphe,graphe)\n",
    "    return (candidats,digraphe,graphe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(lexeme,genDigraphe=True):\n",
    "#    print (lexeme,end=\", \")\n",
    "    generation1=generateForms(lexeme)\n",
    "#    print (\"génération 2\",end=\", \")\n",
    "    (generation2,lexDigraphe,lexGraphe)=generateParadigms(generation1,genDigraphe)\n",
    "    lexCliques=list(nx.algorithms.clique.find_cliques(lexGraphe))\n",
    "#    print (lexCliques)\n",
    "#    print (\"génération 3\")\n",
    "    return (generation2,lexDigraphe,lexGraphe,lexCliques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4642"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paradigmes.dropna(thresh=1)[\"lexeme\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'lexeme',\n",
       " u'ii3P',\n",
       " u'ii3S',\n",
       " u'inf',\n",
       " u'pI2S',\n",
       " u'pi1S',\n",
       " u'pi3P',\n",
       " u'pi3S',\n",
       " u'ppMS',\n",
       " u'FS']"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#paradigmes\n",
    "#analyseCases\n",
    "lexeme=\"absoudre\"\n",
    "paradigmes[paradigmes[\"lexeme\"]==lexeme].columns[paradigmes[paradigmes[\"lexeme\"]==lexeme].notnull().iloc[0]].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45175"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paradigmes.dropna(thresh=1).count().sum()-paradigmes.dropna(thresh=1)[\"lexeme\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculer le score de la clique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cliqueScore(clique,graph):\n",
    "    score=0\n",
    "    for (depart,arrivee) in it.combinations_with_replacement(clique,2):\n",
    "        score+=graph[depart][arrivee][\"weight\"]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trouver tous les liens vers FS-* et FP-*\n",
    "# regrouper par forme \n",
    "# calculer les proportions\n",
    "# renvoyer les proportions par forme\n",
    "# avec le nombre de forme à l'appui\n",
    "def formeScore(forme,graph):\n",
    "    scores={}\n",
    "    scoresNormes={}\n",
    "    for depart in graph.edge:\n",
    "        for arrivee in graph.edge[depart]:\n",
    "            (lexeme, formeArrivee, caseArrivee)=arrivee.split(\"-\")\n",
    "            if caseArrivee==forme:\n",
    "#                print (depart, formeArrivee, graph.edge[depart][arrivee])\n",
    "                if not formeArrivee in scores:\n",
    "                    scores[formeArrivee]=0\n",
    "                scores[formeArrivee]+=graph.edge[depart][arrivee][\"weight\"]\n",
    "    totalArrivee=0\n",
    "    for formeArrivee in scores:\n",
    "        totalArrivee+=scores[formeArrivee]\n",
    "    for formeArrivee in scores:\n",
    "        scoresNormes[formeArrivee]=scores[formeArrivee]/totalArrivee\n",
    "    return (scores,scoresNormes)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération des formes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "basesDerives=pd.read_csv(\"2015-Data/MGC-160104-01-N-basesDerives.csv\",sep=\";\",encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n",
      "CPU times: user 21min 34s, sys: 7.95 s, total: 21min 42s\n",
      "Wall time: 22min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "debug=False\n",
    "#listeTest=[u\"manger\",u\"boire\",u\"dormir\",u\"aller\",u\"neiger\"]\n",
    "#listeTest=paradigmes.dropna(thresh=2)[\"lexeme\"].values.tolist()\n",
    "#listeTest=paradigmes.dropna(thresh=1)[\"lexeme\"].values.tolist()\n",
    "listeTest=basesDerives[\"lexeme\"].tolist()\n",
    "#listeTest=[u\"abasourdir\",u\"évacuer\"]\n",
    "nbVerbes=len(listeTest)\n",
    "print (nbVerbes)\n",
    "globDigraphe=nx.DiGraph()\n",
    "globGraphe=nx.Graph()\n",
    "cliques=[]\n",
    "cliquesScores={}\n",
    "cliquesListes={}\n",
    "numClique=0\n",
    "formesScores={}\n",
    "formesScoresNormes={}\n",
    "progressBar = FloatProgress(min=0, max=nbVerbes)\n",
    "display(progressBar)\n",
    "for i,element in enumerate(listeTest):\n",
    "#    if (i%100)==0: print (i, dateheure()[-4:], int(100*float(i)/nbVerbes), end=\", \")\n",
    "    progressBar.value=i\n",
    "    #print (element)\n",
    "    result=generate(element,genDigraphe)\n",
    "    (generation,lexDigraphe,lexGraphe,lexCliques)= result\n",
    "#    print (generation,lexDigraphe,lexGraphe,lexCliques)\n",
    "    if genFormeVotes:\n",
    "        formesScores[element]={}\n",
    "        formesScoresNormes[element]={}\n",
    "        for formeOutput in listeFormesOutput:\n",
    "            (formesScores[element][formeOutput],formesScoresNormes[element][formeOutput])=formeScore(formeOutput,lexDigraphe)\n",
    "    if genDigraphe:\n",
    "        globDigraphe=nx.union(globDigraphe,lexDigraphe)\n",
    "    if genGraphe:\n",
    "        globGraphe=nx.union(globGraphe,lexGraphe)\n",
    "    cliques.extend(lexCliques)\n",
    "    for clique in lexCliques:\n",
    "        cliquesScores[numClique]=cliqueScore(clique,lexGraphe)\n",
    "        cliquesListes[numClique]=clique\n",
    "        numClique+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if genFormeVotes:\n",
    "    fScores=(formesScores,formesScoresNormes)\n",
    "    with open(\"2015-Data/\"+analysisPrefix+'-Scores.pkl', 'wb') as output:\n",
    "        pickle.dump(fScores, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 52 µs, sys: 36 µs, total: 88 µs\n",
      "Wall time: 93.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "versionStamp=dateheure()\n",
    "if genDigraphe: \n",
    "    nx.write_dot(globDigraphe,u\"2015-Data/digraphe-%s.dot\"%versionStamp)\n",
    "if genGraphe:\n",
    "    nx.write_dot(globGraphe,u\"2015-Data/graphe-%s.dot\"%versionStamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44407\n"
     ]
    }
   ],
   "source": [
    "print (len(cliques))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if genCliques:\n",
    "    infoCliques={\"cliques\":cliques, \"cliquesScores\":cliquesScores, \"cliquesListes\":cliquesListes}\n",
    "    with open(\"2015-Data/\"+analysisPrefix+'-Network.pkl', 'wb') as output:\n",
    "        pickle.dump(infoCliques, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
