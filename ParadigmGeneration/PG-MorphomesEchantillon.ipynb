{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script pour trouver un paradigme morphomique \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "import pandas as pd\n",
    "import pickle, glob,re\n",
    "import itertools as it\n",
    "import networkx as nx\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "debug=False\n",
    "noDiff=True\n",
    "nbFormesPrint=False\n",
    "regroupeTirages=True\n",
    "phonologicalMap=\"-S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dierese={\"j\":\"ij\", \"w\":\"uw\",\"H\":\"yH\",\"i\":\"ij\",\"u\":\"uw\",\"y\":\"yH\"}\n",
    "correctionsGlides={}\n",
    "correctionsHiatus={}\n",
    "preGlideFinal=set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neutralisationsNORD=(u\"6û\",u\"9ê\")\n",
    "neutralisationsSUD=(u\"e2o\",u\"E9O\")\n",
    "if phonologicalMap==\"-N\":\n",
    "    neutralisations=neutralisationsNORD\n",
    "elif phonologicalMap==\"-S\":\n",
    "    neutralisations=neutralisationsSUD\n",
    "else:\n",
    "    neutralisations=(u\"\",u\"\")\n",
    "    phonologicalMap=(\"-X\")\n",
    "bdlexiqueIn = unicode(u\"èò\"+neutralisations[0])\n",
    "bdlexiqueNum = [ord(char) for char in bdlexiqueIn]\n",
    "neutreOut = unicode(u\"EO\"+neutralisations[1])\n",
    "neutralise = dict(zip(bdlexiqueNum, neutreOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recoder(chaine,table=neutralise):\n",
    "    if type(chaine)==str:\n",
    "        temp=unicode(chaine.decode('utf8')).translate(table)\n",
    "        result=temp.encode('utf8')\n",
    "    elif type(chaine)==unicode:\n",
    "        result=chaine.translate(table)\n",
    "    else:\n",
    "        result=chaine\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkFrench(prononciation):\n",
    "    result=recoder(prononciation)\n",
    "    m=re.match(ur\"^.*([^ieEaOouy926êôâ])[jwH]$\",result)\n",
    "    if m:\n",
    "        print \"pb avec un glide final\"\n",
    "    m=re.match(ur\"(.*[ptkbdgfsSvzZ][rl])([jwH])(.*)\",result)\n",
    "    if m:\n",
    "        n=re.search(ur\"[ptkbdgfsSvzZ][rl](wa|Hi|wê)\",result)\n",
    "        if not n:\n",
    "            glide=m.group(2)\n",
    "            result=m.group(1)+dierese[glide]+m.group(3)\n",
    "    m=re.match(ur\"(.*)([iuy])([ieEaOouy].*)\",result)\n",
    "    if m:\n",
    "        glide=m.group(2)\n",
    "        result=m.group(1)+dierese[glide]+m.group(3)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f6zE\n"
     ]
    }
   ],
   "source": [
    "print checkFrench(u\"f6ze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lireLexique(nomLexique):\n",
    "    with open(nomLexique, 'rb') as input:\n",
    "        lexique=pickle.load(input)\n",
    "    return lexique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lexique2Paradigmes(lexique):\n",
    "    return pd.pivot_table(lexique, values='phono', index=['lexeme'], columns=['case'], aggfunc=lambda x: \",\".join(x)).reset_index().reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nomFichierMorphomes=\"/Users/gilles/Github/BoSchal17-Morphology/PG-Morphomes.tex\"\n",
    "listeTirages=glob.glob(\"/Users/gilles/Box Sync/2015-Data/*-Tirage.pkl\")\n",
    "listeVHF=[u\"être\",\"avoir\",\"faire\",\"dire\",\"pouvoir\",\"aller\",\"voir\",\"savoir\",\"vouloir\",\"venir\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coulMF=[\"orange\",\"brown\",\"yellow\",\"lime\",\n",
    "          \"green\",\"teal\",\"lightgray\",\"pink\",\"cyan\",\"magenta\"]\n",
    "coulMT=[\"blue\",\"darkgray\",\"purple\",\"red\",\"olive\",\"violet\"]\n",
    "couleurCase={\n",
    "    \"pi2S\":\"orange\",\"pi3S\":\"orange\",\n",
    "    \"ii1S\":\"brown\",\"ii2S\":\"brown\",\"ii3S\":\"brown\",\"ii3P\":\"brown\",\n",
    "    \"fi1S\":\"yellow\",\"fi2P\":\"yellow\",\n",
    "    \"pc1S\":\"yellow\",\"pc2S\":\"yellow\",\"pc3S\":\"yellow\",\"pc3P\":\"yellow\",\n",
    "    \"fi2S\":\"lime\",\"fi3S\":\"lime\",\n",
    "    \"fi1P\":\"green\",\"fi3P\":\"green\",\n",
    "    \"ps1S\":\"teal\",\"ps2S\":\"teal\",\"ps3S\":\"teal\",\"ps3P\":\"teal\",\n",
    "    \"ai2S\":\"lightgray\",\"ai3S\":\"lightgray\",\"is3S\":\"lightgray\",\n",
    "    \"is1S\":\"pink\",\"is2S\":\"pink\",\"is3P\":\"pink\",\n",
    "    \"ppMS\":\"cyan\",\"ppMP\":\"cyan\",\n",
    "    \"ppFS\":\"magenta\",\"ppFP\":\"magenta\"\n",
    "            }\n",
    "listLimites=[2,8,32,128,512]\n",
    "listLimCoul=[\"red\",\"pink\",\"orange\",\"green\",\"teal\",\"white\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tiragesNom(nom):\n",
    "    result=[tirage for tirage in listeTirages if nom in tirage]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nbFormesEchantillons(nom):\n",
    "    print nom\n",
    "    for tirage in tiragesNom(nom):\n",
    "        sample=lireLexique(tirage)\n",
    "        print sample[sample[\"tir1\"]>0][\"tir1\"].count(),\n",
    "        print sample[sample[\"tir1\"]>0][\"tir1\"].sum(),\n",
    "        print tirage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listeTirages200=tiragesNom(\"200Mo\")\n",
    "listeTirages20=tiragesNom(\"20Mo\")\n",
    "#len(listeTirages200)\n",
    "listeTirages1=tiragesNom(\"1Mo\")\n",
    "listeTirages50k=tiragesNom(\"50Ko\")\n",
    "listeTirages100k=tiragesNom(\"100Ko\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tailleLexique=[]\n",
    "nomLexique0=listeTirages200.pop(0)\n",
    "nomLexique0=listeTirages1.pop(0)\n",
    "lexique=lireLexique(nomLexique0)\n",
    "taille=lexique[lexique[\"tir1\"]>0][\"tir1\"].count()\n",
    "print taille, lexique[lexique[\"tir1\"]>0][\"tir1\"].sum()\n",
    "tailleLexique.append(taille)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findFormNumbers(paradigme):\n",
    "    dictNumbers={}\n",
    "    cases=[c for c in paradigmes.columns.tolist() if c!=\"lexeme\"]\n",
    "    for case in cases:\n",
    "        dictNumbers[case]=paradigme[case].count()\n",
    "    return dictNumbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduceTrad(el,traductions):\n",
    "    if traductions[el]==el:\n",
    "        return el\n",
    "    else:\n",
    "        return reduceTrad(traductions[el],traductions)\n",
    "    \n",
    "def defParadigme(paradigmes):\n",
    "    syncretisms=[]\n",
    "    cases=[c for c in paradigmes.columns.tolist() if c!=\"lexeme\"]\n",
    "    for (c1,c2) in it.combinations(cases, 2):\n",
    "        c1Val=paradigmes[c1].notnull()\n",
    "        c2Val=paradigmes[c2].notnull()\n",
    "        c1Sur=paradigmes[c1].str.contains(\",\")\n",
    "        c2Sur=paradigmes[c2].str.contains(\",\")\n",
    "        l1=len(paradigmes[paradigmes[c1].notnull()])\n",
    "        l2=len(paradigmes[paradigmes[c2].notnull()])\n",
    "        paire=paradigmes[c1Val & c2Val & (paradigmes[c1]!=paradigmes[c2])][[c1,c2]]\n",
    "        lenDiff=len(paire[~paire[c1].str.contains(\",\") & ~paire[c2].str.contains(\",\")])\n",
    "        if lenDiff>0:\n",
    "            if debug:\n",
    "                print u\"%s ≠ %s\"%(c1,c2)\n",
    "                print \"différence\",lenDiff\n",
    "                if lenDiff<12:\n",
    "                    print paire\n",
    "        else:\n",
    "            surAbondant=paire[paire[c1].str.contains(\",\") | paire[c2].str.contains(\",\")]\n",
    "#            print \"--------------------------------\"\n",
    "            if len(surAbondant)==0:\n",
    "#                print u\"%s = %s\"%(c1,c2) \n",
    "                syncretisms.append(u\"%s = %s\"%(c1,c2))\n",
    "            else:\n",
    "                compatible=True\n",
    "                for index,row in surAbondant.iterrows():\n",
    "                    if \",\" in row[c1]:\n",
    "                        if \",\" in row[c2]:\n",
    "                            if row[c1]!=row[c2]:\n",
    "                                compatible=False\n",
    "                        else:\n",
    "                            if not row[c2] in row[c1].split(\",\"):\n",
    "                                compatible=False\n",
    "                    else:\n",
    "                        if not row[c1] in row[c2].split(\",\"):\n",
    "                            compatible=False\n",
    "                if compatible:\n",
    "#                    print u\"%s = %s\"%(c1,c2)\n",
    "                    syncretisms.append(u\"%s = %s\"%(c1,c2))\n",
    "                else:\n",
    "                    print u\"%s ≠ %s\"%(c1,c2)\n",
    "                    print surAbondant\n",
    "\n",
    "    reductionParadigme={c:c for c in cases}\n",
    "    for syncretism in syncretisms:\n",
    "        c1,c2=syncretism.split(\" = \")\n",
    "        removeC=max(c1,c2)\n",
    "        keyC=min(c1,c2)\n",
    "        if removeC in reductionParadigme:\n",
    "            if keyC in reductionParadigme:\n",
    "                key=min(reductionParadigme[keyC],reductionParadigme[removeC])\n",
    "            else:\n",
    "                key=min(keyC,reductionParadigme[removeC])\n",
    "        else:\n",
    "            if keyC in reductionParadigme:\n",
    "                key=reductionParadigme[keyC]\n",
    "            else:\n",
    "                key=keyC\n",
    "        reductionParadigme[removeC]=key\n",
    "        reductionParadigme[keyC]=key\n",
    "\n",
    "    for el in reductionParadigme:\n",
    "        reductionParadigme[el]=reduceTrad(el,reductionParadigme)\n",
    "\n",
    "    paradigmeReduit = {}\n",
    "    for k, v in reductionParadigme.iteritems():\n",
    "        paradigmeReduit[v] = paradigmeReduit.get(v, [])\n",
    "        paradigmeReduit[v].append(k)\n",
    "    print \"syncrétismes\",len(paradigmeReduit), sorted(paradigmeReduit.keys())\n",
    "    print paradigmeReduit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findClique(cliques,remElement=\"node\"):\n",
    "    pNodes=set()\n",
    "\n",
    "    sCliques=sorted(cliques, key=len, reverse=True)\n",
    "\n",
    "    cliqueFound=sorted(sCliques[0])\n",
    "    pNodes=pNodes|set(sCliques[0])\n",
    "\n",
    "    if remElement==\"clique\":\n",
    "        removeCliques=[]\n",
    "        for clique in sCliques:\n",
    "            sClique=set(clique)\n",
    "            if set.intersection(pNodes,sClique):\n",
    "                removeCliques.append(clique)\n",
    "        for clique in removeCliques:\n",
    "            sCliques.remove(clique)\n",
    "    elif remElement==\"node\":\n",
    "        newCliques=[]\n",
    "        for clique in sCliques:\n",
    "            sClique=set(clique)\n",
    "            diffClique=list(sClique-set.intersection(pNodes,sClique))\n",
    "            if diffClique:\n",
    "                newCliques.append(diffClique)               \n",
    "#            print \"sortie\",newCliques\n",
    "        sCliques=sorted(newCliques,key=len,reverse=True)\n",
    "    else:\n",
    "        print \"remElement non prévu\"\n",
    "    return (cliqueFound,sCliques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findPartition(syncretismes):\n",
    "    g=nx.Graph()\n",
    "    for node in list(lexique[lexique[\"tir1\"]>0][\"case\"].unique()):\n",
    "        g.add_node(node)\n",
    "    for syncretisme in syncretismes:\n",
    "        c1,c2=syncretisme.split(\" = \")\n",
    "        g.add_edge(c1,c2)\n",
    "    cliques.extend(list(nx.find_cliques(g)))\n",
    "    sCliques=sorted(cliques, key=len, reverse=True)\n",
    "    foundCliques=[]\n",
    "    while sCliques:\n",
    "        foundClique,sCliques=findClique(sCliques)\n",
    "        foundCliques.append(foundClique)\n",
    "    foundNodes=set(n for l in foundCliques for n in l )\n",
    "    missingNodes=[[n] for n in g.nodes() if not n in foundNodes]\n",
    "    partition=foundCliques+missingNodes\n",
    "    dictPartition={l[0]:l for l in partition}\n",
    "    return dictPartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drawPartition(dictPartition):\n",
    "    g=nx.DiGraph()\n",
    "    g.add_node(\"paradigme\",color=\"red\")\n",
    "    for numMorphome,morphome in enumerate(dictPartition):\n",
    "        g.add_node(\"M%02d\"%numMorphome,color=\"blue\")\n",
    "        g.add_edge(\"paradigme\",\"M%02d\"%numMorphome)\n",
    "        for case in dictPartition[morphome]:\n",
    "            g.add_edge(\"M%02d\"%numMorphome,case)\n",
    "    graphs.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findColours(dictPartition,debug=False):\n",
    "    def assignColour(listMorphome,morphColour):\n",
    "        for m in listMorphome:\n",
    "            if not m in dictColours:\n",
    "                dictColours[m]=morphColour\n",
    "            else:\n",
    "                print \"conflit sur %s entre %s et %s\"%(m,dictColours[m],morphColour)\n",
    "\n",
    "    dictColours={}\n",
    "    iCoul=0\n",
    "    for morphome in dictPartition:\n",
    "        listMorphome=dictPartition[morphome]\n",
    "        lenMorphome=len(listMorphome)\n",
    "        if lenMorphome>1:\n",
    "            if debug: print lenMorphome,listMorphome,\n",
    "            if morphome in couleurCase:\n",
    "                if debug: print couleurCase[morphome]\n",
    "                morphColour=couleurCase[morphome]\n",
    "            else:\n",
    "                noCoul=True\n",
    "                for el in listMorphome:\n",
    "                    if el in couleurCase:\n",
    "                        if debug: print couleurCase[el]\n",
    "                        morphColour=couleurCase[el]\n",
    "                        noCoul=False\n",
    "                        break\n",
    "                if noCoul:\n",
    "                    if debug: print \"autre\",coulMT[iCoul]\n",
    "                    morphColour=coulMT[iCoul]\n",
    "                    iCoul+=1\n",
    "        else:\n",
    "            morphColour=\"white\"\n",
    "        assignColour(listMorphome,morphColour)\n",
    "    return dictColours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeTabular(dictColours,title=\"\",coulLim=False):\n",
    "    tabular=[]\n",
    "    def makeLine6(tenseCode):\n",
    "        line=[]\n",
    "        for person in [per+nb for nb in [\"S\",\"P\"] for per in [\"1\",\"2\",\"3\"]]:\n",
    "            case=tenseCode+person\n",
    "            if case in dictColours:\n",
    "                line.append(r\"\\cellcolor{%s}%s\"%(dictColours[case],case))\n",
    "            else:\n",
    "                line.append(r\"\\cellcolor{%s}%s\"%(\"black\",case))\n",
    "        return r\" & \".join(line)+r\"\\\\\"\n",
    "\n",
    "    def makeLine3(tenseCode):\n",
    "        line=[]\n",
    "        for person in [per+nb for nb in [\"S\",\"P\"] for per in [\"1\",\"2\",\"3\"]]:\n",
    "            if person in [\"2S\",\"1P\",\"2P\"]:\n",
    "                case=tenseCode+person\n",
    "                line.append(r\"\\cellcolor{%s}%s\"%(dictColours[case],case))\n",
    "            else:\n",
    "                line.append(r\"---\")\n",
    "        return r\" & \".join(line)+r\"\\\\\"\n",
    "    \n",
    "    def makeLineNF():\n",
    "        line=[]\n",
    "        for case in [\"inf\",\"pP\",\"ppMS\",\"ppMP\",\"ppFS\",\"ppFP\"]:\n",
    "            line.append(r\"\\cellcolor{%s}%s\"%(dictColours[case],case))\n",
    "        return r\" & \".join(line)+r\"\\\\\"\n",
    "    \n",
    "    def makeLineCoulLim():\n",
    "        line=[]\n",
    "        for numLimite,limite in enumerate(listLimites):\n",
    "            line.append(r\"\\cellcolor{%s}%s\"%(listLimCoul[numLimite],\"$<$\"+str(limite)))\n",
    "        return r\"\\hline\\hline \"+r\" & \".join(line)+r\"\\\\\"\n",
    "        \n",
    "    top=[\n",
    "        r\"\\begin{center}\",\n",
    "        r\"\\begin{tabular}{cccccc}\",\n",
    "        r\"\\hline\"\n",
    "        ]\n",
    "    bottom=[\n",
    "        r\"\\hline\",\n",
    "        r\"\\end{tabular}\\\\\",\n",
    "        title,\n",
    "        r\"\\end{center}\",\n",
    "        r\"\\bigskip\",\n",
    "        r\"\"\n",
    "        ]\n",
    "    tabular.append(\"\\n\".join(top))\n",
    "    for tenseCode in [\"pi\",\"ii\",\"fi\",\"pc\", \"ps\",\"ai\", \"is\"]:\n",
    "        tabular.append(makeLine6(tenseCode))\n",
    "    tabular.append(makeLine3(\"pI\"))\n",
    "    tabular.append(makeLineNF())\n",
    "    if coulLim:\n",
    "        tabular.append(makeLineCoulLim())\n",
    "    tabular.append(\"\\n\".join(bottom))\n",
    "    return \"\\n\".join(tabular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def caseEgalite(c1,c2,debug=False):\n",
    "    c1Val=paradigmes[c1].notnull()\n",
    "    c2Val=paradigmes[c2].notnull()\n",
    "    c1Sur=paradigmes[c1].str.contains(\",\")\n",
    "    c2Sur=paradigmes[c2].str.contains(\",\")\n",
    "    l1=len(paradigmes[paradigmes[c1].notnull()])\n",
    "    l2=len(paradigmes[paradigmes[c2].notnull()])\n",
    "    egalPaire=paradigmes[c1Val & c2Val & (paradigmes[c1]==paradigmes[c2])][[c1,c2]]\n",
    "    diffPaire=paradigmes[c1Val & c2Val & (paradigmes[c1]!=paradigmes[c2])][[c1,c2]]\n",
    "    lenDiff=len(diffPaire[~diffPaire[c1].str.contains(\",\") & ~diffPaire[c2].str.contains(\",\")])\n",
    "    if debug:\n",
    "        print egalPaire\n",
    "        print diffPaire\n",
    "        print lenDiff\n",
    "    if lenDiff>0:\n",
    "        return False\n",
    "        if debug:\n",
    "            print u\"%s ≠ %s\"%(c1,c2)\n",
    "            print \"différence\",lenDiff\n",
    "            if lenDiff<12:\n",
    "                print diffPaire\n",
    "    else:\n",
    "        surAbondant=diffPaire[diffPaire[c1].str.contains(\",\") | diffPaire[c2].str.contains(\",\")]\n",
    "        if len(surAbondant)==0:\n",
    "            if len(egalPaire)>0 or noDiff:\n",
    "                if debug: print u\"%s = %s\"%(c1,c2), len(egalPaire)\n",
    "                return True\n",
    "        else:\n",
    "            compatible=True\n",
    "            egalCount=0\n",
    "            for index,row in surAbondant.iterrows():\n",
    "                if \",\" in row[c1]:\n",
    "                    if \",\" in row[c2]:\n",
    "                        setC1=set(row[c1].split(\",\"))\n",
    "                        setC2=set(row[c2].split(\",\"))\n",
    "                        print setC1&setC2\n",
    "                        if not setC1&setC2:\n",
    "                            compatible=False\n",
    "                            break\n",
    "                        else:\n",
    "                            egalCount+=1\n",
    "                    else:\n",
    "                        if not row[c2] in row[c1].split(\",\"):\n",
    "                            compatible=False\n",
    "                            break\n",
    "                        else:\n",
    "                            egalCount+=1\n",
    "                else:\n",
    "                    if not row[c1] in row[c2].split(\",\"):\n",
    "                        compatible=False\n",
    "                        break\n",
    "                    else:\n",
    "                        egalCount+=1\n",
    "            if compatible:\n",
    "                if debug: print u\"%s = %s\"%(c1,c2), len(egalPaire), egalCount\n",
    "                return True\n",
    "            else:\n",
    "                if debug: print u\"%s ≠ %s\"%(c1,c2)\n",
    "                if debug: print surAbondant\n",
    "                return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def defParadigme(paradigmes,debug=False):\n",
    "    syncretisms=[]\n",
    "\n",
    "    cases=[c for c in paradigmes.columns.tolist() if c!=\"lexeme\"]\n",
    "    if debug: print \"%d cases :\"%len(cases),\", \".join(cases)\n",
    "    for (c1,c2) in it.combinations(cases, 2):\n",
    "        if caseEgalite(c1,c2):\n",
    "            syncretisms.append(u\"%s = %s\"%(c1,c2))\n",
    "    dictPartition=findPartition(syncretisms)\n",
    "    itemizeLines.append(\"%d morphomes\"%len(dictPartition))\n",
    "    for key in sorted(dictPartition):\n",
    "        if debug: print \"%s: %s,\" % (key, dictPartition[key]),\n",
    "    if debug: print\n",
    "    drawPartition(dictPartition)\n",
    "    return(dictPartition)\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def pivotLexique(lexique,debug=False):\n",
    "    paradigmes=pd.pivot_table(lexique[lexique[\"tir1\"]>0], values='phono', index=['lexeme'], columns=['case'], aggfunc=lambda x: \",\".join(x)).reset_index().reindex()\n",
    "    return defParadigme(paradigmes,debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeItemize(itemizeLines):\n",
    "    lines=[]\n",
    "    lines.append(r\"\\begin{itemize}\")\n",
    "    for line in itemizeLines:\n",
    "        lines.append(r\"\\item \"+line)\n",
    "    lines.append(r\"\\end{itemize}\")\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findNumberColour(dictNumbers):\n",
    "    result={}\n",
    "    for case in dictNumbers:\n",
    "        if dictNumbers[case]<listLimites[0]:\n",
    "            result[case]=listLimCoul[0]\n",
    "        elif dictNumbers[case]<listLimites[1]:\n",
    "            result[case]=listLimCoul[1]\n",
    "        elif dictNumbers[case]<listLimites[2]:\n",
    "            result[case]=listLimCoul[2]\n",
    "        elif dictNumbers[case]<listLimites[3]:\n",
    "            result[case]=listLimCoul[3]\n",
    "        elif dictNumbers[case]<listLimites[4]:\n",
    "            result[case]=listLimCoul[4]\n",
    "        else:\n",
    "            result[case]=listLimCoul[5]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regroupeLexique(dictPartition,lexique):\n",
    "    lexiqueRegroupe=lexique.copy()\n",
    "    for p in dictPartition:\n",
    "        lCases=dictPartition[p]\n",
    "        lexiqueRegroupe.loc[lexiqueRegroupe[\"case\"].isin(lCases),\"morphome\"]=\"/\".join(lCases)\n",
    "        lexiqueRegroupe.loc[lexiqueRegroupe[\"case\"].isin(lCases),\"case\"]=p\n",
    "    return lexiqueRegroupe.groupby([\"lexeme\",\"phono\",\"case\",\"morphome\"]).agg({\"freq\":np.sum, \"tir1\":np.sum}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tableauPaires(paradigme):\n",
    "    table=pd.DataFrame(columns=[\"ligne\",\"colonne\",\"nbPaires\"])\n",
    "    refCases=paradigme.columns.tolist()\n",
    "    refCases.remove(\"lexeme\")\n",
    "    for n,paire in enumerate(it.combinations_with_replacement(refCases,2)):\n",
    "        if paire[0] in paradigme.columns and paire[1] in paradigme.columns:\n",
    "            nbPaires=len(paradigme[[paire[0],paire[1]]].dropna())\n",
    "        else:\n",
    "            nbPaires=0\n",
    "        table.loc[2*n]=[paire[0],paire[1],nbPaires]\n",
    "        table.loc[2*n+1]=[paire[1],paire[0],nbPaires]\n",
    "    tableau=table.pivot_table(index=\"ligne\",columns=[\"colonne\"])\n",
    "    return tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graphs=[]\n",
    "latexLines=[]\n",
    "pairesTableaux=[]\n",
    "for nomLexique in sorted(listeTirages100k):\n",
    "    lexique=lireLexique(nomLexique)\n",
    "    lexique[\"phono\"]=lexique[\"phono\"].apply(checkFrench)\n",
    "    lexique1=lexique[lexique[\"tir1\"]>0]\n",
    "    taille=lexique1[\"tir1\"].count()\n",
    "    itemizeLines=[]\n",
    "    latexLines.append(nomLexique.split(\"/\")[-1])\n",
    "    itemizeLines.append(\"%d formes\"%taille)\n",
    "    itemizeLines.append(\"%d tirages\"%lexique1[\"tir1\"].sum())\n",
    "    paradigmes=lexique2Paradigmes(lexique1)\n",
    "    tableauOrigine=tableauPaires(paradigmes)\n",
    "    dictNumbers=findFormNumbers(paradigmes)\n",
    "    dictFormNumbers=findNumberColour(dictNumbers)\n",
    "\n",
    "    syncretisms=[]\n",
    "    cliques=[]\n",
    "\n",
    "    dictPartition=defParadigme(paradigmes)\n",
    "    if regroupeTirages and noDiff:\n",
    "        lexiqueRegroupe=regroupeLexique(dictPartition,lexique1)\n",
    "        paradigmesRegroupe=lexique2Paradigmes(lexiqueRegroupe)\n",
    "        tableauRegroupe=tableauPaires(paradigmesRegroupe)\n",
    "\n",
    "        pairesTableaux.append((tableauOrigine,tableauRegroupe))\n",
    "        nomLexiqueRegroupe=nomLexique.replace(\".pkl\",\"-Morphomes.pkl\")\n",
    "        if nomLexique==nomLexiqueRegroupe:\n",
    "            print u\"pb avec le nom du fichier pour les tirages regroupés\"\n",
    "        else:\n",
    "            with open(nomLexiqueRegroupe,\"wb\") as output:\n",
    "                pickle.dump(lexiqueRegroupe, output, pickle.HIGHEST_PROTOCOL)\n",
    "    dictColours=findColours(dictPartition)\n",
    "    latexLines.append(makeItemize(itemizeLines))\n",
    "    latexLines.append(makeTabular(dictColours,title=\"Morphomes\"))\n",
    "    if nbFormesPrint:\n",
    "        latexLines.append(makeTabular(dictFormNumbers,title=\"Nombre de formes\",coulLim=True))\n",
    "if noDiff:\n",
    "    nomFichierSortie=nomFichierMorphomes.replace(\".tex\",phonologicalMap+\"-%s-NoDiff.tex\"%dt.datetime.now().strftime(\"%y%m%d-%H%M\"))\n",
    "else:\n",
    "    nomFichierSortie=nomFichierMorphomes.replace(\".tex\",phonologicalMap+\"-%s-Diff.tex\"%dt.datetime.now().strftime(\"%y%m%d-%H%M\"))\n",
    "with open(nomFichierSortie,\"w\") as output:\n",
    "    output.write(\"\\n\".join(latexLines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "case     pi2S     pi3S\n",
      "1      abâdOn   abâdOn\n",
      "31     akôpaJ   akôpaJ\n",
      "33      akOrd    akOrd\n",
      "38      akrOS    akrOS\n",
      "49       aSEt     aSEt\n",
      "62       admE     admE\n",
      "72      adrEs    adrEs\n",
      "108        Ed       Ed\n",
      "114        Em       Em\n",
      "116      aZut     aZut\n",
      "124        va       va\n",
      "138      amEn     amEn\n",
      "148      amyz     amyz\n",
      "154      anim     anim\n",
      "171      apEl     apEl\n",
      "176     apOrt    apOrt\n",
      "178      aprâ     aprâ\n",
      "180     aprOS    aprOS\n",
      "183     apruv    apruv\n",
      "184    aprEsi   aprEsi\n",
      "196      arâZ     arâZ\n",
      "198      ariv     ariv\n",
      "201     arôdi    arôdi\n",
      "203      arEt     arEt\n",
      "236       atê      atê\n",
      "238       atâ      atâ\n",
      "256      avâs     avâs\n",
      "261     avili    avili\n",
      "264         a        a\n",
      "276       bEJ      bEJ\n",
      "...       ...      ...\n",
      "2807      tuS      tuS\n",
      "2813     turn     turn\n",
      "2821     trai     trai\n",
      "2823     trEt     trEt\n",
      "2841   travaj   travaj\n",
      "2843     trEn     trEn\n",
      "2844    trâbl    trâbl\n",
      "2860     trôp     trôp\n",
      "2868     truv     truv\n",
      "2876       ty       ty\n",
      "2887  tElEfOn  tElEfOn\n",
      "2898   ytiliz   ytiliz\n",
      "2906       vO       vO\n",
      "2916       vâ       vâ\n",
      "2918      vjê      vjê\n",
      "2931      viz      viz\n",
      "2937       vi       vi\n",
      "2941      vwa      vwa\n",
      "2945      vOl      vOl\n",
      "2951       v9       v9\n",
      "3000     Ekut     Ekut\n",
      "3002    Ekraz    Ekraz\n",
      "3004     Ekri     Ekri\n",
      "3025     ElEv     ElEv\n",
      "3043    EnErv    EnErv\n",
      "3065    EpHiz    EpHiz\n",
      "3078      Etâ      Etâ\n",
      "3085     EtOn     EtOn\n",
      "3103     Evit     Evit\n",
      "3106        E        E\n",
      "\n",
      "[302 rows x 2 columns]\n",
      "case  pi2S       pi3S\n",
      "213   asjE  asjE,aswa\n",
      "0\n",
      "pi2S = pi3S 302 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caseEgalite(\"pi2S\",\"pi3S\",debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for nEchant,(tableau1,tableau2) in enumerate(pairesTableaux):\n",
    "    tableau1.to_csv(nomLexique.replace(\".pkl\",\"%d-Separe.csv\"%nEchant),sep=\";\",encoding=\"utf8\")\n",
    "    tableau2.to_csv(nomLexique.replace(\".pkl\",\"%d-Groupe.csv\"%nEchant),sep=\";\",encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "try:\n",
    "    import pygraphviz\n",
    "    from networkx.drawing.nx_agraph import write_dot\n",
    "    print(\"using package pygraphviz\")\n",
    "except ImportError:\n",
    "    try:\n",
    "        import pydotplus\n",
    "        from networkx.drawing.nx_pydot import write_dot\n",
    "        print(\"using package pydotplus\")\n",
    "    except ImportError:\n",
    "        print()\n",
    "        print(\"Both pygraphviz and pydotplus were not found \")\n",
    "        print(\"see http://networkx.github.io/documentation\"\n",
    "              \"/latest/reference/drawing.html for info\")\n",
    "        print()\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "G=graphs[0]\n",
    "#pos = \n",
    "#nx.draw(G,pos=nx.layout.fruchterman_reingold_layout(G,scale=20))\n",
    "for numG,G in enumerate(graphs):\n",
    "    write_dot(G,\"test%02d.dot\"%numG)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "pdLexiqueRegroupe=regroupeLexique(dictPartition,lexique1)\n",
    "pdLexiqueRegroupe\n",
    "pdParadigmeRegroupe=pd.pivot_table(pdLexiqueRegroupe, values='phono', index=['lexeme'], columns=['case'], aggfunc=lambda x: \",\".join(x))\n",
    "pdParadigmeRegroupe.to_dict(orient=\"index\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pdLexiqueRegroupe[pdLexiqueRegroupe[\"lexeme\"]==u\"abaisser\"][[\"phono\",\"case\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
