{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Générer les paradigmes morphomiques \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "import pandas as pd\n",
    "import pickle, glob,re\n",
    "import itertools as it\n",
    "import networkx as nx\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "debug=False\n",
    "noDiff=True\n",
    "nbFormesPrint=False\n",
    "regroupeTirages=True\n",
    "phonologicalMap=\"-S\"\n",
    "cat=\"A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dierese={\"j\":\"ij\", \"w\":\"uw\",\"H\":\"yH\",\"i\":\"ij\",\"u\":\"uw\",\"y\":\"yH\"}\n",
    "correctionsGlides={}\n",
    "correctionsHiatus={}\n",
    "preGlideFinal=set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neutralisationsNORD=(u\"6û\",u\"9ê\")\n",
    "neutralisationsSUD=(u\"e2o\",u\"E9O\")\n",
    "if phonologicalMap==\"-N\":\n",
    "    neutralisations=neutralisationsNORD\n",
    "elif phonologicalMap==\"-S\":\n",
    "    neutralisations=neutralisationsSUD\n",
    "else:\n",
    "    neutralisations=(u\"\",u\"\")\n",
    "    phonologicalMap=(\"-X\")\n",
    "bdlexiqueIn = unicode(u\"èò\"+neutralisations[0])\n",
    "bdlexiqueNum = [ord(char) for char in bdlexiqueIn]\n",
    "neutreOut = unicode(u\"EO\"+neutralisations[1])\n",
    "neutralise = dict(zip(bdlexiqueNum, neutreOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recoder(chaine,table=neutralise):\n",
    "    if type(chaine)==str:\n",
    "        temp=unicode(chaine.decode('utf8')).translate(table)\n",
    "        result=temp.encode('utf8')\n",
    "    elif type(chaine)==unicode:\n",
    "        result=chaine.translate(table)\n",
    "    else:\n",
    "        result=chaine\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkFrench(prononciation):\n",
    "    result=recoder(prononciation)\n",
    "    m=re.match(ur\"^.*([^ieEaOouy926êôâ])[jwH]$\",result)\n",
    "    if m:\n",
    "        print \"pb avec un glide final\"\n",
    "    m=re.match(ur\"(.*[ptkbdgfsSvzZ][rl])([jwH])(.*)\",result)\n",
    "    if m:\n",
    "        n=re.search(ur\"[ptkbdgfsSvzZ][rl](wa|Hi|wê)\",result)\n",
    "        if not n:\n",
    "            glide=m.group(2)\n",
    "            result=m.group(1)+dierese[glide]+m.group(3)\n",
    "    m=re.match(ur\"(.*)([iuy])([ieEaOouy].*)\",result)\n",
    "    if m:\n",
    "        glide=m.group(2)\n",
    "        result=m.group(1)+dierese[glide]+m.group(3)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f6zE\n"
     ]
    }
   ],
   "source": [
    "print checkFrench(u\"f6ze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lireLexique(nomLexique):\n",
    "    with open(nomLexique, 'rb') as input:\n",
    "        lexique=pickle.load(input)\n",
    "    return lexique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lexique2Paradigmes(lexique):\n",
    "    return pd.pivot_table(lexique, values='phono', index=['lexeme'], columns=['case'], aggfunc=lambda x: \",\".join(x)).reset_index().reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nomFichierMorphomes=\"/Users/gilles/Box Sync/2015-Data/DerivationParadigmes/PG-Morphomes.tex\"\n",
    "listeTirages=glob.glob(\"/Users/gilles/Box Sync/2015-Data/DerivationParadigmes/Longitudinal*.pkl\")\n",
    "listeVHF=[u\"être\",\"avoir\",\"faire\",\"dire\",\"pouvoir\",\"aller\",\"voir\",\"savoir\",\"vouloir\",\"venir\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coulMF=[\"orange\",\"brown\",\"yellow\",\"lime\",\n",
    "          \"green\",\"teal\",\"lightgray\",\"pink\",\"cyan\",\"magenta\"]\n",
    "coulMT=[\"blue\",\"darkgray\",\"purple\",\"red\",\"olive\",\"violet\"]\n",
    "couleurCase={\n",
    "    \"pi2S\":\"orange\",\"pi3S\":\"orange\",\n",
    "    \"ii1S\":\"brown\",\"ii2S\":\"brown\",\"ii3S\":\"brown\",\"ii3P\":\"brown\",\n",
    "    \"fi1S\":\"yellow\",\"fi2P\":\"yellow\",\n",
    "    \"pc1S\":\"yellow\",\"pc2S\":\"yellow\",\"pc3S\":\"yellow\",\"pc3P\":\"yellow\",\n",
    "    \"fi2S\":\"lime\",\"fi3S\":\"lime\",\n",
    "    \"fi1P\":\"green\",\"fi3P\":\"green\",\n",
    "    \"ps1S\":\"teal\",\"ps2S\":\"teal\",\"ps3S\":\"teal\",\"ps3P\":\"teal\",\n",
    "    \"ai2S\":\"lightgray\",\"ai3S\":\"lightgray\",\"is3S\":\"lightgray\",\n",
    "    \"is1S\":\"pink\",\"is2S\":\"pink\",\"is3P\":\"pink\",\n",
    "    \"ppMS\":\"cyan\",\"ppMP\":\"cyan\",\n",
    "    \"ppFS\":\"magenta\",\"ppFP\":\"magenta\"\n",
    "            }\n",
    "listLimites=[2,8,32,128,512]\n",
    "listLimCoul=[\"red\",\"pink\",\"orange\",\"green\",\"teal\",\"white\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nomFichierMorphomes=\"/Users/gilles/Box Sync/2015-Data/PG-Adjectives-Morphomes.tex\"\n",
    "listeTirages=glob.glob(\"/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal*.pkl\")\n",
    "listeVHF=[u\"être\",\"avoir\",\"faire\",\"dire\",\"pouvoir\",\"aller\",\"voir\",\"savoir\",\"vouloir\",\"venir\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coulMF=[\"orange\",\"brown\",\"yellow\",\"lime\",\n",
    "          \"green\",\"teal\",\"lightgray\",\"pink\",\"cyan\",\"magenta\"]\n",
    "coulMT=[\"blue\",\"darkgray\",\"purple\",\"red\",\"olive\",\"violet\"]\n",
    "couleurCase={\n",
    "    \"ms\":\"orange\",\"mp\":\"yellow\",\n",
    "    \"fs\":\"green\",\"fp\":\"green\"\n",
    "            }\n",
    "listLimites=[2,8,32,128,512]\n",
    "listLimCoul=[\"red\",\"pink\",\"orange\",\"green\",\"teal\",\"white\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tiragesNom(nom):\n",
    "    result=[tirage for tirage in listeTirages if nom in tirage]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nbFormesEchantillons(nom):\n",
    "    print nom\n",
    "    for tirage in tiragesNom(nom):\n",
    "        sample=lireLexique(tirage)\n",
    "        print sample[sample[\"tir1\"]>0][\"tir1\"].count(),\n",
    "        print sample[sample[\"tir1\"]>0][\"tir1\"].sum(),\n",
    "        print tirage"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "listeTirages200=tiragesNom(\"200Mo\")\n",
    "listeTirages20=tiragesNom(\"20Mo\")\n",
    "#len(listeTirages200)\n",
    "listeTirages1=tiragesNom(\"1Mo\")\n",
    "listeTirages50k=tiragesNom(\"50Ko\")\n",
    "listeTirages100k=tiragesNom(\"100Ko\")\n",
    "listeTirages20000k=tiragesNom(\"20000Ko\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "listeTirages20"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "listeAdHoc=[listeTirages100k[-1],listeTirages1[0],listeTirages20[0],listeTirages200[0]]\n",
    "listeAdHoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findFormNumbers(paradigme):\n",
    "    dictNumbers={}\n",
    "    cases=[c for c in paradigmes.columns.tolist() if c!=\"lexeme\"]\n",
    "    for case in cases:\n",
    "        dictNumbers[case]=paradigme[case].count()\n",
    "    return dictNumbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reduceTrad(el,traductions):\n",
    "    if traductions[el]==el:\n",
    "        return el\n",
    "    else:\n",
    "        return reduceTrad(traductions[el],traductions)\n",
    "    \n",
    "def defParadigme(paradigmes):\n",
    "    syncretisms=[]\n",
    "    cases=[c for c in paradigmes.columns.tolist() if c!=\"lexeme\"]\n",
    "    for (c1,c2) in it.combinations(cases, 2):\n",
    "        c1Val=paradigmes[c1].notnull()\n",
    "        c2Val=paradigmes[c2].notnull()\n",
    "        c1Sur=paradigmes[c1].str.contains(\",\")\n",
    "        c2Sur=paradigmes[c2].str.contains(\",\")\n",
    "        l1=len(paradigmes[paradigmes[c1].notnull()])\n",
    "        l2=len(paradigmes[paradigmes[c2].notnull()])\n",
    "        paire=paradigmes[c1Val & c2Val & (paradigmes[c1]!=paradigmes[c2])][[c1,c2]]\n",
    "        lenDiff=len(paire[~paire[c1].str.contains(\",\") & ~paire[c2].str.contains(\",\")])\n",
    "        if lenDiff>0:\n",
    "            if debug:\n",
    "                print u\"%s ≠ %s\"%(c1,c2)\n",
    "                print \"différence\",lenDiff\n",
    "                if lenDiff<12:\n",
    "                    print paire\n",
    "        else:\n",
    "            surAbondant=paire[paire[c1].str.contains(\",\") | paire[c2].str.contains(\",\")]\n",
    "#            print \"--------------------------------\"\n",
    "            if len(surAbondant)==0:\n",
    "#                print u\"%s = %s\"%(c1,c2) \n",
    "                syncretisms.append(u\"%s = %s\"%(c1,c2))\n",
    "            else:\n",
    "                compatible=True\n",
    "                for index,row in surAbondant.iterrows():\n",
    "                    if \",\" in row[c1]:\n",
    "                        if \",\" in row[c2]:\n",
    "                            if row[c1]!=row[c2]:\n",
    "                                compatible=False\n",
    "                        else:\n",
    "                            if not row[c2] in row[c1].split(\",\"):\n",
    "                                compatible=False\n",
    "                    else:\n",
    "                        if not row[c1] in row[c2].split(\",\"):\n",
    "                            compatible=False\n",
    "                if compatible:\n",
    "#                    print u\"%s = %s\"%(c1,c2)\n",
    "                    syncretisms.append(u\"%s = %s\"%(c1,c2))\n",
    "                else:\n",
    "                    print u\"%s ≠ %s\"%(c1,c2)\n",
    "                    print surAbondant\n",
    "\n",
    "    reductionParadigme={c:c for c in cases}\n",
    "    for syncretism in syncretisms:\n",
    "        c1,c2=syncretism.split(\" = \")\n",
    "        removeC=max(c1,c2)\n",
    "        keyC=min(c1,c2)\n",
    "        if removeC in reductionParadigme:\n",
    "            if keyC in reductionParadigme:\n",
    "                key=min(reductionParadigme[keyC],reductionParadigme[removeC])\n",
    "            else:\n",
    "                key=min(keyC,reductionParadigme[removeC])\n",
    "        else:\n",
    "            if keyC in reductionParadigme:\n",
    "                key=reductionParadigme[keyC]\n",
    "            else:\n",
    "                key=keyC\n",
    "        reductionParadigme[removeC]=key\n",
    "        reductionParadigme[keyC]=key\n",
    "\n",
    "    for el in reductionParadigme:\n",
    "        reductionParadigme[el]=reduceTrad(el,reductionParadigme)\n",
    "\n",
    "    paradigmeReduit = {}\n",
    "    for k, v in reductionParadigme.iteritems():\n",
    "        paradigmeReduit[v] = paradigmeReduit.get(v, [])\n",
    "        paradigmeReduit[v].append(k)\n",
    "    print \"syncrétismes\",len(paradigmeReduit), sorted(paradigmeReduit.keys())\n",
    "    print paradigmeReduit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findClique(cliques,remElement=\"node\"):\n",
    "    pNodes=set()\n",
    "\n",
    "    sCliques=sorted(cliques, key=len, reverse=True)\n",
    "\n",
    "    cliqueFound=sorted(sCliques[0])\n",
    "    pNodes=pNodes|set(sCliques[0])\n",
    "\n",
    "    if remElement==\"clique\":\n",
    "        removeCliques=[]\n",
    "        for clique in sCliques:\n",
    "            sClique=set(clique)\n",
    "            if set.intersection(pNodes,sClique):\n",
    "                removeCliques.append(clique)\n",
    "        for clique in removeCliques:\n",
    "            sCliques.remove(clique)\n",
    "    elif remElement==\"node\":\n",
    "        newCliques=[]\n",
    "        for clique in sCliques:\n",
    "            sClique=set(clique)\n",
    "            diffClique=list(sClique-set.intersection(pNodes,sClique))\n",
    "            if diffClique:\n",
    "                newCliques.append(diffClique)               \n",
    "#            print \"sortie\",newCliques\n",
    "        sCliques=sorted(newCliques,key=len,reverse=True)\n",
    "    else:\n",
    "        print \"remElement non prévu\"\n",
    "    return (cliqueFound,sCliques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findPartition(syncretismes):\n",
    "    g=nx.Graph()\n",
    "    for node in list(lexique[lexique[\"tir1\"]>0][\"case\"].unique()):\n",
    "        g.add_node(node)\n",
    "    for syncretisme in syncretismes:\n",
    "        c1,c2=syncretisme.split(\" = \")\n",
    "        g.add_edge(c1,c2)\n",
    "    cliques.extend(list(nx.find_cliques(g)))\n",
    "    sCliques=sorted(cliques, key=len, reverse=True)\n",
    "    foundCliques=[]\n",
    "    while sCliques:\n",
    "        foundClique,sCliques=findClique(sCliques)\n",
    "        foundCliques.append(foundClique)\n",
    "    foundNodes=set(n for l in foundCliques for n in l )\n",
    "    missingNodes=[[n] for n in g.nodes() if not n in foundNodes]\n",
    "    partition=foundCliques+missingNodes\n",
    "    dictPartition={l[0]:l for l in partition}\n",
    "    return dictPartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drawPartition(dictPartition):\n",
    "    g=nx.DiGraph()\n",
    "    g.add_node(\"paradigme\",color=\"red\")\n",
    "    for numMorphome,morphome in enumerate(dictPartition):\n",
    "        g.add_node(\"M%02d\"%numMorphome,color=\"blue\")\n",
    "        g.add_edge(\"paradigme\",\"M%02d\"%numMorphome)\n",
    "        for case in dictPartition[morphome]:\n",
    "            g.add_edge(\"M%02d\"%numMorphome,case)\n",
    "    graphs.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findColours(dictPartition,debug=False):\n",
    "    def assignColour(listMorphome,morphColour):\n",
    "        for m in listMorphome:\n",
    "            if not m in dictColours:\n",
    "                dictColours[m]=morphColour\n",
    "            else:\n",
    "                print \"conflit sur %s entre %s et %s\"%(m,dictColours[m],morphColour)\n",
    "\n",
    "    dictColours={}\n",
    "    iCoul=0\n",
    "    for morphome in dictPartition:\n",
    "        listMorphome=dictPartition[morphome]\n",
    "        lenMorphome=len(listMorphome)\n",
    "        if lenMorphome>1:\n",
    "            if debug: print lenMorphome,listMorphome,\n",
    "            if morphome in couleurCase:\n",
    "                if debug: print couleurCase[morphome]\n",
    "                morphColour=couleurCase[morphome]\n",
    "            else:\n",
    "                noCoul=True\n",
    "                for el in listMorphome:\n",
    "                    if el in couleurCase:\n",
    "                        if debug: print couleurCase[el]\n",
    "                        morphColour=couleurCase[el]\n",
    "                        noCoul=False\n",
    "                        break\n",
    "                if noCoul:\n",
    "                    if debug: print \"autre\",coulMT[iCoul]\n",
    "                    morphColour=coulMT[iCoul]\n",
    "                    iCoul+=1\n",
    "        else:\n",
    "            morphColour=\"white\"\n",
    "        assignColour(listMorphome,morphColour)\n",
    "    return dictColours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeTabular(dictColours,title=\"\",coulLim=False, cat=\"V\"):\n",
    "    tabular=[]\n",
    "    def makeLine6(tenseCode):\n",
    "        line=[]\n",
    "        for person in [per+nb for nb in [\"S\",\"P\"] for per in [\"1\",\"2\",\"3\"]]:\n",
    "            case=tenseCode+person\n",
    "            if case in dictColours:\n",
    "                line.append(r\"\\cellcolor{%s}%s\"%(dictColours[case],case))\n",
    "            else:\n",
    "                line.append(r\"\\cellcolor{%s}%s\"%(\"black\",case))\n",
    "        return r\" & \".join(line)+r\"\\\\\"\n",
    "\n",
    "    def makeLine3(tenseCode):\n",
    "        line=[]\n",
    "        for person in [per+nb for nb in [\"S\",\"P\"] for per in [\"1\",\"2\",\"3\"]]:\n",
    "            if person in [\"2S\",\"1P\",\"2P\"]:\n",
    "                case=tenseCode+person\n",
    "                if case in dictColours:\n",
    "                    line.append(r\"\\cellcolor{%s}%s\"%(dictColours[case],case))\n",
    "                else:\n",
    "                    line.append(r\"\\cellcolor{%s}%s\"%(\"black\",case))\n",
    "#                line.append(r\"\\cellcolor{%s}%s\"%(dictColours[case],case))\n",
    "            else:\n",
    "                line.append(r\"---\")\n",
    "        return r\" & \".join(line)+r\"\\\\\"\n",
    "    \n",
    "    def makeLineNF():\n",
    "        line=[]\n",
    "        for case in [\"inf\",\"pP\",\"ppMS\",\"ppMP\",\"ppFS\",\"ppFP\"]:\n",
    "            if case in dictColours:\n",
    "                line.append(r\"\\cellcolor{%s}%s\"%(dictColours[case],case))\n",
    "            else:\n",
    "                line.append(r\"\\cellcolor{%s}%s\"%(\"black\",case))\n",
    "#            line.append(r\"\\cellcolor{%s}%s\"%(dictColours[case],case))\n",
    "        return r\" & \".join(line)+r\"\\\\\"\n",
    "\n",
    "    def makeLineMF(nombre):\n",
    "        line=[]\n",
    "        for genre in \"mf\":\n",
    "            case=genre+nombre\n",
    "            if case in dictColours:\n",
    "                line.append(r\"\\cellcolor{%s}%s\"%(dictColours[case],case))\n",
    "            else:\n",
    "                line.append(r\"\\cellcolor{%s}%s\"%(\"black\",case))\n",
    "        return r\" & \".join(line)+r\"\\\\\"\n",
    "    \n",
    "    def makeLineCoulLim():\n",
    "        line=[]\n",
    "        for numLimite,limite in enumerate(listLimites):\n",
    "            line.append(r\"\\cellcolor{%s}%s\"%(listLimCoul[numLimite],\"$<$\"+str(limite)))\n",
    "        return r\"\\hline\\hline \"+r\" & \".join(line)+r\"\\\\\"\n",
    "        \n",
    "    if cat==\"V\":\n",
    "        top=[\n",
    "            r\"\\begin{center}\",\n",
    "            r\"\\begin{tabular}{cccccc}\",\n",
    "            r\"\\hline\"\n",
    "            ]\n",
    "        bottom=[\n",
    "            r\"\\hline\",\n",
    "            r\"\\end{tabular}\\\\\",\n",
    "            title,\n",
    "            r\"\\end{center}\",\n",
    "            r\"\\bigskip\",\n",
    "            r\"\"\n",
    "            ]\n",
    "        tabular.append(\"\\n\".join(top))\n",
    "        for tenseCode in [\"pi\",\"ii\",\"fi\",\"pc\", \"ps\",\"ai\", \"is\"]:\n",
    "            tabular.append(makeLine6(tenseCode))\n",
    "        tabular.append(makeLine3(\"pI\"))\n",
    "        tabular.append(makeLineNF())\n",
    "    elif cat==\"A\":\n",
    "        top=[\n",
    "            r\"\\begin{center}\",\n",
    "            r\"\\begin{tabular}{cc}\",\n",
    "            r\"\\hline\"\n",
    "            ]\n",
    "        bottom=[\n",
    "            r\"\\hline\",\n",
    "            r\"\\end{tabular}\\\\\",\n",
    "            title,\n",
    "            r\"\\end{center}\",\n",
    "            r\"\\bigskip\",\n",
    "            r\"\"\n",
    "            ]\n",
    "        tabular.append(\"\\n\".join(top))\n",
    "        for number in \"sp\":\n",
    "            tabular.append(makeLineMF(number))\n",
    "    if coulLim:\n",
    "        tabular.append(makeLineCoulLim())\n",
    "    tabular.append(\"\\n\".join(bottom))\n",
    "    return \"\\n\".join(tabular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def caseEgalite(c1,c2,debug=False):\n",
    "    c1Val=paradigmes[c1].notnull()\n",
    "    c2Val=paradigmes[c2].notnull()\n",
    "    c1Sur=paradigmes[c1].str.contains(\",\")\n",
    "    c2Sur=paradigmes[c2].str.contains(\",\")\n",
    "    l1=len(paradigmes[paradigmes[c1].notnull()])\n",
    "    l2=len(paradigmes[paradigmes[c2].notnull()])\n",
    "    egalPaire=paradigmes[c1Val & c2Val & (paradigmes[c1]==paradigmes[c2])][[c1,c2]]\n",
    "    diffPaire=paradigmes[c1Val & c2Val & (paradigmes[c1]!=paradigmes[c2])][[c1,c2]]\n",
    "    lenDiff=len(diffPaire[~diffPaire[c1].str.contains(\",\") & ~diffPaire[c2].str.contains(\",\")])\n",
    "    if debug:\n",
    "        print egalPaire\n",
    "        print diffPaire\n",
    "        print lenDiff\n",
    "    if lenDiff>0:\n",
    "        return False\n",
    "        if debug:\n",
    "            print u\"%s ≠ %s\"%(c1,c2)\n",
    "            print \"différence\",lenDiff\n",
    "            if lenDiff<12:\n",
    "                print diffPaire\n",
    "    else:\n",
    "        surAbondant=diffPaire[diffPaire[c1].str.contains(\",\") | diffPaire[c2].str.contains(\",\")]\n",
    "        if len(surAbondant)==0:\n",
    "            if len(egalPaire)>0 or noDiff:\n",
    "                if debug: print u\"%s = %s\"%(c1,c2), len(egalPaire)\n",
    "                return True\n",
    "        else:\n",
    "            compatible=True\n",
    "            egalCount=0\n",
    "            for index,row in surAbondant.iterrows():\n",
    "                if \",\" in row[c1]:\n",
    "                    if \",\" in row[c2]:\n",
    "                        setC1=set(row[c1].split(\",\"))\n",
    "                        setC2=set(row[c2].split(\",\"))\n",
    "                        print setC1&setC2\n",
    "                        if not setC1&setC2:\n",
    "                            compatible=False\n",
    "                            break\n",
    "                        else:\n",
    "                            egalCount+=1\n",
    "                    else:\n",
    "                        if not row[c2] in row[c1].split(\",\"):\n",
    "                            compatible=False\n",
    "                            break\n",
    "                        else:\n",
    "                            egalCount+=1\n",
    "                else:\n",
    "                    if not row[c1] in row[c2].split(\",\"):\n",
    "                        compatible=False\n",
    "                        break\n",
    "                    else:\n",
    "                        egalCount+=1\n",
    "            if compatible:\n",
    "                if debug: print u\"%s = %s\"%(c1,c2), len(egalPaire), egalCount\n",
    "                return True\n",
    "            else:\n",
    "                if debug: print u\"%s ≠ %s\"%(c1,c2)\n",
    "                if debug: print surAbondant\n",
    "                return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def defParadigme(paradigmes,debug=False):\n",
    "    syncretisms=[]\n",
    "\n",
    "    cases=[c for c in paradigmes.columns.tolist() if c!=\"lexeme\"]\n",
    "    if debug: print \"%d cases :\"%len(cases),\", \".join(cases)\n",
    "    for (c1,c2) in it.combinations(cases, 2):\n",
    "        if caseEgalite(c1,c2):\n",
    "            syncretisms.append(u\"%s = %s\"%(c1,c2))\n",
    "    dictPartition=findPartition(syncretisms)\n",
    "    itemizeLines.append(\"%d morphomes\"%len(dictPartition))\n",
    "    for key in sorted(dictPartition):\n",
    "        if debug: print \"%s: %s,\" % (key, dictPartition[key]),\n",
    "    if debug: print\n",
    "    drawPartition(dictPartition)\n",
    "    return(dictPartition)\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def pivotLexique(lexique,debug=False):\n",
    "    paradigmes=pd.pivot_table(lexique[lexique[\"tir1\"]>0], values='phono', index=['lexeme'], columns=['case'], aggfunc=lambda x: \",\".join(x)).reset_index().reindex()\n",
    "    return defParadigme(paradigmes,debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeItemize(itemizeLines):\n",
    "    lines=[]\n",
    "    lines.append(r\"\\begin{itemize}\")\n",
    "    for line in itemizeLines:\n",
    "        lines.append(r\"\\item \"+line)\n",
    "    lines.append(r\"\\end{itemize}\")\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findNumberColour(dictNumbers):\n",
    "    result={}\n",
    "    for case in dictNumbers:\n",
    "        if dictNumbers[case]<listLimites[0]:\n",
    "            result[case]=listLimCoul[0]\n",
    "        elif dictNumbers[case]<listLimites[1]:\n",
    "            result[case]=listLimCoul[1]\n",
    "        elif dictNumbers[case]<listLimites[2]:\n",
    "            result[case]=listLimCoul[2]\n",
    "        elif dictNumbers[case]<listLimites[3]:\n",
    "            result[case]=listLimCoul[3]\n",
    "        elif dictNumbers[case]<listLimites[4]:\n",
    "            result[case]=listLimCoul[4]\n",
    "        else:\n",
    "            result[case]=listLimCoul[5]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regroupeLexique(dictPartition,lexique):\n",
    "    lexiqueRegroupe=lexique.copy()\n",
    "    for p in dictPartition:\n",
    "        lCases=dictPartition[p]\n",
    "        lexiqueRegroupe.loc[lexiqueRegroupe[\"case\"].isin(lCases),\"morphome\"]=\"/\".join(lCases)\n",
    "        lexiqueRegroupe.loc[lexiqueRegroupe[\"case\"].isin(lCases),\"case\"]=p\n",
    "    return lexiqueRegroupe.groupby([\"lexeme\",\"phono\",\"case\",\"morphome\"]).agg({\"freq\":np.sum, \"tir1\":np.sum}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tableauPaires(paradigme):\n",
    "    table=pd.DataFrame(columns=[\"ligne\",\"colonne\",\"nbPaires\"])\n",
    "    refCases=paradigme.columns.tolist()\n",
    "    refCases.remove(\"lexeme\")\n",
    "    for n,paire in enumerate(it.combinations_with_replacement(refCases,2)):\n",
    "        if paire[0] in paradigme.columns and paire[1] in paradigme.columns:\n",
    "            nbPaires=len(paradigme[[paire[0],paire[1]]].dropna())\n",
    "        else:\n",
    "            nbPaires=0\n",
    "        table.loc[2*n]=[paire[0],paire[1],nbPaires]\n",
    "        table.loc[2*n+1]=[paire[1],paire[0],nbPaires]\n",
    "    tableau=table.pivot_table(index=\"ligne\",columns=[\"colonne\"])\n",
    "    return tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graphs=[]\n",
    "latexLines=[]\n",
    "pairesTableaux=[]\n",
    "#for nomLexique in sorted(listeTirages100k):\n",
    "for nLexique,nomLexique in enumerate(listeTirages):\n",
    "    lexique=lireLexique(nomLexique)\n",
    "    lexique[\"phono\"]=lexique[\"phono\"].apply(checkFrench)\n",
    "    lexique1=lexique[lexique[\"tir1\"]>0]\n",
    "    taille=lexique1[\"tir1\"].count()\n",
    "    itemizeLines=[]\n",
    "    latexLines.append(nomLexique.split(\"/\")[-1])\n",
    "    itemizeLines.append(\"%d formes\"%taille)\n",
    "    itemizeLines.append(\"%d tirages\"%lexique1[\"tir1\"].sum())\n",
    "    paradigmes=lexique2Paradigmes(lexique1)\n",
    "    tableauOrigine=tableauPaires(paradigmes)\n",
    "    dictNumbers=findFormNumbers(paradigmes)\n",
    "    dictFormNumbers=findNumberColour(dictNumbers)\n",
    "\n",
    "    syncretisms=[]\n",
    "    cliques=[]\n",
    "\n",
    "    dictPartition=defParadigme(paradigmes)\n",
    "    if regroupeTirages and noDiff:\n",
    "        lexiqueRegroupe=regroupeLexique(dictPartition,lexique1)\n",
    "        paradigmesRegroupe=lexique2Paradigmes(lexiqueRegroupe)\n",
    "        tableauRegroupe=tableauPaires(paradigmesRegroupe)\n",
    "\n",
    "        tableauOrigine.to_csv(nomLexique.replace(\".pkl\",\"-%s%d-Separe.csv\"%(dt.datetime.now().strftime(\"%y%m%d-%H%M\"),nLexique)),sep=\";\",encoding=\"utf8\")\n",
    "        tableauRegroupe.to_csv(nomLexique.replace(\".pkl\",\"-%s%d-Groupe.csv\"%(dt.datetime.now().strftime(\"%y%m%d-%H%M\"),nLexique)),sep=\";\",encoding=\"utf8\")\n",
    "\n",
    "        pairesTableaux.append((tableauOrigine,tableauRegroupe))\n",
    "        nomLexiqueRegroupe=nomLexique.replace(\".pkl\",phonologicalMap+\"-%s-Morphomes.pkl\"%dt.datetime.now().strftime(\"%y%m%d-%H%M\"))\n",
    "        if nomLexique==nomLexiqueRegroupe:\n",
    "            print u\"pb avec le nom du fichier pour les tirages regroupés\"\n",
    "        else:\n",
    "            with open(nomLexiqueRegroupe,\"wb\") as output:\n",
    "                pickle.dump(lexiqueRegroupe, output, pickle.HIGHEST_PROTOCOL)\n",
    "    dictColours=findColours(dictPartition)\n",
    "    latexLines.append(makeItemize(itemizeLines))\n",
    "    latexLines.append(makeTabular(dictColours,title=\"Morphomes\",cat=cat))\n",
    "    if nbFormesPrint:\n",
    "        latexLines.append(makeTabular(dictFormNumbers,title=\"Nombre de formes\",coulLim=True,cat=cat))\n",
    "if noDiff:\n",
    "    nomFichierSortie=nomFichierMorphomes.replace(\".tex\",phonologicalMap+\"-%s-NoDiff.tex\"%dt.datetime.now().strftime(\"%y%m%d-%H%M\"))\n",
    "else:\n",
    "    nomFichierSortie=nomFichierMorphomes.replace(\".tex\",phonologicalMap+\"-%s-Diff.tex\"%dt.datetime.now().strftime(\"%y%m%d-%H%M\"))\n",
    "with open(nomFichierSortie,\"w\") as output:\n",
    "    output.write(\"\\n\".join(latexLines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculs pour le lexique complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lexiquePrefix=\"MGC-160104\"\n",
    "nomLexiqueBase=\"/Users/gilles/Box Sync/2015-Data/\"+lexiquePrefix+'-Verbes2.pkl'\n",
    "with open(nomLexiqueBase, 'rb') as input:\n",
    "    lexiqueBase = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lexiqueBase[\"freqcum\"]= (lexiqueBase[\"freq\"].cumsum()*1000).astype(int)\n",
    "del lexiqueBase[\"ext\"]\n",
    "del lexiqueBase[\"cs\"]\n",
    "del lexiqueBase[\"ms\"]\n",
    "del lexiqueBase[\"vs\"]\n",
    "del lexiqueBase[\"prob\"]\n",
    "lexiqueBase[\"tir1\"]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graphs=[]\n",
    "latexLines=[]\n",
    "pairesTableaux=[]\n",
    "lexique=lexiqueBase\n",
    "lexique[\"phono\"]=lexique[\"phono\"].apply(checkFrench)\n",
    "lexique1=lexique[lexique[\"tir1\"]>0]\n",
    "taille=lexique1[\"tir1\"].count()\n",
    "itemizeLines=[]\n",
    "latexLines.append(nomLexiqueBase.split(\"/\")[-1])\n",
    "itemizeLines.append(\"%d formes\"%taille)\n",
    "itemizeLines.append(\"%d tirages\"%lexique1[\"tir1\"].sum())\n",
    "paradigmes=lexique2Paradigmes(lexique1)\n",
    "tableauBaseOrigine=tableauPaires(paradigmes)\n",
    "dictNumbers=findFormNumbers(paradigmes)\n",
    "dictFormNumbers=findNumberColour(dictNumbers)\n",
    "\n",
    "syncretisms=[]\n",
    "cliques=[]\n",
    "\n",
    "dictPartition=defParadigme(paradigmes)\n",
    "if regroupeTirages and noDiff:\n",
    "    lexiqueBaseRegroupe=regroupeLexique(dictPartition,lexique1)\n",
    "    paradigmesBaseRegroupe=lexique2Paradigmes(lexiqueBaseRegroupe)\n",
    "    tableauBaseRegroupe=tableauPaires(paradigmesBaseRegroupe)\n",
    "\n",
    "    tableauBaseOrigine.to_csv(nomLexiqueBase.replace(\".pkl\",\"-%s-Complet-Separe.csv\"%(dt.datetime.now().strftime(\"%y%m%d-%H%M\"))),sep=\";\",encoding=\"utf8\")\n",
    "    tableauBaseRegroupe.to_csv(nomLexiqueBase.replace(\".pkl\",\"-%s-Complet-Groupe.csv\"%(dt.datetime.now().strftime(\"%y%m%d-%H%M\"))),sep=\";\",encoding=\"utf8\")\n",
    "\n",
    "    pairesTableaux.append((tableauBaseOrigine,tableauBaseRegroupe))\n",
    "    nomLexiqueBaseRegroupe=nomLexiqueBase.replace(\".pkl\",phonologicalMap+\"-%s-Morphomes.pkl\"%dt.datetime.now().strftime(\"%y%m%d-%H%M\"))\n",
    "    if nomLexiqueBase==nomLexiqueBaseRegroupe:\n",
    "        print u\"pb avec le nom du fichier pour les tirages regroupés\"\n",
    "    else:\n",
    "        with open(nomLexiqueBaseRegroupe,\"wb\") as output:\n",
    "            pickle.dump(lexiqueBaseRegroupe, output, pickle.HIGHEST_PROTOCOL)\n",
    "dictColours=findColours(dictPartition)\n",
    "latexLines.append(makeItemize(itemizeLines))\n",
    "latexLines.append(makeTabular(dictColours,title=\"Morphomes\",cat=cat))\n",
    "if nbFormesPrint:\n",
    "    latexLines.append(makeTabular(dictFormNumbers,title=\"Nombre de formes\",coulLim=True,cat=cat))\n",
    "if noDiff:\n",
    "    nomFichierSortie=nomFichierMorphomes.replace(\".tex\",phonologicalMap+\"-%s-NoDiff.tex\"%dt.datetime.now().strftime(\"%y%m%d-%H%M\"))\n",
    "else:\n",
    "    nomFichierSortie=nomFichierMorphomes.replace(\".tex\",phonologicalMap+\"-%s-Diff.tex\"%dt.datetime.now().strftime(\"%y%m%d-%H%M\"))\n",
    "with open(nomFichierSortie,\"w\") as output:\n",
    "    output.write(\"\\n\".join(latexLines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "caseEgalite(\"pi2S\",\"pi3S\",debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for nEchant,(tableau1,tableau2) in enumerate(pairesTableaux):\n",
    "    tableau1.to_csv(nomLexique.replace(\".pkl\",\"%d-Separe.csv\"%nEchant),sep=\";\",encoding=\"utf8\")\n",
    "    tableau2.to_csv(nomLexique.replace(\".pkl\",\"%d-Groupe.csv\"%nEchant),sep=\";\",encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "try:\n",
    "    import pygraphviz\n",
    "    from networkx.drawing.nx_agraph import write_dot\n",
    "    print(\"using package pygraphviz\")\n",
    "except ImportError:\n",
    "    try:\n",
    "        import pydotplus\n",
    "        from networkx.drawing.nx_pydot import write_dot\n",
    "        print(\"using package pydotplus\")\n",
    "    except ImportError:\n",
    "        print()\n",
    "        print(\"Both pygraphviz and pydotplus were not found \")\n",
    "        print(\"see http://networkx.github.io/documentation\"\n",
    "              \"/latest/reference/drawing.html for info\")\n",
    "        print()\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "G=graphs[0]\n",
    "#pos = \n",
    "#nx.draw(G,pos=nx.layout.fruchterman_reingold_layout(G,scale=20))\n",
    "for numG,G in enumerate(graphs):\n",
    "    write_dot(G,\"test%02d.dot\"%numG)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "pdLexiqueRegroupe=regroupeLexique(dictPartition,lexique1)\n",
    "pdLexiqueRegroupe\n",
    "pdParadigmeRegroupe=pd.pivot_table(pdLexiqueRegroupe, values='phono', index=['lexeme'], columns=['case'], aggfunc=lambda x: \",\".join(x))\n",
    "pdParadigmeRegroupe.to_dict(orient=\"index\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pdLexiqueRegroupe[pdLexiqueRegroupe[\"lexeme\"]==u\"abaisser\"][[\"phono\",\"case\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lexeme</th>\n",
       "      <th>phono</th>\n",
       "      <th>case</th>\n",
       "      <th>morphome</th>\n",
       "      <th>freq</th>\n",
       "      <th>tir1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abaissé</td>\n",
       "      <td>abEsE</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp/fs</td>\n",
       "      <td>0.245</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abaissé</td>\n",
       "      <td>abEsE</td>\n",
       "      <td>mp</td>\n",
       "      <td>mp</td>\n",
       "      <td>0.040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abaissé</td>\n",
       "      <td>abEsE</td>\n",
       "      <td>ms</td>\n",
       "      <td>ms</td>\n",
       "      <td>0.115</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abandonné</td>\n",
       "      <td>abâdOnE</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp/fs</td>\n",
       "      <td>7.295</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abandonné</td>\n",
       "      <td>abâdOnE</td>\n",
       "      <td>mp</td>\n",
       "      <td>mp</td>\n",
       "      <td>2.890</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abandonné</td>\n",
       "      <td>abâdOnE</td>\n",
       "      <td>ms</td>\n",
       "      <td>ms</td>\n",
       "      <td>6.145</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abasourdi</td>\n",
       "      <td>abazuRdi</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp/fs</td>\n",
       "      <td>0.340</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abasourdi</td>\n",
       "      <td>abazuRdi</td>\n",
       "      <td>mp</td>\n",
       "      <td>mp</td>\n",
       "      <td>0.045</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>abasourdi</td>\n",
       "      <td>abazuRdi</td>\n",
       "      <td>ms</td>\n",
       "      <td>ms</td>\n",
       "      <td>1.135</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>abasourdissant</td>\n",
       "      <td>abazuRdisâ</td>\n",
       "      <td>ms</td>\n",
       "      <td>ms</td>\n",
       "      <td>0.005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>abattu</td>\n",
       "      <td>abaty</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp/fs</td>\n",
       "      <td>1.225</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>abattu</td>\n",
       "      <td>abaty</td>\n",
       "      <td>mp</td>\n",
       "      <td>mp</td>\n",
       "      <td>0.775</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>abattu</td>\n",
       "      <td>abaty</td>\n",
       "      <td>ms</td>\n",
       "      <td>ms</td>\n",
       "      <td>2.800</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>abbatial</td>\n",
       "      <td>abasjal</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp/fs</td>\n",
       "      <td>0.170</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>abbatial</td>\n",
       "      <td>abasjal</td>\n",
       "      <td>ms</td>\n",
       "      <td>ms</td>\n",
       "      <td>0.135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>abdominal</td>\n",
       "      <td>abdOminO</td>\n",
       "      <td>mp</td>\n",
       "      <td>mp</td>\n",
       "      <td>0.100</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>abdominal</td>\n",
       "      <td>abdOminal</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp/fs</td>\n",
       "      <td>1.305</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>abdominal</td>\n",
       "      <td>abdOminal</td>\n",
       "      <td>ms</td>\n",
       "      <td>ms</td>\n",
       "      <td>0.250</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>aberrant</td>\n",
       "      <td>abERâ</td>\n",
       "      <td>mp</td>\n",
       "      <td>mp</td>\n",
       "      <td>0.245</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>aberrant</td>\n",
       "      <td>abERâ</td>\n",
       "      <td>ms</td>\n",
       "      <td>ms</td>\n",
       "      <td>0.830</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>aberrant</td>\n",
       "      <td>abERât</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp/fs</td>\n",
       "      <td>0.595</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>abhorré</td>\n",
       "      <td>abORE</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp/fs</td>\n",
       "      <td>0.040</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>abhorré</td>\n",
       "      <td>abORE</td>\n",
       "      <td>ms</td>\n",
       "      <td>ms</td>\n",
       "      <td>0.100</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>abject</td>\n",
       "      <td>abZEkt</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp/fs</td>\n",
       "      <td>1.215</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>abject</td>\n",
       "      <td>abZEkt</td>\n",
       "      <td>mp</td>\n",
       "      <td>mp</td>\n",
       "      <td>0.295</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>abject</td>\n",
       "      <td>abZEkt</td>\n",
       "      <td>ms</td>\n",
       "      <td>ms</td>\n",
       "      <td>1.545</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>aboli</td>\n",
       "      <td>abOli</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp/fs</td>\n",
       "      <td>0.470</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>aboli</td>\n",
       "      <td>abOli</td>\n",
       "      <td>mp</td>\n",
       "      <td>mp</td>\n",
       "      <td>0.205</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>aboli</td>\n",
       "      <td>abOli</td>\n",
       "      <td>ms</td>\n",
       "      <td>ms</td>\n",
       "      <td>0.650</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>abondant</td>\n",
       "      <td>abôdâ</td>\n",
       "      <td>mp</td>\n",
       "      <td>mp</td>\n",
       "      <td>0.500</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14957</th>\n",
       "      <td>éveillé</td>\n",
       "      <td>EvEjE</td>\n",
       "      <td>mp</td>\n",
       "      <td>mp</td>\n",
       "      <td>0.610</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14958</th>\n",
       "      <td>éveillé</td>\n",
       "      <td>EvEjE</td>\n",
       "      <td>ms</td>\n",
       "      <td>ms</td>\n",
       "      <td>3.400</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14959</th>\n",
       "      <td>éventré</td>\n",
       "      <td>EvâtRE</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp/fs</td>\n",
       "      <td>1.130</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14960</th>\n",
       "      <td>éventré</td>\n",
       "      <td>EvâtRE</td>\n",
       "      <td>mp</td>\n",
       "      <td>mp</td>\n",
       "      <td>0.755</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14961</th>\n",
       "      <td>éventré</td>\n",
       "      <td>EvâtRE</td>\n",
       "      <td>ms</td>\n",
       "      <td>ms</td>\n",
       "      <td>0.790</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14962</th>\n",
       "      <td>éventuel</td>\n",
       "      <td>EvâtHEl</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp/fs</td>\n",
       "      <td>4.545</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14963</th>\n",
       "      <td>éventuel</td>\n",
       "      <td>EvâtHEl</td>\n",
       "      <td>mp</td>\n",
       "      <td>mp</td>\n",
       "      <td>1.855</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14964</th>\n",
       "      <td>éventuel</td>\n",
       "      <td>EvâtHEl</td>\n",
       "      <td>ms</td>\n",
       "      <td>ms</td>\n",
       "      <td>2.650</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14965</th>\n",
       "      <td>éventé</td>\n",
       "      <td>EvâtE</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp/fs</td>\n",
       "      <td>0.395</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14966</th>\n",
       "      <td>éventé</td>\n",
       "      <td>EvâtE</td>\n",
       "      <td>mp</td>\n",
       "      <td>mp</td>\n",
       "      <td>0.170</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14967</th>\n",
       "      <td>éventé</td>\n",
       "      <td>EvâtE</td>\n",
       "      <td>ms</td>\n",
       "      <td>ms</td>\n",
       "      <td>0.295</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14968</th>\n",
       "      <td>évident</td>\n",
       "      <td>Evidâ</td>\n",
       "      <td>mp</td>\n",
       "      <td>mp</td>\n",
       "      <td>1.205</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14969</th>\n",
       "      <td>évident</td>\n",
       "      <td>Evidâ</td>\n",
       "      <td>ms</td>\n",
       "      <td>ms</td>\n",
       "      <td>24.445</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14970</th>\n",
       "      <td>évident</td>\n",
       "      <td>Evidât</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp/fs</td>\n",
       "      <td>7.430</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14971</th>\n",
       "      <td>évidé</td>\n",
       "      <td>EvidE</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp/fs</td>\n",
       "      <td>0.080</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14972</th>\n",
       "      <td>évidé</td>\n",
       "      <td>EvidE</td>\n",
       "      <td>ms</td>\n",
       "      <td>ms</td>\n",
       "      <td>0.180</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14973</th>\n",
       "      <td>évitable</td>\n",
       "      <td>Evitabl</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp/fs</td>\n",
       "      <td>0.075</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14974</th>\n",
       "      <td>évocateur</td>\n",
       "      <td>EvOkat9R</td>\n",
       "      <td>mp</td>\n",
       "      <td>mp</td>\n",
       "      <td>0.140</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14975</th>\n",
       "      <td>évocateur</td>\n",
       "      <td>EvOkat9R</td>\n",
       "      <td>ms</td>\n",
       "      <td>ms</td>\n",
       "      <td>0.435</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14976</th>\n",
       "      <td>évocateur</td>\n",
       "      <td>EvOkatRis</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp/fs</td>\n",
       "      <td>0.240</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14977</th>\n",
       "      <td>évolutif</td>\n",
       "      <td>EvOlytif</td>\n",
       "      <td>ms</td>\n",
       "      <td>ms</td>\n",
       "      <td>0.075</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14978</th>\n",
       "      <td>évolutif</td>\n",
       "      <td>EvOlytiv</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp/fs</td>\n",
       "      <td>0.225</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14979</th>\n",
       "      <td>évolutionniste</td>\n",
       "      <td>EvOlysjOnist</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp/fs</td>\n",
       "      <td>0.075</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14980</th>\n",
       "      <td>évolué</td>\n",
       "      <td>EvOlHE</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp/fs</td>\n",
       "      <td>0.610</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14981</th>\n",
       "      <td>évolué</td>\n",
       "      <td>EvOlHE</td>\n",
       "      <td>mp</td>\n",
       "      <td>mp</td>\n",
       "      <td>0.395</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14982</th>\n",
       "      <td>évolué</td>\n",
       "      <td>EvOlHE</td>\n",
       "      <td>ms</td>\n",
       "      <td>ms</td>\n",
       "      <td>0.485</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14983</th>\n",
       "      <td>éwé</td>\n",
       "      <td>EvE</td>\n",
       "      <td>mp</td>\n",
       "      <td>mp</td>\n",
       "      <td>0.070</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14984</th>\n",
       "      <td>éwé</td>\n",
       "      <td>EvE</td>\n",
       "      <td>ms</td>\n",
       "      <td>ms</td>\n",
       "      <td>0.035</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14985</th>\n",
       "      <td>ôté</td>\n",
       "      <td>OtE</td>\n",
       "      <td>fp</td>\n",
       "      <td>fp/fs</td>\n",
       "      <td>0.225</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14986</th>\n",
       "      <td>ôté</td>\n",
       "      <td>OtE</td>\n",
       "      <td>ms</td>\n",
       "      <td>ms</td>\n",
       "      <td>0.155</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14987 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               lexeme         phono case morphome    freq  tir1\n",
       "0             abaissé         abEsE   fp    fp/fs   0.245     6\n",
       "1             abaissé         abEsE   mp       mp   0.040     1\n",
       "2             abaissé         abEsE   ms       ms   0.115     3\n",
       "3           abandonné       abâdOnE   fp    fp/fs   7.295   223\n",
       "4           abandonné       abâdOnE   mp       mp   2.890    96\n",
       "5           abandonné       abâdOnE   ms       ms   6.145   212\n",
       "6           abasourdi      abazuRdi   fp    fp/fs   0.340    10\n",
       "7           abasourdi      abazuRdi   mp       mp   0.045     3\n",
       "8           abasourdi      abazuRdi   ms       ms   1.135    45\n",
       "9      abasourdissant    abazuRdisâ   ms       ms   0.005     1\n",
       "10             abattu         abaty   fp    fp/fs   1.225    37\n",
       "11             abattu         abaty   mp       mp   0.775    23\n",
       "12             abattu         abaty   ms       ms   2.800   116\n",
       "13           abbatial       abasjal   fp    fp/fs   0.170     5\n",
       "14           abbatial       abasjal   ms       ms   0.135     1\n",
       "15          abdominal      abdOminO   mp       mp   0.100     5\n",
       "16          abdominal     abdOminal   fp    fp/fs   1.305    47\n",
       "17          abdominal     abdOminal   ms       ms   0.250    10\n",
       "18           aberrant         abERâ   mp       mp   0.245     3\n",
       "19           aberrant         abERâ   ms       ms   0.830    23\n",
       "20           aberrant        abERât   fp    fp/fs   0.595    24\n",
       "21            abhorré         abORE   fp    fp/fs   0.040     2\n",
       "22            abhorré         abORE   ms       ms   0.100     4\n",
       "23             abject        abZEkt   fp    fp/fs   1.215    36\n",
       "24             abject        abZEkt   mp       mp   0.295    11\n",
       "25             abject        abZEkt   ms       ms   1.545    49\n",
       "26              aboli         abOli   fp    fp/fs   0.470    18\n",
       "27              aboli         abOli   mp       mp   0.205     4\n",
       "28              aboli         abOli   ms       ms   0.650    15\n",
       "29           abondant         abôdâ   mp       mp   0.500    10\n",
       "...               ...           ...  ...      ...     ...   ...\n",
       "14957         éveillé         EvEjE   mp       mp   0.610    21\n",
       "14958         éveillé         EvEjE   ms       ms   3.400    94\n",
       "14959         éventré        EvâtRE   fp    fp/fs   1.130    43\n",
       "14960         éventré        EvâtRE   mp       mp   0.755    22\n",
       "14961         éventré        EvâtRE   ms       ms   0.790    23\n",
       "14962        éventuel       EvâtHEl   fp    fp/fs   4.545   155\n",
       "14963        éventuel       EvâtHEl   mp       mp   1.855    57\n",
       "14964        éventuel       EvâtHEl   ms       ms   2.650    85\n",
       "14965          éventé         EvâtE   fp    fp/fs   0.395    18\n",
       "14966          éventé         EvâtE   mp       mp   0.170     5\n",
       "14967          éventé         EvâtE   ms       ms   0.295    10\n",
       "14968         évident         Evidâ   mp       mp   1.205    31\n",
       "14969         évident         Evidâ   ms       ms  24.445   787\n",
       "14970         évident        Evidât   fp    fp/fs   7.430   224\n",
       "14971           évidé         EvidE   fp    fp/fs   0.080     1\n",
       "14972           évidé         EvidE   ms       ms   0.180     7\n",
       "14973        évitable       Evitabl   fp    fp/fs   0.075     3\n",
       "14974       évocateur      EvOkat9R   mp       mp   0.140     4\n",
       "14975       évocateur      EvOkat9R   ms       ms   0.435     6\n",
       "14976       évocateur     EvOkatRis   fp    fp/fs   0.240     9\n",
       "14977        évolutif      EvOlytif   ms       ms   0.075     2\n",
       "14978        évolutif      EvOlytiv   fp    fp/fs   0.225     5\n",
       "14979  évolutionniste  EvOlysjOnist   fp    fp/fs   0.075     5\n",
       "14980          évolué        EvOlHE   fp    fp/fs   0.610    30\n",
       "14981          évolué        EvOlHE   mp       mp   0.395     8\n",
       "14982          évolué        EvOlHE   ms       ms   0.485    16\n",
       "14983             éwé           EvE   mp       mp   0.070     1\n",
       "14984             éwé           EvE   ms       ms   0.035     2\n",
       "14985             ôté           OtE   fp    fp/fs   0.225    12\n",
       "14986             ôté           OtE   ms       ms   0.155     5\n",
       "\n",
       "[14987 rows x 6 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexiqueRegroupe"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
