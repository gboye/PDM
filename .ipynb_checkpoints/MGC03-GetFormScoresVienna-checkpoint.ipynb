{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "import codecs\n",
    "import features\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it\n",
    "import pickle\n",
    "import networkx as nx\n",
    "#%pylab inline\n",
    "#pd.options.display.mpl_style = 'default'\n",
    "debug=False\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.html.widgets import FloatProgress\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "def dateheure():\n",
    "    return datetime.datetime.utcnow().strftime('%y%m%d%H%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saut=\"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des matrices de traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features.add_config('bdlexique.ini')\n",
    "fs=features.FeatureSystem('phonemes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phonologicalMap=\"-N\"\n",
    "sampleNumber=\"03%s\"%phonologicalMap\n",
    "sampleType=\"BRASS\"\n",
    "sampleType=\"SILVER\"\n",
    "#samplePrefix=\"MGC-160104-%s-ext3-derivations-%s\"%(sampleNumber,sampleType)\n",
    "samplePrefix=\"MGC-160104-%s-ext3-160215-derivations-%s\"%(sampleNumber,sampleType)\n",
    "sampleFile=samplePrefix+\".csv\"\n",
    "#analysisPrefix=\"MGC-160104-%s-ext3-derivations-%s\"%(sampleNumber,sampleType)\n",
    "analysisPrefix=samplePrefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neutralisationsNORD=(u\"6û\",u\"9ê\")\n",
    "neutralisationsSUD=(u\"e2o\",u\"E9O\")\n",
    "if phonologicalMap==\"-N\":\n",
    "    neutralisations=neutralisationsNORD\n",
    "elif phonologicalMap==\"-S\":\n",
    "    neutralisations=neutralisationsSUD\n",
    "else:\n",
    "    neutralisations=(u\"\",u\"\")\n",
    "    phonologicalMap=(\"-X\")\n",
    "bdlexiqueIn = unicode(u\"èò\"+neutralisations[0])\n",
    "bdlexiqueNum = [ord(char) for char in bdlexiqueIn]\n",
    "neutreOut = unicode(u\"EO\"+neutralisations[1])\n",
    "neutralise = dict(zip(bdlexiqueNum, neutreOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def recoder(chaine,table=neutralise):\n",
    "    if type(chaine)==str:\n",
    "        temp=unicode(chaine.decode('utf8')).translate(table)\n",
    "        result=temp.encode('utf8')\n",
    "    elif type(chaine)==unicode:\n",
    "        result=chaine.translate(table)\n",
    "    else:\n",
    "        result=chaine\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"2015-Data/\"+analysisPrefix+'-TousDerives.pkl', 'rb') as input:\n",
    "    tousDerives=pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"2015-Data/MGC-160104-DerivesComplets.pkl\", 'rb') as input:\n",
    "    derivesComplets=pickle.load(input)\n",
    "derivesComplets[\"FS\"]=derivesComplets.apply(lambda x: recoder(x[\"FS\"]),axis=1)\n",
    "derivesComplets[\"FP\"]=derivesComplets.apply(lambda x: recoder(x[\"FP\"]),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Le tableau est assemblé à la main à partir des échantillons\n",
    "- faire une boucle pour charger tous les échantillons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tableauDerives=(tousDerives[[\"lexeme\",\"FS_x\",\"FP_x\",\"FS_y\",\"FP_y\"]]).rename(columns={\"lexeme\":\"base\"})\n",
    "#tableauDerives\n",
    "tableauEvaluation=pd.merge(tableauDerives,derivesComplets,on=\"base\")\n",
    "tableauEvaluation.loc[tableauEvaluation[\"FS\"].isnull(),\"FS\"]=tableauEvaluation.loc[tableauEvaluation[\"FS\"].isnull(),\"FP\"]\n",
    "tableauEvaluation.loc[tableauEvaluation[\"FP\"].isnull(),\"FP\"]=tableauEvaluation.loc[tableauEvaluation[\"FP\"].isnull(),\"FS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numerosSamples=[\"1\",\"2\",\"3\"]\n",
    "typesSamples=[\"B\",\"S\"]\n",
    "nomsSamples=[n+t for (n,t) in (list(it.product(numerosSamples, typesSamples)))]\n",
    "casesSamples=[\"FS\",\"FP\"]\n",
    "samplesColumnsFormes=[c+\"-\"+n for (n,c) in (list(it.product(nomsSamples,casesSamples)))]\n",
    "samplesColumns=[\"base\",\"FS\",\"FP\"]+samplesColumnsFormes\n",
    "samplesEmptyColumn=[\"\" for element in samplesColumns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fNoLex(df):\n",
    "    return ((df[\"FS_x\"].isnull())&(df[\"FP_x\"].isnull()))\n",
    "def fFS(df):\n",
    "    return ((df[\"FS_y\"].notnull())&(df[\"FP_y\"].isnull()))\n",
    "def fFP(df):\n",
    "    return ((df[\"FP_y\"].notnull())&(df[\"FS_y\"].isnull()))\n",
    "def fFSFP(df):\n",
    "    return ((df[\"FS_y\"].notnull())&(df[\"FP_y\"].notnull()))\n",
    "\n",
    "def filtrePrecisionRappel(df,case,nom):\n",
    "    return ((df[case].notnull())&(df[\"%s_x\"%(case)].isnull())&(df[\"%s-%s\"%(case,nom)].notnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-N SILVER\n",
      "FS\t91 40 50\n",
      "FP\t91 40 50\n"
     ]
    }
   ],
   "source": [
    "print (sampleNumber, sampleType)\n",
    "for case in casesSamples:\n",
    "    print (case,end=\"\\t\")\n",
    "    ok=tableauEvaluation[(tableauEvaluation[\"%s_x\"%case].isnull())&(tableauEvaluation[\"%s_y\"%case].notnull())].apply(lambda x: x[case]==x[\"%s_y\"%case],axis=1).sum()\n",
    "    mauvais=tableauEvaluation[(tableauEvaluation[\"%s_x\"%case].isnull())&(tableauEvaluation[\"%s_y\"%case].notnull())].apply(lambda x: x[case]!=x[\"%s_y\"%case],axis=1).sum()\n",
    "    total=tableauEvaluation[tableauEvaluation[\"%s_x\"%case].isnull()].apply(lambda x: x[case]==x[case],axis=1).sum()\n",
    "    print (total, ok, mauvais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03-N SILVER\n",
      "90 40.0 50.0\n"
     ]
    }
   ],
   "source": [
    "print (sampleNumber, sampleType)\n",
    "ok=tableauEvaluation[fNoLex(tableauEvaluation)&fFS(tableauEvaluation)].apply(lambda x: x[\"FS\"]==x[\"FS_y\"],axis=1).sum()\n",
    "ok+=tableauEvaluation[fNoLex(tableauEvaluation)&fFP(tableauEvaluation)].apply(lambda x: x[\"FP\"]==x[\"FP_y\"],axis=1).sum()\n",
    "ok+=tableauEvaluation[fNoLex(tableauEvaluation)&fFSFP(tableauEvaluation)].apply(lambda x: (x[\"FS\"]==x[\"FS_y\"]) and (x[\"FP\"]==x[\"FP_y\"]),axis=1).sum()\n",
    "mauvais=tableauEvaluation[fNoLex(tableauEvaluation)&fFS(tableauEvaluation)].apply(lambda x: x[\"FS\"]!=x[\"FS_y\"],axis=1).sum()\n",
    "mauvais+=tableauEvaluation[fNoLex(tableauEvaluation)&fFP(tableauEvaluation)].apply(lambda x: x[\"FP\"]!=x[\"FP_y\"],axis=1).sum()\n",
    "mauvais+=tableauEvaluation[fNoLex(tableauEvaluation)&fFSFP(tableauEvaluation)].apply(lambda x: (x[\"FS\"]!=x[\"FS_y\"]) or (x[\"FP\"]!=x[\"FP_y\"]),axis=1).sum()\n",
    "total=tableauEvaluation[fNoLex(tableauEvaluation)].apply(lambda x: x[case]==x[case],axis=1).sum()\n",
    "#print (total, ok, mauvais)\n",
    "print (total, ok[\"base\"],mauvais[\"base\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tableauEvaluation[fNoLex(tableauEvaluation)&fFSFP(tableauEvaluation)].apply(lambda x: (x[\"FS\"]!=x[\"FS_y\"]) or (x[\"FP\"]!=x[\"FP_y\"]),axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "samplesSelections=pd.DataFrame(columns=samplesColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samplesSelections=derivesComplets"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "numLexeme=0\n",
    "for sample in formesScoresSamples:\n",
    "    sampleName=\"\".join(sample.split(\"-\"))\n",
    "    if debug: print (sampleName)\n",
    "    for lexeme in formesScoresSamples[sample]:\n",
    "        if debug: print (lexeme)\n",
    "        for cell in formesScoresSamples[sample][lexeme]:\n",
    "            if debug: print (cell)\n",
    "            formeScores=formesScoresSamples[sample][lexeme][cell]\n",
    "            try: \n",
    "                forme=max(formeScores, key=lambda i: formeScores[i])\n",
    "            except ValueError:\n",
    "                forme=\"\"\n",
    "            if debug: print (forme)\n",
    "            if not lexeme in samplesSelections[\"base\"].tolist():\n",
    "                samplesSelections.loc[numLexeme, \"base\"]=lexeme\n",
    "                numLexeme+=1\n",
    "            samplesSelections.loc[samplesSelections[\"base\"]==lexeme,cell+\"-\"+sampleName]=forme"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "for nom in nomsSamples:\n",
    "    print (nom, end=\"\\t\")\n",
    "    for case in casesSamples:\n",
    "        print (case, end=\"\\t\")\n",
    "        ok=samplesSelections[samplesSelections[\"%s-%s\"%(case,nom)].notnull()].apply(lambda x: x[case]==x[\"%s-%s\"%(case,nom)],axis=1).sum()\n",
    "        mauvais=samplesSelections[samplesSelections[\"%s-%s\"%(case,nom)].notnull()].apply(lambda x: x[case]!=x[\"%s-%s\"%(case,nom)],axis=1).sum()\n",
    "        total=samplesSelections[samplesSelections[case].notnull()].apply(lambda x: x[case]==x[case],axis=1).sum()\n",
    "        print (total,\"\\t\", ok,\"\\t\", mauvais,\"\\t\", \"%02.2f\"%(ok/float(ok+mauvais)),\"\\t\", \"%02.2f\"%(ok/float(total)),end=\"\\t\")\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "samplesSelections[samplesColumns].to_csv(\"2015-Data/\"+analysisPrefix+'-Scores.csv',index=False,encoding=\"utf8\",sep=\";\")\n",
    "\n",
    "with open(\"2015-Data/MGC-160104-Derives2.pkl\",\"rb\") as input:\n",
    "    derives=pickle.load(input)\n",
    "\n",
    "paradigmesDerives=pd.pivot_table(derives, values='phono', index=['base'], columns=['ms'], aggfunc=lambda x: \",\".join(x)).reset_index().reindex()\n",
    "paradigmesDerives[[\"base\",\"FS\",\"FP\"]].to_csv(\"2015-Data/MGC-160104-DerivesComplets.csv\",index=False,encoding=\"utf8\",sep=\";\")\n",
    "with open(\"2015-Data/MGC-160104-DerivesComplets.pkl\", 'wb') as output:\n",
    "    pickle.dump(paradigmesDerives[[\"base\",\"FS\",\"FP\"]], output, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
