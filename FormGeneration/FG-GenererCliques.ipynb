{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Génération des cliques à partir d'un échantillon et des classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importations\n",
    "- codecs pour les encodages\n",
    "- pandas et numpy pour les calculs sur tableaux\n",
    "- matplotlib pour les graphiques\n",
    "- itertools pour les itérateurs sophistiqués (paires sur liste, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "import codecs,glob,re,pickle,features\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it\n",
    "import networkx as nx\n",
    "debug=False\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def dateheure():\n",
    "    return datetime.datetime.utcnow().strftime('%y%m%d%H%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saut=\"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des matrices de traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.add_config('../bdlexique.ini')\n",
    "fs=features.FeatureSystem('phonemes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "genDigraphe=False\n",
    "genGraphe=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-00-T10000-F2994-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-00-T10000-F2994-S-MSP-Regles.pkl\n"
     ]
    }
   ],
   "source": [
    "phonologicalMap=\"-S\"\n",
    "\n",
    "repSample=\"/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/\"\n",
    "repClasses=\"/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/\"\n",
    "serie=\"MSP\"\n",
    "numEchantillon=0\n",
    "nomGold=\"/Users/gilles/Box Sync/2015-Data/MGC-170716-Adjectifs.pkl\"\n",
    "\n",
    "listeSamples=glob.glob(repSample+\"Longitudinal*%s.pkl\"%serie)\n",
    "nomSample=listeSamples[numEchantillon]\n",
    "print (nomSample)\n",
    "listeClasses=glob.glob(repSample+\"Longitudinal*%s-Regles.pkl\"%serie)\n",
    "nomClasse=listeClasses[numEchantillon]\n",
    "print (nomClasse)\n",
    "analyseCases=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dierese={\"j\":\"ij\", \"w\":\"uw\",\"H\":\"yH\",\"i\":\"ij\",\"u\":\"uw\",\"y\":\"yH\"}\n",
    "def checkFrench(prononciation):\n",
    "    result=recoder(prononciation)\n",
    "    m=re.match(ur\"^.*([^ieèEaOouy926êôâ])[jwH]$\",result)\n",
    "    if m:\n",
    "        print (\"pb avec un glide final\", prononciation)\n",
    "    m=re.match(ur\"(.*[ptkbdgfsSvzZ][rl])([jwH])(.*)\",result)\n",
    "    if m:\n",
    "        n=re.search(ur\"[ptkbdgfsSvzZ][rl](wa|Hi|wê)\",result)\n",
    "        if not n:\n",
    "            glide=m.group(2)\n",
    "            result=m.group(1)+dierese[glide]+m.group(3)\n",
    "    m=re.match(ur\"(.*)([iuy])([ieEaOouy].*)\",result)\n",
    "    if m:\n",
    "        glide=m.group(2)\n",
    "        result=m.group(1)+dierese[glide]+m.group(3)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lireLexique(nomLexique):\n",
    "    with open(nomLexique, 'rb') as input:\n",
    "        lexique=pickle.load(input)\n",
    "    return lexique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lexique2Paradigmes(lexique):\n",
    "    return pd.pivot_table(lexique, values='phono', index=['lexeme'], columns=['case'], aggfunc=lambda x: \",\".join(x)).reset_index().reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if debug: print(phonologicalMap)\n",
    "neutralisationsNORD=(u\"6û\",u\"9ê\")\n",
    "neutralisationsSUD=(u\"e2o\",u\"E9O\")\n",
    "if phonologicalMap==\"-N\":\n",
    "    neutralisations=neutralisationsNORD\n",
    "elif phonologicalMap==\"-S\":\n",
    "    neutralisations=neutralisationsSUD\n",
    "else:\n",
    "    neutralisations=(u\"\",u\"\")\n",
    "    phonologicalMap=(\"-X\")\n",
    "bdlexiqueIn = unicode(u\"èò\"+neutralisations[0])\n",
    "bdlexiqueNum = [ord(char) for char in bdlexiqueIn]\n",
    "neutreOut = unicode(u\"EO\"+neutralisations[1])\n",
    "neutralise = dict(zip(bdlexiqueNum, neutreOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recoder(chaine,table=neutralise):\n",
    "    if type(chaine)==str:\n",
    "        temp=unicode(chaine.decode('utf8')).translate(table)\n",
    "        result=temp.encode('utf8')\n",
    "    elif type(chaine)==unicode:\n",
    "        result=chaine.translate(table)\n",
    "    else:\n",
    "        result=chaine\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation du paradigme de référence (Gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexiqueGold=lireLexique(nomGold)\n",
    "lexiqueGold[\"phono\"]=lexiqueGold[\"phono\"].apply(checkFrench)\n",
    "paradigmesGold=lexique2Paradigmes(lexiqueGold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation du paradigme de référence (Base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preparerLexiqueBase(nomSample):\n",
    "    nomBase=nomSample\n",
    "    if serie==\"OMP\":\n",
    "        nomBase=nomSample.replace(\"OMP\",\"MSP\")\n",
    "    print (nomBase)\n",
    "    lexiqueBase=lireLexique(nomBase)\n",
    "    lexiqueBase[\"phono\"]=lexiqueBase[\"phono\"].apply(checkFrench)\n",
    "    paradigmesBase=lexique2Paradigmes(lexiqueBase)\n",
    "    return paradigmesBase"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "paradigmesGold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des cases du paradigme"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "casesTotales=lireLexique(nomSample)[\"case\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation du calcul des analogies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul de la différence entre deux formes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def diff(mot1,mot2):\n",
    "    result=[]\n",
    "    diff1=\"\"\n",
    "    diff2=\"\"\n",
    "    same=\"\"\n",
    "    vide=\".\"\n",
    "    lmax=max(len(mot1),len(mot2))\n",
    "    lmin=min(len(mot1),len(mot2))\n",
    "    for index in range(lmax):\n",
    "        if index < lmin:\n",
    "            if mot1[index]!=mot2[index]:\n",
    "                diff1+=mot1[index]\n",
    "                diff2+=mot2[index]\n",
    "                same+=vide\n",
    "            else:\n",
    "                same+=mot1[index]\n",
    "                diff1+=vide\n",
    "                diff2+=vide\n",
    "        elif index < len(mot1):\n",
    "            diff1+=mot1[index]\n",
    "        elif index < len(mot2):\n",
    "            diff2+=mot2[index]\n",
    "    diff1=diff1.lstrip(\".\")\n",
    "    diff2=diff2.lstrip(\".\")\n",
    "#    return (same,diff1,diff2,diff1+\"_\"+diff2)\n",
    "    return (diff1+\"-\"+diff2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accumulation des paires appartenant à un patron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rowDiff(row, patrons):\n",
    "    result=diff(row[0],row[1])\n",
    "    if not result in patrons:\n",
    "        patrons[result]=(formesPatron(),formesPatron())\n",
    "    patrons[result][0].ajouterFormes(row[0])\n",
    "    patrons[result][1].ajouterFormes(row[1])\n",
    "    return (result[0],result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation d'un patron en RegExp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patron2regexp(morceaux):\n",
    "    result=\"^\"\n",
    "    for morceau in morceaux:\n",
    "        if morceau==\"*\":\n",
    "            result+=\"(.*)\"\n",
    "        elif len(morceau)>1:\n",
    "            result+=\"([\"+morceau+\"])\"\n",
    "        else:\n",
    "            result+=morceau\n",
    "    result+=\"$\"\n",
    "    result=result.replace(\")(\",\"\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Substitution de sortie \n",
    "???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remplacementSortie(sortie):\n",
    "    n=1\n",
    "    nsortie=\"\"\n",
    "    for lettre in sortie:\n",
    "        if lettre==\".\":\n",
    "            nsortie+=\"\\g<%d>\"%n\n",
    "            n+=1\n",
    "        else:\n",
    "            nsortie+=lettre\n",
    "    return nsortie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classe pour la gestion des patrons, des classes et des transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class paireClasses:\n",
    "    def __init__(self,case1,case2):\n",
    "        self.case1=case1\n",
    "        self.case2=case2\n",
    "        self.nom=case1+\"-\"+case2\n",
    "        self.classes1=classesPaire(case1,case2)\n",
    "        self.classes2=classesPaire(case2,case1)\n",
    "\n",
    "    def ajouterPatron(self,n,patron,motif):\n",
    "        if n==1:\n",
    "            self.classes1.ajouterPatron(patron,motif)\n",
    "        elif n==2:\n",
    "            self.classes2.ajouterPatron(patron,motif)\n",
    "        else:\n",
    "            if debug: print (\"le numéro de forme n'est pas dans [1,2]\",n,file=logfile)\n",
    "\n",
    "    def ajouterPaire(self,forme1,forme2):\n",
    "        self.classes1.ajouterPaire(forme1,forme2)\n",
    "        self.classes2.ajouterPaire(forme2,forme1)\n",
    "        \n",
    "    def calculerClasses(self):\n",
    "        return(self.classes1,self.classes2)\n",
    "\n",
    "    \n",
    "class classesPaire:\n",
    "    '''\n",
    "    Gestion des patrons, des classes et des transformations\n",
    "    \n",
    "    ajouterPatron : ajoute un patron et son motif associé (MGL)\n",
    "    ajouterPaire : ajoute une paire de formes, calcule la classe de la forme1 et la règle sélectionnée\n",
    "    sortirForme : cacule les formes de sortie correspondant à la forme1 avec leurs coefficients respectifs\n",
    "    '''\n",
    "    def __init__(self,case1,case2):\n",
    "        self.case1=case1\n",
    "        self.case2=case2\n",
    "        self.nom=case1+\"-\"+case2\n",
    "        self.classe={}\n",
    "        self.nbClasse={}\n",
    "        self.patrons={}\n",
    "        self.entree={}\n",
    "        self.sortie={}\n",
    "    \n",
    "    def ajouterPatron(self,patron,motif):\n",
    "        self.patrons[patron]=motif\n",
    "        (entree,sortie)=patron.split(\"-\")\n",
    "        self.entree[patron]=entree.replace(u\".\",u\"(.)\")\n",
    "        self.sortie[patron]=remplacementSortie(sortie)\n",
    "    \n",
    "    def ajouterPaire(self,forme1,forme2):\n",
    "        '''\n",
    "        on calcule la classe de la paire idClasseForme et la règle sélectionnée\n",
    "        on incrémente le compteur de la classe et celui de la règle sélectionnée à l'intérieur de la classe\n",
    "        '''\n",
    "        classeForme=[]\n",
    "        regleForme=\"\"\n",
    "        for patron in self.patrons:\n",
    "            if re.match(self.patrons[patron],forme1):\n",
    "                classeForme.append(patron)\n",
    "                '''\n",
    "                le +\"$\" permet de forcer l'alignement à droite pour les transformations suffixales\n",
    "                '''\n",
    "                if forme2==re.sub(self.entree[patron]+\"$\",self.sortie[patron],forme1):\n",
    "                    regleForme=patron\n",
    "        idClasseForme=\", \".join(classeForme)\n",
    "        if not idClasseForme in self.classe:\n",
    "            self.classe[idClasseForme]={}\n",
    "            self.nbClasse[idClasseForme]=0\n",
    "        if not regleForme in self.classe[idClasseForme]:\n",
    "            self.classe[idClasseForme][regleForme]=0\n",
    "        self.nbClasse[idClasseForme]+=1\n",
    "        self.classe[idClasseForme][regleForme]+=1\n",
    "\n",
    "    def sortirForme(self,forme):\n",
    "        classeForme=[]\n",
    "        sortieForme={}\n",
    "        for patron in self.patrons:\n",
    "            if re.match(self.patrons[patron],forme):\n",
    "                classeForme.append(patron)\n",
    "        if classeForme:\n",
    "            idClasseForme=\", \".join(classeForme)\n",
    "            if idClasseForme in self.nbClasse:\n",
    "                nTotal=self.nbClasse[idClasseForme]\n",
    "                for patron in self.classe[idClasseForme]:\n",
    "                    sortie=re.sub(self.entree[patron]+\"$\",self.sortie[patron],forme)\n",
    "                    sortieForme[sortie]=float(self.classe[idClasseForme][patron])/nTotal\n",
    "            else:\n",
    "                if debug:\n",
    "                    print (forme, file=logfile)\n",
    "                    print (\"pas de classe\",idClasseForme, file=logfile)\n",
    "                    print (\"%.2f par forme de sortie\" % (float(1)/len(classeForme)), file=logfile)\n",
    "                nTotal=len(classeForme)\n",
    "                for patron in classeForme:\n",
    "                    sortie=re.sub(self.entree[patron]+\"$\",self.sortie[patron],forme)\n",
    "                    sortieForme[sortie]=float(1)/nTotal\n",
    "        else:\n",
    "            if debug:\n",
    "                print (forme, file=logfile) \n",
    "                print (\"pas de patron\", file=logfile)\n",
    "        return sortieForme\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appliquer la formule de calcul des différences entre chaines à chaque ligne\n",
    "\n",
    ">si il y a au moins une ligne\n",
    "\n",
    ">>on applique la différence à la ligne\n",
    "\n",
    ">>on calcule les deux patrons par suppression des points initiaux\n",
    "\n",
    ">>on renvoie le groupement par patrons (1&2)\n",
    "\n",
    ">sinon\n",
    "\n",
    ">>on renvoie le paradigme vide d'origine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLDrapports(paradigme):\n",
    "    (case1,case2,lexeme)= paradigme.columns.values.tolist()\n",
    "    patrons=pairePatrons(case1,case2)\n",
    "    if len(paradigme)>0:\n",
    "#        for index, row in paradigme.iterrows():\n",
    "#            patrons.ajouterFormes(row[0],row[1],diff(row[0],row[1]))\n",
    "        paradigme.apply(lambda x: patrons.ajouterFormes(x[case1],x[case2],diff(x[case1],x[case2])), axis=1)\n",
    "        (regles1,regles2)=patrons.calculerGM()\n",
    "    return patrons.calculerGM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rapports(paradigme):\n",
    "    if len(paradigme.columns.values.tolist())==2:\n",
    "        (case1,lexeme)= paradigme.columns.values.tolist()\n",
    "        case2=case1\n",
    "    else:\n",
    "        (case1,case2,lexeme)= paradigme.columns.values.tolist()\n",
    "    patrons=pairePatrons(case1,case2)\n",
    "    classes=paireClasses(case1,case2)\n",
    "    if len(paradigme)>0:\n",
    "        paradigme.apply(lambda x: patrons.ajouterFormes(x[case1],x[case2],diff(x[case1],x[case2])), axis=1)\n",
    "        (regles1,regles2)=patrons.calculerGM()\n",
    "        for regle in regles1:\n",
    "            classes.ajouterPatron(1,regle,regles1[regle])\n",
    "        for regle in regles2:\n",
    "            classes.ajouterPatron(2,regle,regles2[regle])\n",
    "        paradigme.apply(lambda x: classes.ajouterPaire(x[case1],x[case2]), axis=1)\n",
    "    (classes1,classes2)=classes.calculerClasses()\n",
    "    return (classes1,classes2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dédoubler les lignes avec des surabondances dans *colonne*\n",
    ">identifier une ligne avec surabondance\n",
    "\n",
    ">>ajouter les lignes correspondant à chaque valeur\n",
    "\n",
    ">>ajouter le numéro de la ligne initiale dans les lignes à supprimer\n",
    "\n",
    ">supprimer les lignes avec surabondance\n",
    "\n",
    "NB : il faut préparer le tableau pour avoir une indexation qui permette l'ajout des valeurs individuelles et la suppression des lignes de surabondances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitCellMates(df,colonne):\n",
    "    '''\n",
    "    Calcul d'une dataframe sans surabondance par dédoublement des valeurs\n",
    "    '''\n",
    "    test=df.reset_index()\n",
    "    del test[\"index\"]\n",
    "    splitIndexes=[]\n",
    "    for index,ligne in test.iterrows():\n",
    "        if \",\" in ligne[colonne]:\n",
    "            valeurs=set(ligne[colonne].split(\",\"))\n",
    "            nouvelleLigne=ligne\n",
    "            for valeur in valeurs:\n",
    "                nouvelleLigne[colonne]=valeur\n",
    "                test=test.append(nouvelleLigne,ignore_index=True)\n",
    "            splitIndexes.append(index)\n",
    "    if splitIndexes:\n",
    "        test=test.drop(test.index[splitIndexes])\n",
    "    return test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparerSample(nomSample):\n",
    "    lexique=lireLexique(nomSample)\n",
    "    lexique[\"phono\"]=lexique[\"phono\"].apply(checkFrench)\n",
    "    morphomes={}\n",
    "    if \"morphome\" in lexique.columns:\n",
    "        for morphome in lexique.morphome.unique():\n",
    "            if \"/\" in morphome:\n",
    "                morphomeCases=morphome.split(\"/\")\n",
    "                morphomeCase=lexique[lexique[\"morphome\"]==morphome][\"case\"].unique().tolist()\n",
    "                if len(morphomeCase)>1:\n",
    "                    print(\"pb\",morphomeCase)\n",
    "                else:\n",
    "                    morphomeCase=morphomeCase[0]\n",
    "                morphomes[morphomeCase]=morphomeCases\n",
    "        print (morphomes)\n",
    "    paradigmes=lexique2Paradigmes(lexique)\n",
    "    paradigmes=paradigmes.dropna(axis=1,how='all')\n",
    "    return morphomes,paradigmes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sampleCases pour la liste des cases effectivement représentées dans le corpus de départ "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sampleCases=paradigmes.columns.values.tolist()\n",
    "sampleCases.remove(u\"lexeme\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "paradigmes.stack().value_counts(dropna=True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparerClasses(numSample):\n",
    "    nomClasse=listeClasses[numSample]\n",
    "    print(nomClasse)\n",
    "    with open(nomClasse, 'rb') as input:\n",
    "        resultatsLecture = pickle.load(input)\n",
    "    return resultatsLecture\n",
    "#resultatsLecture=preparerClasses(numSample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparer les cases analysées avec l'ensemble de toutes les cases"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "analyseCases=list(set([case for (case,autre) in resultatsLecture.keys()]))\n",
    "if sorted(analyseCases)!=sorted(casesTotales):\n",
    "    print (\"Attention l'analyse ne comprend pas toutes les cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class paradigmeDistribution:\n",
    "    '''\n",
    "    Gestion des distributions dans les cases du paradigme\n",
    "    '''\n",
    "\n",
    "    def __init__(self,lexeme):\n",
    "        self.lexeme=lexeme\n",
    "        self.formes={i:{} for i in analyseCases}\n",
    "\n",
    "    def ajouterFormes(self,case,formes,coef=1.0):\n",
    "        for forme in formes:\n",
    "            if not forme in self.formes[case]:\n",
    "                self.formes[case][forme]=0\n",
    "            self.formes[case][forme]+=formes[forme]*coef\n",
    "            \n",
    "    def normaliserDistributions(self,caseListe=analyseCases):\n",
    "#        print (analyseCases)\n",
    "        normalesDistributions={i:{} for i in caseListe}\n",
    "        for case in caseListe:\n",
    "            total=0\n",
    "            for element in self.formes[case]:\n",
    "                total+=self.formes[case][element]\n",
    "            for element in self.formes[case]:\n",
    "                normalesDistributions[case][element]=float(self.formes[case][element])/total\n",
    "        return normalesDistributions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generateForms(lexeme):\n",
    "    candidats=paradigmeDistribution(lexeme)\n",
    "    casesSamples=paradigmes[paradigmes[\"lexeme\"]==lexeme].columns[paradigmes[paradigmes[\"lexeme\"]==lexeme].notnull().iloc[0]].tolist()\n",
    "    casesSamples.remove(\"lexeme\")\n",
    "    for caseDepart in casesSamples:\n",
    "        formeDepart=paradigmes[paradigmes[\"lexeme\"]==lexeme][caseDepart].iloc[0]\n",
    "        if debug: print (caseDepart,formeDepart, file=logfile)\n",
    "#        if formeDepart!=\"nan\":\n",
    "        for case in analyseCases:\n",
    "            if debug: print (case, file=logfile)\n",
    "            if not isinstance(resultatsLecture[(caseDepart, case)],str):\n",
    "                if \",\" in formeDepart:\n",
    "                    formesDepart=formeDepart.split(\",\")\n",
    "                    coef=1.0/len(formesDepart)\n",
    "                    for element in formesDepart:\n",
    "                        candidats.ajouterFormes(case,resultatsLecture[(caseDepart, case)].sortirForme(element),coef)\n",
    "                else:\n",
    "                    candidats.ajouterFormes(case,resultatsLecture[(caseDepart, case)].sortirForme(formeDepart))\n",
    "            else: \n",
    "                if debug: print (\"str\", resultatsLecture[(caseDepart, case)], file=logfile)\n",
    "    return candidats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ajouterPoint(lexeme,forme,case,digraphe,graphe):\n",
    "    pointName=\"%s-%s-%s\"%(lexeme,forme,case)\n",
    "#    if not pointName in digraphe.nodes():\n",
    "    tam=case[:2]\n",
    "    if tam==\"in\": tam=\"inf\"\n",
    "    digraphe.add_node(pointName, tam='\"%s\"'%tam)\n",
    "    graphe.add_node(pointName, tam='\"%s\"'%tam)\n",
    "    return pointName\n",
    "\n",
    "def ajouterFleche(pointDepart,pointSortie,coef,digraphe,graphe):\n",
    "    digraphe.add_edge(pointDepart,pointSortie,weight=float(coef))\n",
    "    if digraphe.has_edge(pointSortie,pointDepart):\n",
    "        coefGraphe=float(digraphe.edge[pointSortie][pointDepart][\"weight\"]+coef)/2\n",
    "        graphe.add_edge(pointDepart,pointSortie,weight=coefGraphe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateParadigms(generation1,genDigraphe=True):\n",
    "#    print (generation1.formes)\n",
    "    lexeme=generation1.lexeme\n",
    "    distributionInitiale=generation1.normaliserDistributions()\n",
    "    candidats=paradigmeDistribution(lexeme)\n",
    "    digraphe=nx.DiGraph()\n",
    "    graphe=nx.Graph()\n",
    "    for caseDepart in analyseCases:\n",
    "#        print (distributionInitiale)\n",
    "        for formeDepart in distributionInitiale[caseDepart]:\n",
    "            if formeDepart:\n",
    "                pointDepart=ajouterPoint(lexeme,formeDepart,caseDepart,digraphe,graphe)\n",
    "                coefDepart=distributionInitiale[caseDepart][formeDepart]\n",
    "                if debug: print (caseDepart,formeDepart, file=logfile)\n",
    "                for caseSortie in analyseCases:\n",
    "                    distributionSortieBrute=resultatsLecture[(caseDepart, caseSortie)].sortirForme(formeDepart)\n",
    "                    if distributionSortieBrute:\n",
    "                        if not genDigraphe:\n",
    "#                            print (\"brute\",distributionSortieBrute)\n",
    "                            distributionSortie={f:distributionSortieBrute[f] for f in distributionSortieBrute if f in distributionInitiale[caseSortie]}\n",
    "                        else:\n",
    "                            distributionSortie=distributionSortieBrute\n",
    "#                        print (\"filtre\",distributionSortie)\n",
    "#                        print (distributionInitiale[caseSortie])\n",
    "                        if debug: print (caseSortie,distributionSortie,distributionInitiale[caseDepart], file=logfile)\n",
    "                        candidats.ajouterFormes(caseSortie,distributionSortie,distributionInitiale[caseDepart][formeDepart])\n",
    "                        for formeSortie in distributionSortie:\n",
    "                            pointSortie=ajouterPoint(lexeme,formeSortie,caseSortie,digraphe,graphe)\n",
    "                            coefSortie=distributionSortie[formeSortie]\n",
    "                            ajouterFleche(pointDepart,pointSortie,float(coefDepart*coefSortie),digraphe,graphe)\n",
    "    return (candidats,digraphe,graphe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(lexeme,genDigraphe=True):\n",
    "#    print (lexeme,end=\", \")\n",
    "    generation1=generateForms(lexeme)\n",
    "#    print (\"génération 2\",end=\", \")\n",
    "    (generation2,lexDigraphe,lexGraphe)=generateParadigms(generation1,genDigraphe)\n",
    "    lexCliques=list(nx.algorithms.clique.find_cliques(lexGraphe))\n",
    "#    print (lexCliques)\n",
    "#    print (\"génération 3\")\n",
    "    return (generation2,lexDigraphe,lexGraphe,lexCliques)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "len(paradigmes.dropna(thresh=1)[\"lexeme\"])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "paradigmes.dropna(thresh=1);"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "paradigmes.dropna(thresh=1).count().sum()-paradigmes.dropna(thresh=1)[\"lexeme\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculer le score de la clique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cliqueScore(clique,graph):\n",
    "    score=0\n",
    "    for (depart,arrivee) in it.combinations_with_replacement(clique,2):\n",
    "        score+=graph[depart][arrivee][\"weight\"]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération des formes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def genererFormes(paradigmes):\n",
    "    debug=False\n",
    "    listeTest=paradigmes.dropna(thresh=1)[\"lexeme\"].values.tolist()\n",
    "    nbLexemes=len(listeTest)\n",
    "    print (nbLexemes)\n",
    "    globDigraphe=nx.DiGraph()\n",
    "    globGraphe=nx.Graph()\n",
    "    cliques=[]\n",
    "    cliquesScores={}\n",
    "    cliquesListes={}\n",
    "    numClique=0\n",
    "    #progressBar = FloatProgress(min=0, max=nbLexemes)\n",
    "    #display(progressBar)\n",
    "    for i,element in enumerate(listeTest):\n",
    "    #    if (i%100)==0: print (i, dateheure()[-4:], int(100*float(i)/nbVerbes), end=\", \")\n",
    "    #    progressBar.value=i\n",
    "        result=generate(element,genDigraphe)\n",
    "        (generation,lexDigraphe,lexGraphe,lexCliques)= result\n",
    "    #    print (generation,lexDigraphe,lexGraphe,lexCliques)\n",
    "        if genDigraphe:\n",
    "            globDigraphe=nx.union(globDigraphe,lexDigraphe)\n",
    "        if genGraphe:\n",
    "            globGraphe=nx.union(globGraphe,lexGraphe)\n",
    "        cliques.extend(lexCliques)\n",
    "        for clique in lexCliques:\n",
    "            cliquesScores[numClique]=cliqueScore(clique,lexGraphe)\n",
    "            cliquesListes[numClique]=clique\n",
    "            numClique+=1\n",
    "    versionStamp=dateheure()\n",
    "    if genDigraphe: \n",
    "        nx.write_dot(globDigraphe,u\"2015-Data/digraphe-%s.dot\"%versionStamp)\n",
    "    if genGraphe:\n",
    "        nx.write_dot(globGraphe,u\"2015-Data/graphe-%s.dot\"%versionStamp)    \n",
    "    return listeTest,cliques,cliquesScores"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print (len(cliques))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "longueurCliques={}\n",
    "for clique in cliques:\n",
    "    longueur=len(clique)\n",
    "    if not longueur in longueurCliques:\n",
    "        longueurCliques[longueur]=1\n",
    "    else:\n",
    "        longueurCliques[longueur]+=1\n",
    "longueurCliques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faire la liste des cases lexicalisées de l'échantillon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparerCasesLexicales(paradigmes):\n",
    "    nbFormesLexicales={}\n",
    "    casesLexicales={element:paradigmes[paradigmes[\"lexeme\"]==element].columns[paradigmes[paradigmes[\"lexeme\"]==element].notnull().iloc[0]].tolist() for element in listeTest}\n",
    "    for element in casesLexicales:\n",
    "        casesLexicales[element].remove(\"lexeme\")\n",
    "        nbFormesLexicales[element]=len(casesLexicales[element])\n",
    "    return casesLexicales\n",
    "#casesLexicales=preparerCasesLexicales(paradigmes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparer la sortie des cliques avec le paradigme de départ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filtrerFidelite(clique,casesLexicales):\n",
    "    seuilClique=1\n",
    "    paradigmesListe=[]\n",
    "    #progressBar = FloatProgress(min=0, max=len(cliques))\n",
    "    #display(progressBar)\n",
    "    for n,clique in enumerate(cliques):\n",
    "    #    progressBar.value=n\n",
    "        if len(clique)>seuilClique:\n",
    "            paradigmeClique={}\n",
    "            sampleOK=True\n",
    "            point=clique[0].split(\"-\")\n",
    "            lPoint=len(point)\n",
    "            if lPoint==3:\n",
    "                lexeme=point[0]\n",
    "            else:\n",
    "                lexeme=\"-\".join(point[0:len(point)-2])\n",
    "            paradigmeClique[\"lexeme\"]=lexeme\n",
    "            casesLexeme=casesLexicales[lexeme]\n",
    "            nbInitial=len(casesLexeme)\n",
    "            if casesLexeme and len(casesLexeme)<=len(clique):\n",
    "                for element in casesLexeme:\n",
    "                    champForme=paradigmes[paradigmes[\"lexeme\"]==lexeme][element].iloc[0]\n",
    "                    if \",\"  in champForme:\n",
    "                        formes=champForme.split(\",\")\n",
    "                        nbInitial+=len(formes)-1\n",
    "                        okFormes=False\n",
    "                        for forme in formes:\n",
    "                            pointCase=u\"%s-%s-%s\"% (lexeme,forme,element)\n",
    "                            if pointCase in clique:\n",
    "                                okFormes=True\n",
    "                                if debug: print (\"point\",pointCase)\n",
    "                        if okFormes:\n",
    "                            sampleOK=True\n",
    "                        else:\n",
    "                            sampleOK=False\n",
    "                            break\n",
    "                    else:\n",
    "                        forme=champForme\n",
    "                        pointCase=u\"%s-%s-%s\"% (lexeme,forme,element)\n",
    "                        if debug: print (pointCase, clique)\n",
    "                        if not pointCase in clique:\n",
    "                            sampleOK=False\n",
    "                            break\n",
    "            else:\n",
    "                sampleOK=False\n",
    "            if sampleOK:\n",
    "                for element in clique:\n",
    "                    elements=element.split(\"-\")\n",
    "                    forme=elements[-2]\n",
    "                    taminfo=elements[-1]\n",
    "                    paradigmeClique[taminfo]=forme\n",
    "                paradigmeClique[\"score\"]=cliquesScores[n]\n",
    "                paradigmeClique[\"ajouts\"]=len(clique)-nbInitial\n",
    "                paradigmeClique[\"lexicales\"]=\", \".join(casesLexeme)\n",
    "                paradigmesListe.append(paradigmeClique)\n",
    "            else:\n",
    "                if debug:\n",
    "                    print ()\n",
    "                    print (lexeme,clique)\n",
    "                    print ()\n",
    "    paradigmesCLIQUES=pd.DataFrame(paradigmesListe,columns=[u\"lexeme\"]+sampleCases+[u\"score\",u\"ajouts\",\"lexicales\"])\n",
    "    return paradigmesCLIQUES\n",
    "#paradigmesCLIQUES=filtrerFidelite(clique,casesLexicales)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "paradigmesCLIQUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mesurerSimilarite(x):\n",
    "    def calculSimilariteCase(x,caseMorphome):\n",
    "        if (paradigmesBase[paradigmesBase[\"lexeme\"]==lexeme][caseMorphome]!=x[case]).all():\n",
    "            if (paradigmesGold[paradigmesGold[\"lexeme\"]==lexeme][caseMorphome]!=x[case]).all():\n",
    "                if x[case]:\n",
    "                    result[\"wrong\"]+=1\n",
    "                else:\n",
    "                    result[\"missing\"]+=1\n",
    "            else:\n",
    "                result[\"right\"]+=1\n",
    "        else:\n",
    "            result[\"known\"]+=1\n",
    "    \n",
    "    result={\"known\":0,\"right\":0,\"wrong\":0,\"missing\":0}\n",
    "    lexeme=x[\"lexeme\"]\n",
    "#    print (lexeme,sampleCases)\n",
    "    for case in sampleCases:\n",
    "#        print (case)\n",
    "        if case in morphomes:\n",
    "#            print (\"morphome\",case,morphomes[case])\n",
    "            for caseMorphome in morphomes[case]:\n",
    "#                print (\"caseMorphome\",caseMorphome)\n",
    "                calculSimilariteCase(x,caseMorphome)\n",
    "#                print (result,case)\n",
    "        else:\n",
    "#            print (\"normal\",case)\n",
    "            calculSimilariteCase(x,case)\n",
    "#    print (lexeme,result[\"known\"],result[\"right\"],result[\"wrong\"],result[\"missing\"])\n",
    "    return (result[\"known\"],result[\"right\"],result[\"wrong\"],result[\"missing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filtrerMax(paradigmesCLIQUES):\n",
    "    paradigmesMAX=paradigmesCLIQUES[paradigmesCLIQUES[\"score\"]==paradigmesCLIQUES.groupby([\"lexeme\"])[\"score\"].transform(max)].reset_index()\n",
    "    del paradigmesMAX[\"index\"]\n",
    "    paradigmesMAX[\"score\"]=paradigmesMAX[\"score\"].apply(str)\n",
    "    paradigmesMAX[\"ajouts\"]=paradigmesMAX[\"ajouts\"].apply(str)\n",
    "\n",
    "    paradigmesSILVER=paradigmesMAX.groupby(\"lexeme\").agg(lambda x: \",\".join(list(set(x.dropna().values)))).reset_index()\n",
    "    paradigmesSILVER[\"eval\"]=paradigmesSILVER.apply(lambda x: mesurerSimilarite(x), axis=1)\n",
    "    paradigmesSILVER[\"known\"],paradigmesSILVER[\"right\"],paradigmesSILVER[\"wrong\"],paradigmesSILVER[\"missing\"]=zip(*paradigmesSILVER[\"eval\"])\n",
    "    paradigmesSILVER.drop(\"eval\",axis=1,inplace=True)\n",
    "\n",
    "    return paradigmesSILVER\n",
    "\n",
    "#paradigmesSILVER=filtrerMax(paradigmesCLIQUES)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "paradigmesSILVER.to_csv(path_or_buf=nomSample.replace(\".pkl\",\"-Silver.csv\"),encoding=\"utf8\",sep=\";\")\n",
    "#GOLD.to_csv(path_or_buf=\"2015-Data/\"+analysisPrefix+'-Gold.csv',encoding=\"utf8\",sep=\";\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "paradigmesSILVER[[\"known\",\"right\",\"wrong\",\"missing\"]].sum(),numEchantillon,serie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boucle sur les échantillons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-00-T10000-F2994-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-00-T10000-F2994-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-00-T10000-F2994-S-MSP-Regles.pkl\n",
      "1910\n",
      "known      2994\n",
      "right      3927\n",
      "wrong       582\n",
      "missing     137\n",
      "dtype: int64 0 MSP\n",
      "1 /Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-01-T20000-F4568-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-01-T20000-F4568-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-01-T20000-F4568-S-MSP-Regles.pkl\n",
      "2663\n",
      "known      4568\n",
      "right      5149\n",
      "wrong       793\n",
      "missing     142\n",
      "dtype: int64 1 MSP\n",
      "2 /Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-02-T30000-F5701-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-02-T30000-F5701-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-02-T30000-F5701-S-MSP-Regles.pkl\n",
      "3150\n",
      "known      5699\n",
      "right      5853\n",
      "wrong       784\n",
      "missing     264\n",
      "dtype: int64 2 MSP\n",
      "3 /Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-03-T40000-F6652-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-03-T40000-F6652-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-03-T40000-F6652-S-MSP-Regles.pkl\n",
      "3523\n",
      "known      6649\n",
      "right      6304\n",
      "wrong       765\n",
      "missing     370\n",
      "dtype: int64 3 MSP\n",
      "4 /Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-04-T50000-F7385-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-04-T50000-F7385-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-04-T50000-F7385-S-MSP-Regles.pkl\n",
      "3798\n",
      "known      7382\n",
      "right      6595\n",
      "wrong       811\n",
      "missing     400\n",
      "dtype: int64 4 MSP\n",
      "5 /Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-05-T60000-F8040-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-05-T60000-F8040-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-05-T60000-F8040-S-MSP-Regles.pkl\n",
      "4021\n",
      "known      8037\n",
      "right      6757\n",
      "wrong       839\n",
      "missing     447\n",
      "dtype: int64 5 MSP\n",
      "6 /Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-06-T70000-F8568-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-06-T70000-F8568-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-06-T70000-F8568-S-MSP-Regles.pkl\n",
      "4195\n",
      "known      8565\n",
      "right      6893\n",
      "wrong       824\n",
      "missing     494\n",
      "dtype: int64 6 MSP\n",
      "7 /Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-07-T80000-F9081-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-07-T80000-F9081-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-07-T80000-F9081-S-MSP-Regles.pkl\n",
      "4370\n",
      "known      9078\n",
      "right      7025\n",
      "wrong       863\n",
      "missing     510\n",
      "dtype: int64 7 MSP\n",
      "8 /Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-08-T90000-F9561-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-08-T90000-F9561-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-08-T90000-F9561-S-MSP-Regles.pkl\n",
      "4541\n",
      "known      9558\n",
      "right      7162\n",
      "wrong       906\n",
      "missing     534\n",
      "dtype: int64 8 MSP\n",
      "9 /Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-09-T100000-F9974-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-09-T100000-F9974-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-09-T100000-F9974-S-MSP-Regles.pkl\n",
      "4667\n",
      "known      9971\n",
      "right      7225\n",
      "wrong       919\n",
      "missing     549\n",
      "dtype: int64 9 MSP\n",
      "10 /Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-10-T200000-F12719-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-10-T200000-F12719-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-10-T200000-F12719-S-MSP-Regles.pkl\n",
      "5573\n",
      "known      12715\n",
      "right       7957\n",
      "wrong        952\n",
      "missing      660\n",
      "dtype: int64 10 MSP\n",
      "11 /Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-11-T300000-F14300-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-11-T300000-F14300-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-11-T300000-F14300-S-MSP-Regles.pkl\n",
      "6119\n",
      "known      14293\n",
      "right       8566\n",
      "wrong       1258\n",
      "missing      347\n",
      "dtype: int64 11 MSP\n",
      "12 /Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-12-T400000-F15326-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-12-T400000-F15326-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-12-T400000-F15326-S-MSP-Regles.pkl\n",
      "6457\n",
      "known      15317\n",
      "right       8845\n",
      "wrong       1291\n",
      "missing      363\n",
      "dtype: int64 12 MSP\n",
      "13 /Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-13-T500000-F16117-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-13-T500000-F16117-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-13-T500000-F16117-S-MSP-Regles.pkl\n",
      "6718\n",
      "known      16108\n",
      "right       9078\n",
      "wrong       1314\n",
      "missing      360\n",
      "dtype: int64 13 MSP\n",
      "14 /Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-14-T600000-F16725-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-14-T600000-F16725-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-14-T600000-F16725-S-MSP-Regles.pkl\n",
      "6933\n",
      "known      16714\n",
      "right       9383\n",
      "wrong       1278\n",
      "missing      345\n",
      "dtype: int64 14 MSP\n",
      "15 /Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-15-T700000-F17209-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-15-T700000-F17209-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-15-T700000-F17209-S-MSP-Regles.pkl\n",
      "7111\n",
      "known      17196\n",
      "right       9569\n",
      "wrong       1315\n",
      "missing      352\n",
      "dtype: int64 15 MSP\n",
      "16 /Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-16-T800000-F17602-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-16-T800000-F17602-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-16-T800000-F17602-S-MSP-Regles.pkl\n",
      "7237\n",
      "known      17587\n",
      "right       9655\n",
      "wrong       1357\n",
      "missing      337\n",
      "dtype: int64 16 MSP\n",
      "17 /Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-17-T900000-F17925-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-17-T900000-F17925-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-17-T900000-F17925-S-MSP-Regles.pkl\n",
      "7364\n",
      "known      17910\n",
      "right       9844\n",
      "wrong       1422\n",
      "missing      268\n",
      "dtype: int64 17 MSP\n",
      "18 /Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-18-T1000000-F18210-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-18-T1000000-F18210-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-18-T1000000-F18210-S-MSP-Regles.pkl\n",
      "7463\n",
      "known      18195\n",
      "right       9935\n",
      "wrong       1433\n",
      "missing      277\n",
      "dtype: int64 18 MSP\n",
      "19 /Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-19-T2000000-F19654-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-19-T2000000-F19654-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-19-T2000000-F19654-S-MSP-Regles.pkl\n",
      "8005\n",
      "known      19635\n",
      "right      10615\n",
      "wrong       1525\n",
      "missing      233\n",
      "dtype: int64 19 MSP\n",
      "20 /Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-20-T3000000-F20160-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-20-T3000000-F20160-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-20-T3000000-F20160-S-MSP-Regles.pkl\n",
      "8215\n",
      "known      20140\n",
      "right      10917\n",
      "wrong       1551\n",
      "missing      236\n",
      "dtype: int64 20 MSP\n",
      "21 /Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-21-T4000000-F20440-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-21-T4000000-F20440-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-21-T4000000-F20440-S-MSP-Regles.pkl\n",
      "8321\n",
      "known      20420\n",
      "right      11054\n",
      "wrong       1549\n",
      "missing      245\n",
      "dtype: int64 21 MSP\n",
      "22 /Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-22-T5000000-F20590-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-22-T5000000-F20590-S-MSP.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-22-T5000000-F20590-S-MSP-Regles.pkl\n",
      "8388\n",
      "known      20570\n",
      "right      11163\n",
      "wrong       1553\n",
      "missing      250\n",
      "dtype: int64 22 MSP\n",
      "23 /Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-23-T6000000-F20701-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-23-T6000000-F20701-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-23-T6000000-F20701-S-MSP-Regles.pkl\n",
      "8437\n",
      "known      20679\n",
      "right      11250\n",
      "wrong       1551\n",
      "missing      252\n",
      "dtype: int64 23 MSP\n",
      "24 /Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-24-T7000000-F20791-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-24-T7000000-F20791-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-24-T7000000-F20791-S-MSP-Regles.pkl\n",
      "8474\n",
      "known      20769\n",
      "right      11299\n",
      "wrong       1560\n",
      "missing      252\n",
      "dtype: int64 24 MSP\n",
      "25 /Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-25-T8000000-F20865-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-25-T8000000-F20865-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-25-T8000000-F20865-S-MSP-Regles.pkl\n",
      "8510\n",
      "known      20843\n",
      "right      11365\n",
      "wrong       1562\n",
      "missing      254\n",
      "dtype: int64 25 MSP\n",
      "26 /Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-26-T9000000-F20927-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-26-T9000000-F20927-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-26-T9000000-F20927-S-MSP-Regles.pkl\n",
      "8537\n",
      "known      20905\n",
      "right      11408\n",
      "wrong       1570\n",
      "missing      249\n",
      "dtype: int64 26 MSP\n",
      "27 /Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-27-T10000000-F20973-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-27-T10000000-F20973-S-MSP.pkl\n",
      "/Users/gilles/Box Sync/2015-Data/FlexionAdjectifs/Longitudinal-27-T10000000-F20973-S-MSP-Regles.pkl\n",
      "8557\n",
      "known      20951\n",
      "right      11442\n",
      "wrong       1570\n",
      "missing      249\n",
      "dtype: int64 27 MSP\n"
     ]
    }
   ],
   "source": [
    "for numSample,nomSample in enumerate(listeSamples):\n",
    "    print (numSample,nomSample)\n",
    "    paradigmesBase=preparerLexiqueBase(nomSample)\n",
    "    morphomes,paradigmes=preparerSample(nomSample)\n",
    "    sampleCases=paradigmes.columns.values.tolist()\n",
    "    sampleCases.remove(u\"lexeme\")\n",
    "    casesTotales=paradigmesGold.columns.values.tolist()\n",
    "    casesTotales.remove(u\"lexeme\")\n",
    "    resultatsLecture=preparerClasses(numSample)\n",
    "    analyseCases=list(set([case for (case,autre) in resultatsLecture.keys()]))\n",
    "    if sorted(analyseCases)!=sorted(casesTotales):\n",
    "        print (\"Attention l'analyse ne comprend pas toutes les cases\")\n",
    "    listeTest,cliques,cliquesScores=genererFormes(paradigmes)\n",
    "    casesLexicales=preparerCasesLexicales(paradigmes)\n",
    "    paradigmesCLIQUES=filtrerFidelite(cliques,casesLexicales)\n",
    "    paradigmesSILVER=filtrerMax(paradigmesCLIQUES)\n",
    "    paradigmesSILVER.to_csv(path_or_buf=nomSample.replace(\".pkl\",\"-Silver.csv\"),encoding=\"utf8\",sep=\";\")\n",
    "    print (paradigmesSILVER[[\"known\",\"right\",\"wrong\",\"missing\"]].sum(),numSample,serie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paradigmesSILVER[paradigmesSILVER[\"wrong\"]>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paradigmesBase[paradigmesBase[\"fs\"].notnull() & paradigmesBase[\"fs\"].str.contains(\",\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexique=lireLexique(nomSample.replace(\"OMP\",\"MSP\"))\n",
    "lexique[lexique[\"lexeme\"]==\"lapon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultatsLecture[(\"fp\",\"ms\")].patrons"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
