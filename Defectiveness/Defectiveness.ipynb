{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import features\n",
    "import glob,re,pickle,os,yaml,datetime,pyperclip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choix échantillon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "debut=datetime.datetime.now()\n",
    "filePrefix=\"/Volumes/gilles/Transfert/Copies-iMac-GB/2015-Data/LongitudinalesRnd/\"\n",
    "filePrefix=\"/Volumes/gilles/Transfert/Copies-iMac-GB/2015-Data/lexique3/\"\n",
    "sampleFiles=glob.glob(filePrefix+\"Longitudinal*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefixEchantillon(numero):\n",
    "    candidats=[]\n",
    "    for sample in sampleFiles:\n",
    "#        m=re.match(ur\"^.*/(Longitudinal-%s-T\\d+-F\\d+)%s-paradigmes\\.csv\"%(numero,casesType),sample)\n",
    "        m=re.match(ur\"^.*/(Longitudinal-Lexique3-%s-T\\d+-F\\d+)%s-paradigmes\\.csv\"%(numero,casesType),sample)\n",
    "        if m:\n",
    "            candidats.append(m.group(1))\n",
    "    if len(candidats)==1:\n",
    "        return candidats[0]\n",
    "    else:\n",
    "        print \"PB pas de nom unique correspondant\",candidats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/gilles/Transfert/Copies-iMac-GB/2015-Data/lexique3/Longitudinal-Lexique3-00-T150000000-F73539-X-Morphomes-paradigmes-Swim2.csv\n"
     ]
    }
   ],
   "source": [
    "numeroEchantillon=\"00\"\n",
    "sampleType=\"-X\"\n",
    "casesType=\"-X-Morphomes\"\n",
    "etapeSwim=\"-Swim2\"\n",
    "samplePrefix=prefixEchantillon(numeroEchantillon)\n",
    "initialFile=filePrefix+samplePrefix+\"-X-paradigmes.csv\"\n",
    "analysisPrefix=filePrefix+samplePrefix+casesType\n",
    "predictionsFile=analysisPrefix+\"-paradigmes%s.csv\"%etapeSwim\n",
    "print predictionsFile\n",
    "referenceFile=\"/Volumes/gilles/Transfert/Copies-iMac-GB/2015-Data/MGC-171229-Verbes3.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variante phonologique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "phonologicalMap=sampleType.strip(\"-\")\n",
    "neutralisationsNORD=(u\"6û\",u\"9ê\")\n",
    "neutralisationsSUD=(u\"e2o\",u\"E9O\")\n",
    "if phonologicalMap==\"N\":\n",
    "    neutralisations=neutralisationsNORD\n",
    "elif phonologicalMap==\"S\":\n",
    "    neutralisations=neutralisationsSUD\n",
    "else:\n",
    "    neutralisations=(u\"\",u\"\")\n",
    "    phonologicalMap=(\"X\")\n",
    "bdlexiqueIn = unicode(u\"èò\"+neutralisations[0])\n",
    "bdlexiqueNum = [ord(char) for char in bdlexiqueIn]\n",
    "neutreOut = unicode(u\"EO\"+neutralisations[1])\n",
    "neutralise = dict(zip(bdlexiqueNum, neutreOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recoder(chaine,table=neutralise):\n",
    "    if type(chaine)==str:\n",
    "        temp=unicode(chaine.decode('utf8')).translate(table)\n",
    "        result=temp.encode('utf8')\n",
    "    elif type(chaine)==unicode:\n",
    "        result=chaine.translate(table)\n",
    "    else:\n",
    "        result=chaine\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dierese={\"j\":\"ij\", \"w\":\"uw\",\"H\":\"yH\",\"i\":\"ij\",\"u\":\"uw\",\"y\":\"yH\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkFrench(prononciation):\n",
    "    glide2voyelle={\"j\":\"i\",\"w\":\"u\",\"H\":\"y\"}\n",
    "    if prononciation:\n",
    "        if \",\" in prononciation:\n",
    "            prononciations=prononciation.split(\",\")\n",
    "            setPrononciations=set()\n",
    "            for element in prononciations:\n",
    "                setPrononciations.add(checkFrench(element))\n",
    "            result=\",\".join(list(setPrononciations))\n",
    "        else:\n",
    "            result=recoder(prononciation)\n",
    "            result=result.replace(\"Jj\",\"J\")\n",
    "            m=re.match(ur\"^(.*[^ieèEaOouy926êôâ])([jwH])$\",result)\n",
    "            if m:\n",
    "                print (\"pb avec un glide final\", prononciation)\n",
    "                voyelle=glide2voyelle[m.group(2)]\n",
    "                result=m.group(1)+voyelle\n",
    "            m=re.match(ur\"(.*[ptkbdgfsSvzZ][rl])([jwH])(.*)\",result)\n",
    "            if m:\n",
    "                n=re.search(ur\"[ptkbdgfsSvzZ][rl](wa|Hi|wê)\",result)\n",
    "                if not n:\n",
    "                    glide=m.group(2)\n",
    "                    result=m.group(1)+dierese[glide]+m.group(3)\n",
    "            m=re.match(ur\"(.*)([iuy])([ieEaOouy].*)\",result)\n",
    "            if m:\n",
    "                glide=m.group(2)\n",
    "                result=m.group(1)+dierese[glide]+m.group(3)\n",
    "            result=result.replace(\"jj\",\"ij\")\n",
    "    else:\n",
    "        result=prononciation\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paradigmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialParadigmes=pd.read_csv(initialFile,sep=\";\",encoding=\"utf8\")\n",
    "del initialParadigmes[u\"Unnamed: 0\"]\n",
    "initialParadigmes=initialParadigmes.dropna(axis=1,how='all')\n",
    "initialParadigmesColumns=initialParadigmes.columns.tolist()\n",
    "listeLexemes=initialParadigmes[\"lexeme\"].tolist()\n",
    "nbLexemes=len(listeLexemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialForms=pd.melt(initialParadigmes[initialParadigmes[\"lexeme\"].isin(listeLexemes)],id_vars=[\"lexeme\"]).dropna()\n",
    "initialForms[\"lexeme-case\"]=initialForms[\"lexeme\"]+\"-\"+initialForms[\"variable\"]\n",
    "initialForms.drop(labels=[\"lexeme\",\"variable\"],axis=1,inplace=True)\n",
    "initialForms.set_index([\"lexeme-case\"],inplace=True)\n",
    "initialFormsIndex=initialForms.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedParadigmes=pd.read_csv(predictionsFile,sep=\";\",encoding=\"utf8\")\n",
    "del predictedParadigmes[u\"Unnamed: 0\"]\n",
    "predictedParadigmes=predictedParadigmes.loc[:,predictedParadigmes.columns.isin(initialParadigmesColumns)].dropna(axis=1,how='all')\n",
    "if listeLexemes!=predictedParadigmes[\"lexeme\"].tolist():\n",
    "    print \"PB avec la liste des lexèmes prédits\"\n",
    "if set(initialParadigmesColumns)!=set(predictedParadigmes.columns.tolist()):\n",
    "    print \"PB avec la liste des cases prédites\"\n",
    "    print predictedParadigmes.columns.tolist()\n",
    "    print initialParadigmesColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedForms=pd.melt(predictedParadigmes[predictedParadigmes[\"lexeme\"].isin(listeLexemes)],id_vars=[\"lexeme\"]).dropna()\n",
    "predictedForms[\"lexeme-case\"]=predictedForms[\"lexeme\"]+\"-\"+predictedForms[\"variable\"]\n",
    "predictedForms.drop(labels=[\"lexeme\",\"variable\"],axis=1,inplace=True)\n",
    "predictedForms.set_index([\"lexeme-case\"],inplace=True)\n",
    "predictedFormsIndex=predictedForms.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(referenceFile,\"rb\") as input:\n",
    "#     lexiqueGold=pickle.load(input)\n",
    "\n",
    "lexiqueGold=pd.read_pickle(referenceFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u\"abstraire\", u\"accroire\", u\"adirer\", u\"advenir\", u\"apparoir\", u\"assavoir\", u\"avenir\", u\"becter\", u\"béer\", u\"bienvenir\", u\"braire\", u\"bruire\", u\"chaloir\", u\"choir\", u\"clore\", u\"comparoir\", u\"contrefoutre\", u\"courre\", u\"déchoir\", u\"déclore\", u\"dépourvoir\", u\"discontinuer\", u\"dissoudre\", u\"distraire\", u\"douer\", u\"échoir\", u\"éclore\", u\"enclore\", u\"endêver\", u\"ensuivre\", u\"ester\", u\"extraire\", u\"faillir\", u\"férir\", u\"forclore\", u\"forfaire\", u\"foutre\", u\"frire\", u\"gésir\", u\"huir\", u\"impartir\", u\"issir\", u\"malfaire\", u\"méfaire\", u\"messeoir\", u\"moufeter\", u\"moufter\", u\"mourir\", u\"oindre\", u\"ouïr\", u\"paître\", u\"parfaire\", u\"poindre\", u\"quérir\", u\"raire\", u\"rassir\", u\"ravoir\", u\"reclure\", u\"revaloir\", u\"saillir\", u\"seoir\", u\"sourdre\", u\"soustraire\", u\"stupéfaire\", u\"surfaire\", u\"titre\", u\"traire\", u\"urger\"]\n"
     ]
    }
   ],
   "source": [
    "boyeDefectifs=u\"abstraire accroire adirer advenir apparoir assavoir\".split(\" \")\n",
    "boyeDefectifs+=u\"avenir becter béer bienvenir braire bruire chaloir\".split(\" \")\n",
    "boyeDefectifs+=u\"choir clore comparoir contrefoutre courre déchoir\".split(\" \")\n",
    "boyeDefectifs+=u\"déclore dépourvoir discontinuer dissoudre\".split(\" \")\n",
    "boyeDefectifs+=u\"distraire douer échoir éclore\".split(\" \")\n",
    "boyeDefectifs+=u\"enclore endêver ensuivre ester extraire faillir\".split(\" \")\n",
    "boyeDefectifs+=u\"férir forclore forfaire foutre frire gésir\".split(\" \")\n",
    "boyeDefectifs+=u\"huir impartir issir malfaire méfaire messeoir\".split(\" \")\n",
    "boyeDefectifs+=u\"moufeter moufter mourir oindre ouïr paître parfaire\".split(\" \")\n",
    "boyeDefectifs+=u\"poindre quérir raire rassir ravoir reclure revaloir\".split(\" \")\n",
    "boyeDefectifs+=u\"saillir seoir sourdre soustraire stupéfaire\".split(\" \")\n",
    "boyeDefectifs+=u\"surfaire titre traire urger\".split(\" \")\n",
    "print '[u\"'+'\", u\"'.join(boyeDefectifs)+'\"]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "defectifsParadigmes=predictedParadigmes[predictedParadigmes[\"lexeme\"].isin(boyeDefectifs)]\n",
    "initialDefectifs=initialParadigmes[initialParadigmes[\"lexeme\"].isin(boyeDefectifs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codage phonétique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cSAMPA=u\"SZNJêôârEHO692\"\n",
    "cIPA=[u\"ʃ\",u\"ʒ\",u\"ŋ\",u\"ɲ\",u\"ɛ̃\",u\"ɔ̃\",u\"ɑ̃\",u\"ʁ\",u\"ɛ\",u\"ɥ\",u\"ɔ\",u\"ə\",u\"œ\",u\"ø\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S Z N J ê ô â r E H O 6 9 2\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "def listerUnicode(chaine):\n",
    "    result=[]\n",
    "    comb=False\n",
    "    prec=u\"\"\n",
    "    for char in chaine:\n",
    "        print char,\n",
    "        if unicodedata.combining(char):\n",
    "            result.append(prec+char)\n",
    "            prec=\"\"\n",
    "        else:\n",
    "            result.append(prec)\n",
    "            prec=char\n",
    "    result.append(prec)\n",
    "    return [r for r in result if r!=\"\"]\n",
    "\n",
    "ipaIn = listerUnicode(cSAMPA)\n",
    "ipaOut= cIPA\n",
    "toipa = dict(zip(ipaIn, ipaOut))\n",
    "\n",
    "def coderIPA(chaine,table=toipa):\n",
    "    result=chaine\n",
    "    for k in table:\n",
    "        result=result.replace(k,table[k])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular de conjugaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "etColours=[\"orange\",\n",
    "           \"brown!50\",\n",
    "           \"brown\",\n",
    "           \"blue!10\",\n",
    "           \"yellow!50\",\n",
    "           \"blue!25\",\n",
    "           \"teal!50\",\n",
    "           \"blue!50\",\n",
    "           \"cyan!50\",\n",
    "           \"lime\",\n",
    "           \"pink\",\n",
    "           \"magenta!50\",\n",
    "          ]\n",
    "etCells=[\n",
    "    [\"pi1P\",\"pi2P\"]+[\"ii\"+p+n for p in \"123\" for n in \"SP\"],\n",
    "    [\"pi3P\"],\n",
    "    [\"pi\"+p+\"S\" for p in \"123\"],\n",
    "    [\"pP\"],\n",
    "    [\"pI2S\"],\n",
    "    [\"pI1P\",\"pI2P\"],\n",
    "    [\"ps\"+p+\"S\" for p in \"123\"]+[\"ps3P\"],\n",
    "    [\"ps1P\",\"ps2P\"],\n",
    "    [\"inf\"],\n",
    "    [\"fi\"+p+n for p in \"123\" for n in \"SP\"]+[\"pc\"+p+n for p in \"123\" for n in \"SP\"],\n",
    "    [\"ai\"+p+n for p in \"123\" for n in \"SP\"]+[\"is\"+p+n for p in \"123\" for n in \"SP\"],\n",
    "    [\"pp\"+g+n for g in \"MF\" for n in \"SP\"],\n",
    "        ]\n",
    "tabTemps={\n",
    "    \"pi\":u\"ind. prs\",\n",
    "    \"ii\":u\"ind. ipf\",\n",
    "    \"ai\":u\"ind. ps\",\n",
    "    \"fi\":u\"ind. fut\",\n",
    "    \"ps\":u\"subj. prs\",\n",
    "    \"is\":u\"subj. ipf\",\n",
    "    \"pc\":u\"cond. prs\",\n",
    "    \"pI\":u\"imper. prs\",\n",
    "    \"inf\":u\"non-fini\"\n",
    "    }\n",
    "dictEtColours={}\n",
    "for nET,ET in enumerate(etCells):\n",
    "    for c in ET:\n",
    "        dictEtColours[c]=etColours[nET]\n",
    "#dictEtColours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTabularParadigmeDF(lexeme,lDF,dictColours,title=\"\",coulLim=False, cat=\"V\",dictMorphomes={}):\n",
    "    row=lDF[lDF[\"lexeme\"]==lexeme.encode(\"utf8\")]\n",
    "    return makeTabularParadigme(row,dictColours,title=\"\",coulLim=False, cat=\"V\",dictMorphomes={},lexeme=lexeme)\n",
    "\n",
    "def makeTabularParadigme(row,dictColours,title=\"\",coulLim=False, cat=\"V\",dictMorphomes={},lexeme=\"\"):\n",
    "    tabular=[]\n",
    "    def makeValue(case):\n",
    "#        if len(row[case])>0 and len(row[case].values[0])>0:\n",
    "        if case in row and all(row[case].notnull()):\n",
    "            result=coderIPA(row[case].values[0])\n",
    "        elif dictMorphomes!={} and case in dictMorphomes:\n",
    "            altCase=dictMorphomes[case][0]\n",
    "            if len(row[altCase])>0 and len(row[altCase].values[0])>0:\n",
    "                result=coderIPA(row[altCase].values[0])\n",
    "            else:\n",
    "                result=\"?\"\n",
    "        else:\n",
    "            result=\"?\"\n",
    "        return result\n",
    "    \n",
    "    def makeLine6(tenseCode):\n",
    "        line=[tabTemps[tenseCode]]\n",
    "        for person in [per+nb for nb in [\"S\",\"P\"] for per in [\"1\",\"2\",\"3\"]]:\n",
    "            case=tenseCode+person\n",
    "            if case in dictColours:\n",
    "                line.append(r\"\\cellcolor{%s}%s\"%(dictColours[case],makeValue(case)))\n",
    "            else:\n",
    "                line.append(r\"\\cellcolor{%s}%s\"%(\"black\",makeValue(case)))\n",
    "        return r\" & \".join(line)+r\"\\\\\"\n",
    "\n",
    "    def makeLine3(tenseCode):\n",
    "        line=[tabTemps[tenseCode]]\n",
    "        for person in [per+nb for nb in [\"S\",\"P\"] for per in [\"1\",\"2\",\"3\"]]:\n",
    "            if person in [\"2S\",\"1P\",\"2P\"]:\n",
    "                case=tenseCode+person\n",
    "                if case in dictColours:\n",
    "                    line.append(r\"\\cellcolor{%s}%s\"%(dictColours[case],makeValue(case)))\n",
    "                else:\n",
    "                    line.append(r\"\\cellcolor{%s}%s\"%(\"black\",makeValue(case)))\n",
    "#                line.append(r\"\\cellcolor{%s}%s\"%(dictColours[case],case))\n",
    "            else:\n",
    "                line.append(r\"---\")\n",
    "        return r\" & \".join(line)+r\"\\\\\"\n",
    "    \n",
    "    def makeLineNF():\n",
    "        line=[\"non-fini\"]\n",
    "        for case in [\"inf\",\"pP\",\"ppMS\",\"ppMP\",\"ppFS\",\"ppFP\"]:\n",
    "            if case in dictColours:\n",
    "                line.append(r\"\\cellcolor{%s}%s\"%(dictColours[case],makeValue(case)))\n",
    "            else:\n",
    "                line.append(r\"\\cellcolor{%s}%s\"%(\"black\",makeValue(case)))\n",
    "#            line.append(r\"\\cellcolor{%s}%s\"%(dictColours[case],case))\n",
    "        return r\" & \".join(line)+r\"\\\\\"\n",
    "\n",
    "    def makeLineMF(nombre):\n",
    "        line=[]\n",
    "        for genre in \"mf\":\n",
    "            case=genre+nombre\n",
    "            if case in dictColours:\n",
    "                line.append(r\"\\cellcolor{%s}%s\"%(dictColours[case],makeValue(case)))\n",
    "            else:\n",
    "                line.append(r\"\\cellcolor{%s}%s\"%(\"black\",makeValue(case)))\n",
    "        return r\" & \".join(line)+r\"\\\\\"\n",
    "    \n",
    "    def makeLineCoulLim():\n",
    "        line=[]\n",
    "        for numLimite,limite in enumerate(listLimites):\n",
    "            line.append(r\"\\cellcolor{%s}%s\"%(listLimCoul[numLimite],\"$<$\"+str(limite)))\n",
    "        return r\"\\hline\\hline \"+r\" & \".join(line)+r\"\\\\\"\n",
    "        \n",
    "    if cat==\"V\":\n",
    "        top=[\n",
    "            r\"\\begin{center}\",\n",
    "            r\"\\begin{tabular}{ccccccc}\",\n",
    "            r\"\\toprule\",\n",
    "            \" & \".join([ur\"\\textsc{%s}\"%lexeme]+[p+n for n in [\"sg\",\"pl\"] for p in \"123\" ])+r\"\\\\\",\n",
    "            r\"\\midrule\"\n",
    "            ]\n",
    "        bottom=[\n",
    "            r\"\\bottomrule\",\n",
    "            r\"\\end{tabular}\\\\\",\n",
    "            title,\n",
    "            r\"\\end{center}\",\n",
    "            r\"\\bigskip\",\n",
    "            r\"\"\n",
    "            ]\n",
    "        tabular.append(\"\\n\".join(top))\n",
    "        for tenseCode in [\"pi\",\"ii\",\"fi\",\"pc\", \"ps\",\"ai\", \"is\"]:\n",
    "            tabular.append(makeLine6(tenseCode))\n",
    "        tabular.append(makeLine3(\"pI\"))\n",
    "        tabular.append(u\"\\midrule\\n\")\n",
    "        tabular.append(ur\"& inf. & part. prés. & \\multicolumn{4}{c}{part. passé}\\\\\")\n",
    "        tabular.append(makeLineNF())\n",
    "    elif cat==\"A\":\n",
    "        top=[\n",
    "            r\"\\begin{center}\",\n",
    "            r\"\\begin{tabular}{cc}\",\n",
    "            r\"\\toprule\"\n",
    "            ]\n",
    "        bottom=[\n",
    "            r\"\\bottomrule\",\n",
    "            r\"\\end{tabular}\\\\\",\n",
    "            title,\n",
    "            r\"\\end{center}\",\n",
    "#            r\"\\bigskip\",\n",
    "            r\"\"\n",
    "            ]\n",
    "        tabular.append(\"\\n\".join(top))\n",
    "        for number in \"sp\":\n",
    "            tabular.append(makeLineMF(number))\n",
    "    if coulLim:\n",
    "        tabular.append(makeLineCoulLim())\n",
    "    tabular.append(\"\\n\".join(bottom))\n",
    "    return \"\\n\".join(tabular)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création des tableaux de conjugaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "defectifsTabular=[]\n",
    "for v in defectifsParadigmes[\"lexeme\"].tolist():\n",
    "    defectifsTabular.append(makeTabularParadigmeDF(v,initialDefectifs,dictEtColours))\n",
    "    defectifsTabular.append(makeTabularParadigmeDF(v,defectifsParadigmes,dictEtColours))\n",
    "pyperclip.copy(\"\\n\".join(defectifsTabular))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
