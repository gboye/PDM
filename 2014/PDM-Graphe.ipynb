{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Importation des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import PDM8\n",
    "from PDM8 import *\n",
    "import pickle\n",
    "from lxml.html import builder as E\n",
    "import string\n",
    "from IPython.core.display import HTML,display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PDM8.seuilDistribution=0.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('Regles.pkl', 'rb') as input:\n",
    "    PDM8.analyse = pickle.load(input)\n",
    "with open('Classes.pkl', 'rb') as input:\n",
    "    PDM8.classification = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finisɑ̃ finisɔ̃ pɛ̃tɑ̃\n"
     ]
    }
   ],
   "source": [
    "bdlexIn=[u\"S\",u\"J\",u\"E\",u\"ê\",u\"â\",u\"ô\",u\"6\"]\n",
    "ipaOut=[u\"ʃ\",u\"ɲ\",u\"e\",u\"ɛ̃\",u\"ɑ̃\",u\"ɔ̃\",u\"ə\"]\n",
    "def recoder(chaine):\n",
    "    if isinstance(chaine,str):\n",
    "        chaine=chaine.decode(\"utf8\")\n",
    "    for n,element in enumerate(bdlexIn):\n",
    "        chaine=chaine.replace(element,ipaOut[n])\n",
    "    return chaine\n",
    "print recoder(u\"finisâ finisô pêtâ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def html_table(table):\n",
    "    htmlTable=[]\n",
    "    htmlTable.append('<table border=\"1\"><tbody>')\n",
    "    for ligne in table:\n",
    "        htmlTable.append('  <tr>')\n",
    "        for element in ligne:\n",
    "            htmlTable.append('    <td>%s</td>'%element)\n",
    "        htmlTable.append('  </tr>')\n",
    "    htmlTable.append('<tbody></table>')\n",
    "    return \"\\n\".join(htmlTable)\n",
    "    \n",
    "class ConjugaisonTableau:\n",
    "    def __init__(self,nom,liste):\n",
    "        self.nom=nom\n",
    "        self.finies=[]\n",
    "        self.nonfinies=[]\n",
    "        tradPersonnesFinies={\"1\":\"1SG\",\"2\":\"2SG\",\"3\":\"3SG\",\"4\":\"1PL\",\"5\":\"2PL\",\"6\":\"3PL\"}\n",
    "#        personnesFinies=tradPersonnesFinies.keys()\n",
    "        personnesFinies=[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"]\n",
    "        enteteFinies=[\"temps\"]\n",
    "        for personne in personnesFinies:\n",
    "            enteteFinies.append(tradPersonnesFinies[personne])\n",
    "        self.finies.append(enteteFinies)\n",
    "#        self.tableau.append(enteteTableau)\n",
    "        tradTempsFinies={\"prs\":\"present\",\"ipf\":\"imperfective\",\"pst\":\"past\",\"fut\":\"future\",\n",
    "                     \"sbjv\":\"present subj.\",\"pst.sbj\":\"imperfective subj.\",\n",
    "                     \"cond\":\"conditional\",\n",
    "                     \"imp\":\"imperative\"}\n",
    "        tempsFinies=[\"prs\",\"ipf\",\"pst\",\"fut\",\"sbjv\",\"pst.sbj\",\"cond\",\"imp\"]\n",
    "        tradNonFinies={\"inf\":\"infinitive\",\"prs.pcp\":\"present part.\",\"pst.pcp\":\"past part.\"}\n",
    "        nonFinies=[\"inf\",\"prs.pcp\"\"pst.pcp\"]\n",
    "#        enteteNonFinies=tradNonFinies.values()\n",
    "        tempTableau=[]\n",
    "        for temps in tempsFinies:\n",
    "            ligne=[]\n",
    "            for personne in personnesFinies:\n",
    "                ligne.append(\"\")\n",
    "            tempTableau.append(ligne)\n",
    "        for element in liste:\n",
    "            case,forme=element.split(\"-\")\n",
    "            if case[-1] in \"123456\":\n",
    "#                print case\n",
    "                temps,personne=case.rsplit(\".\",1)\n",
    "                numTemps=tempsFinies.index(temps)\n",
    "                numPers=personnesFinies.index(personne)\n",
    "                tempTableau[numTemps][numPers]=recoder(forme)\n",
    "            else:\n",
    "                self.nonfinies.append([case,recoder(forme)])\n",
    "        for n,ligne in enumerate(tempTableau):\n",
    "#            print n,ligne,[tempsFinies[n]]+ligne\n",
    "            self.finies.append([tradTempsFinies[tempsFinies[n]]]+ligne)\n",
    "            \n",
    "            \n",
    "def prettyClique(clique):\n",
    "    '''\n",
    "    remplir un dict tableau pour afficher un paradigme\n",
    "    '''\n",
    "    tableau={'NF':{}}\n",
    "    for element in sorted(clique):\n",
    "        case,forme=element.split(\"-\")\n",
    "        try:\n",
    "            temps,personne=case.split(\".\")\n",
    "            if personne in \"123456\":\n",
    "                if not temps in tableau:\n",
    "                    tableau[temps]={}\n",
    "                tableau[temps][personne]=forme\n",
    "            else:\n",
    "                tableau['NF'][temps]={personne:forme}\n",
    "        except:\n",
    "            tableau['NF'][case]=forme\n",
    "#    pretty(tableau)\n",
    "        \n",
    "def prettyDict(d, indent=0):\n",
    "   for key, value in d.iteritems():\n",
    "      print '\\t' * indent + str(key)\n",
    "      if isinstance(value, dict):\n",
    "         prettyDict(value, indent+1)\n",
    "      elif isinstance(value, list):\n",
    "        for element in value:\n",
    "            print '\\t' * (indent+1) + (element)\n",
    "        print\n",
    "      else:\n",
    "         print '\\t' * (indent+1) + str(value)    \n",
    "                \n",
    "def faireCliques(lexical):\n",
    "    dataCliques={}\n",
    "    cliques=list(nx.algorithms.clique.find_cliques(lexical.graphe))\n",
    "    dataCliques[\"nb\"]=len(cliques)\n",
    "    nMaxClique=0\n",
    "    tableaux=[]\n",
    "    for n,clique in enumerate(sorted(cliques,key=lambda x: len(x),reverse=True)):\n",
    "        total=0\n",
    "        for node in sorted(clique):\n",
    "            poids=lexical.graphe.node[node][\"weight\"]\n",
    "            total+=poids\n",
    "#        dataCliques[n]={\"taille\":len(clique),\"représentant\":clique[0],\"clique\":sorted(clique)}\n",
    "        conjugaison=ConjugaisonTableau(\"test\",sorted(clique))\n",
    "        tableFinies=html_table(conjugaison.finies)\n",
    "        tableNonFinies=html_table(conjugaison.nonfinies)\n",
    "        tables=([lexeme.encode('utf8'),len(clique),total/len(clique)],tableFinies,tableNonFinies)\n",
    "        tableaux.append(tables)\n",
    "        if len(clique)>=nMaxClique:\n",
    "            nMaxClique=len(clique)\n",
    "            total=0\n",
    "            for node in sorted(clique):\n",
    "                poids=lexical.graphe.node[node][\"weight\"]\n",
    "                total+=poids\n",
    "#                print(node,poids)\n",
    "#            print (len(clique),clique[0])\n",
    "#            print (sorted(clique))\n",
    "#            prettyClique(clique)\n",
    "#            print (total/len(clique))\n",
    "#            print ()\n",
    "    return (cliques, tableaux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def faireGraphes(lexical):\n",
    "    lexical.calculerParadigme()\n",
    "    (cliques,tableaux)=faireCliques(lexical)\n",
    "#    return lexical, cliques, tableaux\n",
    "    nx.write_dot(lexical.graphe,prefixeLexeme+u\"graphe.dot\")\n",
    "#    nx.write_dot(lexical.digraphe,prefixeLexeme+u\"digraphe.dot\")\n",
    "    for n in range(len(cliques)):\n",
    "#        print (n)\n",
    "        digraphe=lexical.digraphe.subgraph(cliques[n])\n",
    "#        nx.write_dot(digraphe,prefixeLexeme+u\"clique%d.dot\"%n)\n",
    "    textHTML='<html><head>'\n",
    "    textHTML+='<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />'\n",
    "    textHTML+='<style>'\n",
    "    textHTML+='table {font-family:\"Lucida Sans Unicode\", \"Lucida Grande\", sans-serif}'\n",
    "    textHTML+='</style>'\n",
    "    textHTML+='</head><body>\\n'\n",
    "    for table in tableaux:\n",
    "        textHTML+=\"<center><b>\\n\"\n",
    "        for element in table[0]:\n",
    "            textHTML+=str(element)+\"\\n\"\n",
    "        textHTML+=\"</b>\\n\"\n",
    "        textHTML+=table[1].encode('utf8')\n",
    "        textHTML+=(table[2]+\"\\n\").encode('utf8')\n",
    "        textHTML+=\"</center><br/><br/>\\n\"\n",
    "    textHTML+=\"</body></html>\"\n",
    "    with open(prefixeLexeme+\"Cliques.html\", 'w') as output:\n",
    "        output.write(textHTML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lexique={\n",
    "            \"finir-INF\":{\"inf\":\"finir\"},\n",
    "            \"finir-PRS3\":{\"prs.3\":\"fini\"},\n",
    "            \"finir-PRS4\":{\"prs.4\":\"finisô\"},\n",
    "            \"finir-PRS34\":{\"prs.3\":\"fini\",\"prs.4\":\"finisô\"},\n",
    "            \"aboyer-INF\":{\"inf\":\"abwajE\"},\n",
    "            \"aboyer-PRS3\":{\"prs.3\":\"abwa\"},\n",
    "            \"aboyer-PRS4\":{\"prs.4\":\"abwajô\"},\n",
    "            \"aboyer-PRS66\":{\"prs.6\":[\"abwa\",\"abwaj\"]},\n",
    "            \"balayer-PRS4\":{\"prs.4\":\"balEjô\"},\n",
    "            \"cacher-IMP2\":{\"imp.2\":\"kaS\"},\n",
    "            \"avoir-PRS1\":{\"prs.1\":\"E\"},\n",
    "            \"suivre-PRS1\":{\"prs.1\":\"sHi\"},\n",
    "            \"bougre-INF\":{\"inf\":\"bugr\"},\n",
    "            \"jitre-INF\":{\"inf\":\"Zitr\"},\n",
    "            \"clore-INF\":{\"inf\":\"klor\"},\n",
    "            \"courir-INF\":{\"inf\":\"kurir\"},\n",
    "            \"distraire-INF\":{\"inf\":\"distrEr\"},\n",
    "            \"cahincaher-INF\":{\"inf\":\"kaêkaE\"},\n",
    "            \"fiche-PSTPCP\":{\"pst.pcp\":\"fiSy\"},\n",
    "            \"frire-PRS3\":{\"prs.3\":\"fri\"},\n",
    "            \"courir-FUT3\":{\"fut.3\":\"kurra\"},\n",
    "            \"battre-FUT3\":{\"fut.3\":\"batra\"},\n",
    "            \"peindre-FUT3\":{\"fut.3\":\"pêdra\"},\n",
    "            \"savoir-PRS2IMP2\":{\"prs.2\":\"sE\",\"imp.2\":\"saS\"},\n",
    "            \"savoir-IMP2\":{\"imp.2\":\"saS\"},\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lexique={\n",
    "#    \"casser-IMP2\":{\"imp.2\":\"kas\"},\n",
    "#    \"casser-PRS6\":{\"prs.6\":\"kas\"},    \n",
    "#    \"casser-SUBJ6\":{\"sbjv.6\":\"kas\"},   \n",
    "    \"aboyer-PRS3\":{\"prs.3\":\"abwa\"},\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aboyer-PRS3\n"
     ]
    }
   ],
   "source": [
    "PDM8.verbose=False\n",
    "for lexeme in lexique:\n",
    "    lexical=Paradigme()\n",
    "    prefixeLexeme=lexeme+\"-\"\n",
    "    print lexeme\n",
    "    cases={}\n",
    "    for case in lexique[lexeme]:\n",
    "        cases[case]=Case(case)\n",
    "        if isinstance(lexique[lexeme][case],list):\n",
    "            for element in lexique[lexeme][case]:\n",
    "                cases[case].addForm(FormeCoef(element.decode('utf8'),1))\n",
    "        else:\n",
    "            cases[case].addForm(FormeCoef(lexique[lexeme][case].decode('utf8'),1))\n",
    "    for case in cases:\n",
    "        lexical.addEntree(cases[case])\n",
    "    faireGraphes(lexical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rCliques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for element in lexical.graphe.nodes():\n",
    "    print lexical.graphe.node[element]\n",
    "#    nom=element.encode(\"utf8\")\n",
    "    print element, type(element)==str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hiver', u'E~tE~']\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "#from unidecode import unidecode\n",
    "G=nx.Graph()\n",
    "G.add_node(\"hiver\", label=\"été\")\n",
    "G.add_edge(u\"E~tE~\",u\"hiver\")\n",
    "G.node[\"hiver\"]\n",
    "print G.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode characters in position 31-32: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-640e688543b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mP\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"TEST.dot\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<decorator-gen-322>\u001b[0m in \u001b[0;36mwrite_dot\u001b[0;34m(G, path)\u001b[0m\n",
      "\u001b[0;32m/Users/gilles/anaconda/lib/python2.7/site-packages/networkx/utils/decorators.pyc\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# Finally, we call the original function, making sure to close the fobj.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclose_fobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/gilles/anaconda/lib/python2.7/site-packages/networkx/drawing/nx_pydot.pyc\u001b[0m in \u001b[0;36mwrite_dot\u001b[0;34m(G, path)\u001b[0m\n\u001b[1;32m     38\u001b[0m                           \"http://code.google.com/p/pydot/\")\n\u001b[1;32m     39\u001b[0m     \u001b[0mP\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode characters in position 31-32: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "P=nx.write_dot(G,\"TEST.dot\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
