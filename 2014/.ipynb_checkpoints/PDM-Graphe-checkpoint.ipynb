{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Importation des modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import PDM\n",
    "from PDM import *\n",
    "import pickle\n",
    "from lxml.html import builder as E\n",
    "import string\n",
    "from IPython.core.display import HTML,display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PDM.seuilDistribution=0.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('Regles.pkl', 'rb') as input:\n",
    "    PDM.analyse = pickle.load(input)\n",
    "with open('Classes.pkl', 'rb') as input:\n",
    "    PDM.classification = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ceb7b90b21d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mchaine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchaine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mipaOut\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mchaine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu\"finisâ finisô pêtâ\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-ceb7b90b21d8>\u001b[0m in \u001b[0;36mrecoder\u001b[0;34m(chaine)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchaine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchaine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mchaine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchaine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbdlexIn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mchaine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchaine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mipaOut\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "bdlexIn=[u\"S\",u\"J\",u\"E\",u\"ê\",u\"â\",u\"ô\",u\"6\"]\n",
    "ipaOut=[u\"ʃ\",u\"ɲ\",u\"e\",u\"ɛ̃\",u\"ɑ̃\",u\"ɔ̃\",u\"ə\"]\n",
    "def recoder(chaine):\n",
    "    if isinstance(chaine,str):\n",
    "        chaine=chaine.decode(\"utf8\")\n",
    "    for n,element in enumerate(bdlexIn):\n",
    "        chaine=chaine.replace(element,ipaOut[n])\n",
    "    return chaine\n",
    "print recoder(u\"finisâ finisô pêtâ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def html_table(table):\n",
    "    htmlTable=[]\n",
    "    htmlTable.append('<table border=\"1\"><tbody>')\n",
    "    for ligne in table:\n",
    "        htmlTable.append('  <tr>')\n",
    "        for element in ligne:\n",
    "            htmlTable.append('    <td>%s</td>'%element)\n",
    "        htmlTable.append('  </tr>')\n",
    "    htmlTable.append('<tbody></table>')\n",
    "    return \"\\n\".join(htmlTable)\n",
    "    \n",
    "class ConjugaisonTableau:\n",
    "    def __init__(self,nom,liste):\n",
    "        self.nom=nom\n",
    "        self.finies=[]\n",
    "        self.nonfinies=[]\n",
    "        tradPersonnesFinies={\"1\":\"1SG\",\"2\":\"2SG\",\"3\":\"3SG\",\"4\":\"1PL\",\"5\":\"2PL\",\"6\":\"3PL\"}\n",
    "#        personnesFinies=tradPersonnesFinies.keys()\n",
    "        personnesFinies=[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\"]\n",
    "        enteteFinies=[\"temps\"]\n",
    "        for personne in personnesFinies:\n",
    "            enteteFinies.append(tradPersonnesFinies[personne])\n",
    "        self.finies.append(enteteFinies)\n",
    "#        self.tableau.append(enteteTableau)\n",
    "        tradTempsFinies={\"prs\":\"present\",\"ipf\":\"imperfective\",\"pst\":\"past\",\"fut\":\"future\",\n",
    "                     \"sbjv\":\"present subj.\",\"pst.sbj\":\"imperfective subj.\",\n",
    "                     \"cond\":\"conditional\",\n",
    "                     \"imp\":\"imperative\"}\n",
    "        tempsFinies=[\"prs\",\"ipf\",\"pst\",\"fut\",\"sbjv\",\"pst.sbj\",\"cond\",\"imp\"]\n",
    "        tradNonFinies={\"inf\":\"infinitive\",\"prs.pcp\":\"present part.\",\"pst.pcp\":\"past part.\"}\n",
    "        nonFinies=[\"inf\",\"prs.pcp\"\"pst.pcp\"]\n",
    "#        enteteNonFinies=tradNonFinies.values()\n",
    "        tempTableau=[]\n",
    "        for temps in tempsFinies:\n",
    "            ligne=[]\n",
    "            for personne in personnesFinies:\n",
    "                ligne.append(\"\")\n",
    "            tempTableau.append(ligne)\n",
    "        for element in liste:\n",
    "            case,forme=element.split(\"-\")\n",
    "            if case[-1] in \"123456\":\n",
    "#                print case\n",
    "                temps,personne=case.rsplit(\".\",1)\n",
    "                numTemps=tempsFinies.index(temps)\n",
    "                numPers=personnesFinies.index(personne)\n",
    "                tempTableau[numTemps][numPers]=recoder(forme)\n",
    "            else:\n",
    "                self.nonfinies.append([case,recoder(forme)])\n",
    "        for n,ligne in enumerate(tempTableau):\n",
    "#            print n,ligne,[tempsFinies[n]]+ligne\n",
    "            self.finies.append([tradTempsFinies[tempsFinies[n]]]+ligne)\n",
    "            \n",
    "            \n",
    "def prettyClique(clique):\n",
    "    '''\n",
    "    remplir un dict tableau pour afficher un paradigme\n",
    "    '''\n",
    "    tableau={'NF':{}}\n",
    "    for element in sorted(clique):\n",
    "        case,forme=element.split(\"-\")\n",
    "        try:\n",
    "            temps,personne=case.split(\".\")\n",
    "            if personne in \"123456\":\n",
    "                if not temps in tableau:\n",
    "                    tableau[temps]={}\n",
    "                tableau[temps][personne]=forme\n",
    "            else:\n",
    "                tableau['NF'][temps]={personne:forme}\n",
    "        except:\n",
    "            tableau['NF'][case]=forme\n",
    "#    pretty(tableau)\n",
    "        \n",
    "def prettyDict(d, indent=0):\n",
    "   for key, value in d.iteritems():\n",
    "      print '\\t' * indent + str(key)\n",
    "      if isinstance(value, dict):\n",
    "         prettyDict(value, indent+1)\n",
    "      elif isinstance(value, list):\n",
    "        for element in value:\n",
    "            print '\\t' * (indent+1) + (element)\n",
    "        print\n",
    "      else:\n",
    "         print '\\t' * (indent+1) + str(value)    \n",
    "                \n",
    "def faireCliques(lexical):\n",
    "    dataCliques={}\n",
    "    cliques=list(nx.algorithms.clique.find_cliques(lexical.graphe))\n",
    "    dataCliques[\"nb\"]=len(cliques)\n",
    "    nMaxClique=0\n",
    "    tableaux=[]\n",
    "    for n,clique in enumerate(sorted(cliques,key=lambda x: len(x),reverse=True)):\n",
    "        total=0\n",
    "        for node in sorted(clique):\n",
    "            poids=lexical.graphe.node[node][\"weight\"]\n",
    "            total+=poids\n",
    "#        dataCliques[n]={\"taille\":len(clique),\"représentant\":clique[0],\"clique\":sorted(clique)}\n",
    "        conjugaison=ConjugaisonTableau(\"test\",sorted(clique))\n",
    "        tableFinies=html_table(conjugaison.finies)\n",
    "        tableNonFinies=html_table(conjugaison.nonfinies)\n",
    "        tables=([lexeme.encode('utf8'),len(clique),total/len(clique)],tableFinies,tableNonFinies)\n",
    "        tableaux.append(tables)\n",
    "        if len(clique)>=nMaxClique:\n",
    "            nMaxClique=len(clique)\n",
    "            total=0\n",
    "            for node in sorted(clique):\n",
    "                poids=lexical.graphe.node[node][\"weight\"]\n",
    "                total+=poids\n",
    "#                print(node,poids)\n",
    "#            print (len(clique),clique[0])\n",
    "#            print (sorted(clique))\n",
    "#            prettyClique(clique)\n",
    "#            print (total/len(clique))\n",
    "#            print ()\n",
    "    return (cliques, tableaux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def faireGraphes(lexical):\n",
    "    lexical.calculerParadigme()\n",
    "    (cliques,tableaux)=faireCliques(lexical)\n",
    "# return lexical\n",
    "    nx.write_dot(lexical.graphe,prefixeLexeme+u\"graphe.dot\", encoding=\"utf8\")\n",
    "    nx.write_dot(lexical.digraphe,prefixeLexeme+u\"digraphe.dot\")\n",
    "    for n in range(len(cliques)):\n",
    "#        print (n)\n",
    "        digraphe=lexical.digraphe.subgraph(cliques[n])\n",
    "        nx.write_dot(digraphe,prefixeLexeme+u\"clique%d.dot\"%n)\n",
    "    textHTML='<html><head>'\n",
    "    textHTML+='<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />'\n",
    "    textHTML+='<style>'\n",
    "    textHTML+='table {font-family:\"Lucida Sans Unicode\", \"Lucida Grande\", sans-serif}'\n",
    "    textHTML+='</style>'\n",
    "    textHTML+='</head><body>\\n'\n",
    "    for table in tableaux:\n",
    "        textHTML+=\"<center><b>\\n\"\n",
    "        for element in table[0]:\n",
    "            textHTML+=str(element)+\"\\n\"\n",
    "        textHTML+=\"</b>\\n\"\n",
    "        textHTML+=table[1].encode('utf8')\n",
    "        textHTML+=(table[2]+\"\\n\").encode('utf8')\n",
    "        textHTML+=\"</center><br/><br/>\\n\"\n",
    "    textHTML+=\"</body></html>\"\n",
    "    with open(prefixeLexeme+\"Cliques.html\", 'w') as output:\n",
    "        output.write(textHTML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lexique={\n",
    "            \"finir-INF\":{\"inf\":\"finir\"},\n",
    "            \"finir-PRS3\":{\"prs.3\":\"fini\"},\n",
    "            \"finir-PRS4\":{\"prs.4\":\"finisô\"},\n",
    "            \"finir-PRS34\":{\"prs.3\":\"fini\",\"prs.4\":\"finisô\"},\n",
    "            \"aboyer-INF\":{\"inf\":\"abwajE\"},\n",
    "            \"aboyer-PRS3\":{\"prs.3\":\"abwa\"},\n",
    "            \"aboyer-PRS4\":{\"prs.4\":\"abwajô\"},\n",
    "            \"aboyer-PRS66\":{\"prs.6\":[\"abwa\",\"abwaj\"]},\n",
    "            \"balayer-PRS4\":{\"prs.4\":\"balEjô\"},\n",
    "            \"cacher-IMP2\":{\"imp.2\":\"kaS\"},\n",
    "            \"avoir-PRS1\":{\"prs.1\":\"E\"},\n",
    "            \"suivre-PRS1\":{\"prs.1\":\"sHi\"},\n",
    "            \"bougre-INF\":{\"inf\":\"bugr\"},\n",
    "            \"jitre-INF\":{\"inf\":\"Zitr\"},\n",
    "            \"clore-INF\":{\"inf\":\"klor\"},\n",
    "            \"courir-INF\":{\"inf\":\"kurir\"},\n",
    "            \"distraire-INF\":{\"inf\":\"distrEr\"},\n",
    "            \"cahincaher-INF\":{\"inf\":\"kaêkaE\"},\n",
    "            \"fiche-PSTPCP\":{\"pst.pcp\":\"fiSy\"},\n",
    "            \"frire-PRS3\":{\"prs.3\":\"fri\"},\n",
    "            \"courir-FUT3\":{\"fut.3\":\"kurra\"},\n",
    "            \"battre-FUT3\":{\"fut.3\":\"batra\"},\n",
    "            \"peindre-FUT3\":{\"fut.3\":\"pêdra\"},\n",
    "            \"savoir-PRS2IMP2\":{\"prs.2\":\"sE\",\"imp.2\":\"saS\"},\n",
    "            \"savoir-IMP2\":{\"imp.2\":\"saS\"},\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lexique={\"TEST\":{\"imp.2\":\"saS\"},}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for lexeme in lexique:\n",
    "    lexical=Paradigme()\n",
    "    prefixeLexeme=lexeme+\"-\"\n",
    "    print lexeme\n",
    "    cases={}\n",
    "    for case in lexique[lexeme]:\n",
    "        cases[case]=Case(case)\n",
    "        if isinstance(lexique[lexeme][case],list):\n",
    "            for element in lexique[lexeme][case]:\n",
    "                cases[case].addForm(FormeCoef(element.decode('utf8'),1))\n",
    "        else:\n",
    "            cases[case].addForm(FormeCoef(lexique[lexeme][case].decode('utf8'),1))\n",
    "    for case in cases:\n",
    "        lexical.addEntree(cases[case])\n",
    "    result=faireGraphes(lexical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lexical.graphe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    m=nx.drawing.write_dot.__module__\n",
    "except:\n",
    "    print()\n",
    "    print(\"pygraphviz or pydot were not found \")\n",
    "    print(\"see http://networkx.github.io/documentation/latest/reference/drawing.html for info\")\n",
    "    print()\n",
    "    raise\n",
    "\n",
    "print(\"using module\", m)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
