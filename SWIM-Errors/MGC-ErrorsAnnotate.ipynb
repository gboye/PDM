{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colorer les résultats de SWIM\n",
    "Pour voir la distribution des résultats de la génération par SWIM, les cases sont colorées en fonction de leur valeur :\n",
    "- bleu pour les cases dans l'échantillon de départ\n",
    "- vert pour les cases bien générées\n",
    "- rouge pour les erreurs\n",
    "- orange pour les sur-générations\n",
    "- jaune pour les cases non-générées\n",
    "- blanc pour les cases vides dans le Gold\n",
    "\n",
    "Les résultats *paradigmes-Swim?.csv* sont pris dans le répertoire où ils ont été calculés. Les annotations sont écrites dans des fichiers .xlsx correspondants dans le répertoire *HDR/Longitudinales/XLS*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S Z N J ê ô â r E H O 6 9 2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml,re,pyperclip\n",
    "import EspacesThematiques as ET\n",
    "from EspacesThematiques import *\n",
    "from FrenchPhonology import makeFrench,setNeutralisation\n",
    "\n",
    "debug=False\n",
    "import datetime,glob\n",
    "def dateheure(f=\"%y%m%d%H%M\"):\n",
    "    return datetime.datetime.utcnow().strftime(f) # %y%m%d%H%M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:30\n"
     ]
    }
   ],
   "source": [
    "cases=etCols\n",
    "print dateheure(\"%H:%M\")\n",
    "phonologicalMap=\"NS\"\n",
    "neutralise=setNeutralisation(phonologicalMap)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from IPython.html.widgets import FloatProgress\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "repCSV=\"/Users/gilles/pCloud Drive/FOD/GB/2015-Data/Longitudinales/\"\n",
    "repXLS=\"/Users/gilles/ownCloud/Recherche/Boye/HDR/Memoire/Longitudinales/PhonoMap-X-NS/\"\n",
    "fichiersPar=glob.glob(repCSV+\"*paradigmes*.csv\")\n",
    "fichiersOG=glob.glob(repCSV+\"*overGeneration*.csv\")\n",
    "fichiersFP=glob.glob(repCSV+\"*diffForms*.csv\")\n",
    "fichiersUG=glob.glob(repCSV+\"*underGeneration*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findFichier(patron,fichiers):\n",
    "    candidats=[]\n",
    "    for sample in fichiers:\n",
    "        m=re.match(patron,sample)\n",
    "        if m:\n",
    "            candidats.append(m.group(1))\n",
    "    if len(candidats)==1:\n",
    "        return candidats[0]\n",
    "    else:\n",
    "        print \"PB pas de nom unique correspondant\",candidats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorCells(row):\n",
    "    result=[\"\"]\n",
    "    lexeme=row[\"lexeme\"]\n",
    "    for case in casesPar:\n",
    "        if all(row[case]==dfPar.loc[dfPar.lexeme==lexeme,case]):\n",
    "            result.append('background-color: blue')\n",
    "        elif u\"%s-%s\"%(lexeme,case) in dfFP[\"lexeme-case\"].tolist():\n",
    "            formeBrute=dfFP[dfFP[\"lexeme-case\"]==u\"%s-%s\"%(lexeme,case)][\"value\"].values[0]\n",
    "            formeGold=dfFP[dfFP[\"lexeme-case\"]==u\"%s-%s\"%(lexeme,case)][\"right\"].values[0]\n",
    "            if \",\" not in formeGold:\n",
    "#                print formeBrute,formeGold\n",
    "                if makeFrench(formeBrute,neutralise)!=makeFrench(formeGold,neutralise):\n",
    "                    result.append('background-color: red')\n",
    "                else:\n",
    "                    result.append('background-color: #90EE90')\n",
    "            else:\n",
    "                if makeFrench(formeBrute,neutralise) in formeGold.split(\",\"):\n",
    "                    result.append('background-color: #FF00FF')\n",
    "                else:\n",
    "                    result.append('background-color: #8B0000')                \n",
    "        elif u\"%s-%s\"%(lexeme,case) in dfOG[\"lexeme-case\"].tolist():        \n",
    "            result.append('background-color: orange')\n",
    "        elif u\"%s-%s\"%(lexeme,case) in dfUG[\"lexeme-case\"].tolist():        \n",
    "            result.append('background-color: yellow')\n",
    "        elif row[case]==row[case]:\n",
    "            result.append('background-color: green')\n",
    "        else:\n",
    "            result.append(\"\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"lecture\"></a>\n",
    "Liens :\n",
    "- [lecture erreurs](#lecture)\n",
    "- [Excel](#excel)\n",
    "\n",
    "### Lecture fichiers erreurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:30 29\n",
      "-Swim2 18:34\n",
      "\n",
      "18:34 30\n",
      "-Swim2 18:39\n",
      "\n",
      "18:39 31\n",
      "-Swim2 18:44\n",
      "\n",
      "18:44 32\n",
      "-Swim2 18:48\n",
      "\n",
      "18:48 33\n",
      "-Swim2 18:54\n",
      "\n",
      "18:54 34\n",
      "-Swim2 18:59\n",
      "\n",
      "18:59 35\n",
      "-Swim2 19:05\n",
      "\n",
      "19:05 36\n",
      "-Swim2 19:11\n",
      "\n",
      "19:11 37\n",
      "-Swim2 19:18\n",
      "\n",
      "19:18 38\n",
      "-Swim2 19:23\n",
      "\n",
      "19:23 39\n",
      "-Swim2 19:28\n",
      "\n",
      "19:28 40\n",
      "-Swim2 19:33\n",
      "\n",
      "19:33 41\n",
      "-Swim2 19:38\n",
      "\n",
      "19:38 42\n",
      "-Swim2 19:44\n",
      "\n",
      "19:44 43\n",
      "-Swim2 19:49\n",
      "\n",
      "19:49 44\n",
      "-Swim2 19:54\n",
      "\n",
      "19:54 45\n",
      "-Swim2 19:59\n",
      "\n",
      "19:59 46\n",
      "-Swim2 20:04\n",
      "\n",
      "20:04 47\n",
      "-Swim2 20:09\n",
      "\n",
      "20:09 48\n",
      "-Swim2 20:15\n",
      "\n",
      "20:15 49\n",
      "-Swim2 20:21\n",
      "\n",
      "20:21 50\n",
      "-Swim2 20:26\n",
      "\n",
      "20:26 51\n",
      "-Swim2 20:31\n",
      "\n",
      "20:31 52\n",
      "-Swim2 20:36\n",
      "\n",
      "20:36 53\n",
      "-Swim2 20:41\n",
      "\n",
      "20:41 54\n",
      "-Swim2 20:46\n",
      "\n",
      "20:46 55\n",
      "-Swim2 20:51\n",
      "\n",
      "20:51 56\n",
      "-Swim2 20:56\n",
      "\n",
      "20:56 57\n",
      "-Swim2 21:01\n",
      "\n",
      "21:01 58\n",
      "-Swim2 21:06\n",
      "\n",
      "21:06 59\n",
      "-Swim2 21:11\n",
      "\n",
      "21:11 60\n",
      "-Swim2 21:15\n",
      "\n",
      "21:15 61\n",
      "-Swim2 21:20\n",
      "\n",
      "21:20 62\n",
      "-Swim2 21:25\n",
      "\n",
      "21:25 63\n",
      "-Swim2 21:31\n",
      "\n",
      "21:31 64\n",
      "-Swim2 21:36\n",
      "\n",
      "21:36 65\n",
      "-Swim2 21:41\n",
      "\n",
      "21:41 66\n",
      "-Swim2 21:45\n",
      "\n",
      "21:45 67\n",
      "-Swim2 21:50\n",
      "\n",
      "21:50 68\n",
      "-Swim2 21:55\n",
      "\n",
      "21:55 69\n",
      "-Swim2 22:00\n",
      "\n",
      "22:00 70\n",
      "-Swim2 22:05\n",
      "\n",
      "22:05 71\n",
      "-Swim2 22:10\n",
      "\n",
      "22:10 72\n",
      "-Swim2 22:15\n",
      "\n",
      "22:15 73\n",
      "-Swim2 22:20\n",
      "\n",
      "22:20 74\n",
      "-Swim2 22:25\n",
      "\n",
      "22:25 75\n",
      "-Swim2 22:30\n",
      "\n",
      "22:30 76\n",
      "-Swim2 22:35\n",
      "\n",
      "22:35 77\n",
      "-Swim2 22:40\n",
      "\n",
      "22:40 78\n",
      "-Swim2 22:45\n",
      "\n",
      "22:45 79\n",
      "-Swim2 22:50\n",
      "\n",
      "22:50 80\n",
      "-Swim2 22:55\n",
      "\n",
      "22:55 81\n",
      "-Swim2 23:00\n",
      "\n",
      "23:00 82\n",
      "-Swim2 23:05\n",
      "\n",
      "23:05 83\n",
      "-Swim2 23:10\n",
      "\n",
      "23:10 84\n",
      "-Swim2 23:14\n",
      "\n",
      "23:14 85\n",
      "-Swim2 23:19\n",
      "\n",
      "23:19 86\n",
      "-Swim2 23:24\n",
      "\n",
      "23:24 87\n",
      "-Swim2 23:29\n",
      "\n",
      "23:29 88\n",
      "-Swim2 23:34\n",
      "\n",
      "23:34 89\n",
      "-Swim2 23:39\n",
      "\n",
      "23:39 90\n",
      "-Swim2 23:44\n",
      "\n",
      "23:44 91\n",
      "-Swim2 23:49\n",
      "\n",
      "23:49 92\n",
      "-Swim2 23:54\n",
      "\n",
      "23:54 93\n",
      "-Swim2 23:59\n",
      "\n",
      "23:59 94\n",
      "-Swim2 00:04\n",
      "\n",
      "00:04 95\n",
      "-Swim2 00:09\n",
      "\n",
      "00:09 96\n",
      "-Swim2 00:14\n",
      "\n",
      "00:14 97\n",
      "-Swim2 00:20\n",
      "\n",
      "00:20 98\n",
      "-Swim2 00:25\n",
      "\n",
      "00:25 99\n",
      "-Swim2 00:30\n",
      "\n",
      "00:30 100\n",
      "-Swim2 00:35\n",
      "\n",
      "00:35 101\n",
      "-Swim2 00:40\n",
      "\n",
      "00:40 102\n",
      "-Swim2 00:45\n",
      "\n",
      "00:45 103\n",
      "-Swim2 00:51\n",
      "\n",
      "00:51 104\n",
      "-Swim2 00:56\n",
      "\n",
      "00:56 105\n",
      "-Swim2 01:02\n",
      "\n",
      "01:02 106\n",
      "-Swim2 01:07\n",
      "\n",
      "01:07 107\n",
      "-Swim2 01:12\n",
      "\n",
      "01:12 108\n",
      "-Swim2 01:17\n",
      "\n",
      "01:17 109\n",
      "-Swim2 01:23\n",
      "\n",
      "01:23 110\n",
      "-Swim2 01:28\n",
      "\n",
      "01:28 111\n",
      "-Swim2 01:32\n",
      "\n",
      "01:32 112\n",
      "-Swim2 01:37\n",
      "\n",
      "01:37 113\n",
      "-Swim2 01:42\n",
      "\n",
      "01:42 114\n",
      "-Swim2 01:47\n",
      "\n",
      "01:47 115\n",
      "-Swim2 01:53\n",
      "\n",
      "01:53 116\n",
      "-Swim2 01:58\n",
      "\n",
      "01:58 117\n",
      "-Swim2 02:03\n",
      "\n",
      "02:03 118\n",
      "-Swim2 02:08\n",
      "\n",
      "02:08 119\n",
      "-Swim2 02:13\n",
      "\n",
      "02:13 120\n",
      "-Swim2 02:19\n",
      "\n",
      "02:19 121\n",
      "-Swim2 02:24\n",
      "\n",
      "02:24 122\n",
      "-Swim2 02:29\n",
      "\n",
      "02:29 123\n",
      "-Swim2 02:35\n",
      "\n",
      "02:35 124\n",
      "-Swim2 02:40\n",
      "\n",
      "02:40 125\n",
      "-Swim2 02:45\n",
      "\n",
      "02:45 126\n",
      "-Swim2 02:51\n",
      "\n",
      "02:51 127\n",
      "-Swim2 02:56\n",
      "\n",
      "02:56 128\n",
      "-Swim2 03:01\n",
      "\n",
      "03:01 129\n",
      "-Swim2 03:07\n",
      "\n"
     ]
    }
   ],
   "source": [
    "casesTypes=[\"-X-Morphomes\"]#,\"-X\"]\n",
    "echantillons=[\"%02d\"%n for n in range(29,130)]\n",
    "etapes=[\"-Swim2\"]#,\"-Swim1\"]\n",
    "for casesType in casesTypes:\n",
    "    for numeroEchantillon in echantillons:\n",
    "        print dateheure(\"%H:%M\"),\n",
    "        print numeroEchantillon\n",
    "        patron=ur\"^.*/(.*Longitudinal-%s-.*-F\\d+%s-%s%s\\.csv)\"%(numeroEchantillon,casesType,\"paradigmes\",\"\")\n",
    "        nomPar=findFichier(patron,fichiersPar)\n",
    "        dfPar=pd.read_csv(repCSV+nomPar,sep=\";\",encoding=\"utf8\")\n",
    "        casesPar=[c for c in cases if c in dfPar.columns]\n",
    "        dfPar=dfPar[[\"lexeme\"]+casesPar]\n",
    "        for etape in etapes:\n",
    "            print etape,\n",
    "            patron=patron=ur\"^.*/(.*Longitudinal-%s-.*-F\\d+%s-%s%s.*\\.csv)\"%(numeroEchantillon,casesType,\"paradigmes\",etape)\n",
    "            nomRes=findFichier(patron,fichiersPar)\n",
    "            dfRes=pd.read_csv(repCSV+nomRes,sep=\";\",encoding=\"utf8\")\n",
    "            dfRes=dfRes[[\"lexeme\"]+casesPar]\n",
    "\n",
    "            patron=ur\"^.*/(.*Longitudinal-%s-.*-F\\d+%s-%s%s.*\\.csv)\"%(numeroEchantillon,casesType,\"overGeneration\",etape)\n",
    "            nomOG=findFichier(patron,fichiersOG)\n",
    "\n",
    "            patron=ur\"^.*/(.*Longitudinal-%s-.*-F\\d+%s-%s%s.*\\.csv)\"%(numeroEchantillon,casesType,\"diffForms\",etape)\n",
    "            nomFP=findFichier(patron,fichiersFP)\n",
    "\n",
    "            patron=ur\"^.*/(.*Longitudinal-%s-.*-F\\d+%s-%s%s.*\\.csv)\"%(numeroEchantillon,casesType,\"underGeneration\",etape)\n",
    "            nomUG=findFichier(patron,fichiersUG)\n",
    "\n",
    "            dfOG=pd.read_csv(filepath_or_buffer=repCSV+nomOG,encoding=\"utf8\")\n",
    "            dfFP=pd.read_csv(filepath_or_buffer=repCSV+nomFP,encoding=\"utf8\")\n",
    "            dfUG=pd.read_csv(filepath_or_buffer=repCSV+nomUG,encoding=\"utf8\")\n",
    "\n",
    "            dfOG[\"lexeme\"]=dfOG[\"lexeme-case\"].str.rsplit(\"-\",1).str[0]\n",
    "            dfOG[\"case\"]=dfOG[\"lexeme-case\"].str.rsplit(\"-\",1).str[1]\n",
    "            dfFP[\"lexeme\"]=dfFP[\"lexeme-case\"].str.rsplit(\"-\",1).str[0]\n",
    "            dfFP[\"case\"]=dfFP[\"lexeme-case\"].str.rsplit(\"-\",1).str[1]\n",
    "            dfUG[\"lexeme\"]=dfUG[\"lexeme-case\"].str.rsplit(\"-\",1).str[0]\n",
    "            dfUG[\"case\"]=dfUG[\"lexeme-case\"].str.rsplit(\"-\",1).str[1]\n",
    "\n",
    "            dfResCol=dfRes.style.apply(colorCells,axis=1)\n",
    "            nomResCol=repXLS+nomRes.replace(\"-X-\",\"-%s-\"%phonologicalMap) # bug avec .xls\n",
    "            nomResCol=nomResCol.replace(\".csv\",\"-Annot.xlsx\")\n",
    "            dfResCol.to_excel(nomResCol)\n",
    "        print dateheure(\"%H:%M\")\n",
    "        print\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
