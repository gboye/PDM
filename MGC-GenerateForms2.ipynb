{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Importations\n",
    "- codecs pour les encodages\n",
    "- pandas et numpy pour les calculs sur tableaux\n",
    "- matplotlib pour les graphiques\n",
    "- itertools pour les itérateurs sophistiqués (paires sur liste, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "import codecs\n",
    "import features\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it\n",
    "import pickle\n",
    "import networkx as nx\n",
    "#%pylab inline\n",
    "#pd.options.display.mpl_style = 'default'\n",
    "debug=False\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "def dateheure():\n",
    "    return datetime.datetime.utcnow().strftime('%y%m%d%H%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saut=\"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Préparation des matrices de traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features.add_config('bdlexique.ini')\n",
    "fs=features.FeatureSystem('phonemes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampleNumber=\"03-X\"\n",
    "genDigraphe=False\n",
    "genGraphe=False\n",
    "samplePrefix=\"MGC-150815-extend-%s-paradigmes\"%sampleNumber\n",
    "sampleFile=samplePrefix+\".csv\"\n",
    "goldFile=\"MGC-150815-total-1508150555-paradigmes.csv\"\n",
    "analysisPrefix=\"MGC-150815-extend-%s\"%sampleNumber\n",
    "logfile_name=analysisPrefix+samplePrefix+\".log\"\n",
    "logfile = codecs.open(\"2015-Data/\"+logfile_name,mode='w',encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Préparation des cases du paradigme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "casesPrincipales= [\n",
    "        'inf', 'pi1S', 'pi2S', 'pi3S', 'pi1P', 'pi2P', 'pi3P', 'ii1S',\n",
    "        'ii2S', 'ii3S', 'ii1P', 'ii2P', 'ii3P', \n",
    "        'fi1S', 'fi2S', 'fi3S', 'fi1P', 'fi2P',\n",
    "        'fi3P', 'pI2S', 'pI1P', 'pI2P', 'ps1S', 'ps2S', 'ps3S', 'ps1P',\n",
    "        'ps2P', 'ps3P', \n",
    "        'pc1S', 'pc2S', 'pc3S', 'pc1P', 'pc2P', 'pc3P', 'pP',\n",
    "        'ppMS', 'ppMP', 'ppFS', 'ppFP'\n",
    "            ]\n",
    "casesSecondaires= [\n",
    "       'ai1S', 'ai2S', 'ai3S', 'ai1P', 'ai2P', 'ai3P', 'is1S', 'is2S', 'is3S', 'is1P', 'is2P', 'is3P'\n",
    "            ]\n",
    "casesTotales=casesPrincipales+casesSecondaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Préparation du calcul des analogies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Calcul de la différence entre deux formes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def diff(mot1,mot2):\n",
    "    result=[]\n",
    "    diff1=\"\"\n",
    "    diff2=\"\"\n",
    "    same=\"\"\n",
    "    vide=\".\"\n",
    "    lmax=max(len(mot1),len(mot2))\n",
    "    lmin=min(len(mot1),len(mot2))\n",
    "    for index in range(lmax):\n",
    "        if index < lmin:\n",
    "            if mot1[index]!=mot2[index]:\n",
    "                diff1+=mot1[index]\n",
    "                diff2+=mot2[index]\n",
    "                same+=vide\n",
    "            else:\n",
    "                same+=mot1[index]\n",
    "                diff1+=vide\n",
    "                diff2+=vide\n",
    "        elif index < len(mot1):\n",
    "            diff1+=mot1[index]\n",
    "        elif index < len(mot2):\n",
    "            diff2+=mot2[index]\n",
    "    diff1=diff1.lstrip(\".\")\n",
    "    diff2=diff2.lstrip(\".\")\n",
    "#    return (same,diff1,diff2,diff1+\"_\"+diff2)\n",
    "    return (diff1+\"-\"+diff2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Accumulation des paires appartenant à un patron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rowDiff(row, patrons):\n",
    "    result=diff(row[0],row[1])\n",
    "    if not result in patrons:\n",
    "        patrons[result]=(formesPatron(),formesPatron())\n",
    "    patrons[result][0].ajouterFormes(row[0])\n",
    "    patrons[result][1].ajouterFormes(row[1])\n",
    "    return (result[0],result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Transformation d'un patron en RegExp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def patron2regexp(morceaux):\n",
    "    result=\"^\"\n",
    "    for morceau in morceaux:\n",
    "        if morceau==\"*\":\n",
    "            result+=\"(.*)\"\n",
    "        elif len(morceau)>1:\n",
    "            result+=\"([\"+morceau+\"])\"\n",
    "        else:\n",
    "            result+=morceau\n",
    "    result+=\"$\"\n",
    "    result=result.replace(\")(\",\"\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Substitution de sortie \n",
    "???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remplacementSortie(sortie):\n",
    "    n=1\n",
    "    nsortie=\"\"\n",
    "    for lettre in sortie:\n",
    "        if lettre==\".\":\n",
    "            nsortie+=\"\\g<%d>\"%n\n",
    "            n+=1\n",
    "        else:\n",
    "            nsortie+=lettre\n",
    "    return nsortie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Classe pour la gestion des patrons, des classes et des transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class paireClasses:\n",
    "    def __init__(self,case1,case2):\n",
    "        self.case1=case1\n",
    "        self.case2=case2\n",
    "        self.nom=case1+\"-\"+case2\n",
    "        self.classes1=classesPaire(case1,case2)\n",
    "        self.classes2=classesPaire(case2,case1)\n",
    "\n",
    "    def ajouterPatron(self,n,patron,motif):\n",
    "        if n==1:\n",
    "            self.classes1.ajouterPatron(patron,motif)\n",
    "        elif n==2:\n",
    "            self.classes2.ajouterPatron(patron,motif)\n",
    "        else:\n",
    "            print (\"le numéro de forme n'est pas dans [1,2]\",n,file=logfile)\n",
    "\n",
    "    def ajouterPaire(self,forme1,forme2):\n",
    "        self.classes1.ajouterPaire(forme1,forme2)\n",
    "        self.classes2.ajouterPaire(forme2,forme1)\n",
    "        \n",
    "    def calculerClasses(self):\n",
    "        return(self.classes1,self.classes2)\n",
    "\n",
    "    \n",
    "class classesPaire:\n",
    "    '''\n",
    "    Gestion des patrons, des classes et des transformations\n",
    "    \n",
    "    ajouterPatron : ajoute un patron et son motif associé (MGL)\n",
    "    ajouterPaire : ajoute une paire de formes, calcule la classe de la forme1 et la règle sélectionnée\n",
    "    sortirForme : cacule les formes de sortie correspondant à la forme1 avec leurs coefficients respectifs\n",
    "    '''\n",
    "    def __init__(self,case1,case2):\n",
    "        self.case1=case1\n",
    "        self.case2=case2\n",
    "        self.nom=case1+\"-\"+case2\n",
    "        self.classe={}\n",
    "        self.nbClasse={}\n",
    "        self.patrons={}\n",
    "        self.entree={}\n",
    "        self.sortie={}\n",
    "    \n",
    "    def ajouterPatron(self,patron,motif):\n",
    "        self.patrons[patron]=motif\n",
    "        (entree,sortie)=patron.split(\"-\")\n",
    "        self.entree[patron]=entree.replace(u\".\",u\"(.)\")\n",
    "        self.sortie[patron]=remplacementSortie(sortie)\n",
    "    \n",
    "    def ajouterPaire(self,forme1,forme2):\n",
    "        '''\n",
    "        on calcule la classe de la paire idClasseForme et la règle sélectionnée\n",
    "        on incrémente le compteur de la classe et celui de la règle sélectionnée à l'intérieur de la classe\n",
    "        '''\n",
    "        classeForme=[]\n",
    "        regleForme=\"\"\n",
    "        for patron in self.patrons:\n",
    "            if re.match(self.patrons[patron],forme1):\n",
    "                classeForme.append(patron)\n",
    "                '''\n",
    "                le +\"$\" permet de forcer l'alignement à droite pour les transformations suffixales\n",
    "                '''\n",
    "                if forme2==re.sub(self.entree[patron]+\"$\",self.sortie[patron],forme1):\n",
    "                    regleForme=patron\n",
    "        idClasseForme=\", \".join(classeForme)\n",
    "        if not idClasseForme in self.classe:\n",
    "            self.classe[idClasseForme]={}\n",
    "            self.nbClasse[idClasseForme]=0\n",
    "        if not regleForme in self.classe[idClasseForme]:\n",
    "            self.classe[idClasseForme][regleForme]=0\n",
    "        self.nbClasse[idClasseForme]+=1\n",
    "        self.classe[idClasseForme][regleForme]+=1\n",
    "\n",
    "    def sortirForme(self,forme):\n",
    "        classeForme=[]\n",
    "        sortieForme={}\n",
    "        for patron in self.patrons:\n",
    "            if re.match(self.patrons[patron],forme):\n",
    "                classeForme.append(patron)\n",
    "        if classeForme:\n",
    "            idClasseForme=\", \".join(classeForme)\n",
    "            if idClasseForme in self.nbClasse:\n",
    "                nTotal=self.nbClasse[idClasseForme]\n",
    "                for patron in self.classe[idClasseForme]:\n",
    "                    sortie=re.sub(self.entree[patron]+\"$\",self.sortie[patron],forme)\n",
    "                    sortieForme[sortie]=float(self.classe[idClasseForme][patron])/nTotal\n",
    "            else:\n",
    "                if debug:\n",
    "                    print (forme, file=logfile)\n",
    "                    print (\"pas de classe\",idClasseForme, file=logfile)\n",
    "                    print (\"%.2f par forme de sortie\" % (float(1)/len(classeForme)), file=logfile)\n",
    "                nTotal=len(classeForme)\n",
    "                for patron in classeForme:\n",
    "                    sortie=re.sub(self.entree[patron]+\"$\",self.sortie[patron],forme)\n",
    "                    sortieForme[sortie]=float(1)/nTotal\n",
    "        else:\n",
    "            print (forme, file=logfile) \n",
    "            print (\"pas de patron\", file=logfile)\n",
    "        return sortieForme\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Appliquer la formule de calcul des différences entre chaines à chaque ligne\n",
    "\n",
    ">si il y a au moins une ligne\n",
    "\n",
    ">>on applique la différence à la ligne\n",
    "\n",
    ">>on calcule les deux patrons par suppression des points initiaux\n",
    "\n",
    ">>on renvoie le groupement par patrons (1&2)\n",
    "\n",
    ">sinon\n",
    "\n",
    ">>on renvoie le paradigme vide d'origine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def OLDrapports(paradigme):\n",
    "    (case1,case2,lexeme)= paradigme.columns.values.tolist()\n",
    "    patrons=pairePatrons(case1,case2)\n",
    "    if len(paradigme)>0:\n",
    "#        for index, row in paradigme.iterrows():\n",
    "#            patrons.ajouterFormes(row[0],row[1],diff(row[0],row[1]))\n",
    "        paradigme.apply(lambda x: patrons.ajouterFormes(x[case1],x[case2],diff(x[case1],x[case2])), axis=1)\n",
    "        (regles1,regles2)=patrons.calculerGM()\n",
    "    return patrons.calculerGM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rapports(paradigme):\n",
    "    if len(paradigme.columns.values.tolist())==2:\n",
    "        (case1,lexeme)= paradigme.columns.values.tolist()\n",
    "        case2=case1\n",
    "    else:\n",
    "        (case1,case2,lexeme)= paradigme.columns.values.tolist()\n",
    "    patrons=pairePatrons(case1,case2)\n",
    "    classes=paireClasses(case1,case2)\n",
    "    if len(paradigme)>0:\n",
    "        paradigme.apply(lambda x: patrons.ajouterFormes(x[case1],x[case2],diff(x[case1],x[case2])), axis=1)\n",
    "        (regles1,regles2)=patrons.calculerGM()\n",
    "        for regle in regles1:\n",
    "            classes.ajouterPatron(1,regle,regles1[regle])\n",
    "        for regle in regles2:\n",
    "            classes.ajouterPatron(2,regle,regles2[regle])\n",
    "        paradigme.apply(lambda x: classes.ajouterPaire(x[case1],x[case2]), axis=1)\n",
    "    (classes1,classes2)=classes.calculerClasses()\n",
    "    return (classes1,classes2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Dédoubler les lignes avec des surabondances dans *colonne*\n",
    ">identifier une ligne avec surabondance\n",
    "\n",
    ">>ajouter les lignes correspondant à chaque valeur\n",
    "\n",
    ">>ajouter le numéro de la ligne initiale dans les lignes à supprimer\n",
    "\n",
    ">supprimer les lignes avec surabondance\n",
    "\n",
    "NB : il faut préparer le tableau pour avoir une indexation qui permette l'ajout des valeurs individuelles et la suppression des lignes de surabondances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def splitCellMates(df,colonne):\n",
    "    '''\n",
    "    Calcul d'une dataframe sans surabondance par dédoublement des valeurs\n",
    "    '''\n",
    "    test=df.reset_index()\n",
    "    del test[\"index\"]\n",
    "    splitIndexes=[]\n",
    "    for index,ligne in test.iterrows():\n",
    "        if \",\" in ligne[colonne]:\n",
    "            valeurs=set(ligne[colonne].split(\",\"))\n",
    "            nouvelleLigne=ligne\n",
    "            for valeur in valeurs:\n",
    "                nouvelleLigne[colonne]=valeur\n",
    "                test=test.append(nouvelleLigne,ignore_index=True)\n",
    "            splitIndexes.append(index)\n",
    "    if splitIndexes:\n",
    "        test=test.drop(test.index[splitIndexes])\n",
    "    return test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paradigmes=pd.read_csv(\"2015-Data/\"+sampleFile,sep=\";\",encoding=\"utf8\")\n",
    "del paradigmes[u\"Unnamed: 0\"]\n",
    "#paradigmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phonologicalMap=analysisPrefix[-2:]\n",
    "if debug: print(phonologicalMap)\n",
    "neutralisationsNORD=(u\"6û\",u\"9ê\")\n",
    "neutralisationsSUD=(u\"e2o\",u\"E9O\")\n",
    "if phonologicalMap==\"-N\":\n",
    "    neutralisations=neutralisationsNORD\n",
    "elif phonologicalMap==\"-S\":\n",
    "    neutralisations=neutralisationsSUD\n",
    "else:\n",
    "    neutralisations=(u\"\",u\"\")\n",
    "    phonologicalMap=(\"-X\")\n",
    "bdlexiqueIn = unicode(u\"èò\"+neutralisations[0])\n",
    "bdlexiqueNum = [ord(char) for char in bdlexiqueIn]\n",
    "neutreOut = unicode(u\"EO\"+neutralisations[1])\n",
    "neutralise = dict(zip(bdlexiqueNum, neutreOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recoder(chaine,table=neutralise):\n",
    "    if type(chaine)==str:\n",
    "        temp=unicode(chaine.decode('utf8')).translate(table)\n",
    "        result=temp.encode('utf8')\n",
    "    elif type(chaine)==unicode:\n",
    "        result=chaine.translate(table)\n",
    "    else:\n",
    "        result=chaine\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GOLD=pd.read_csv(\"2015-Data/\"+goldFile,sep=\";\",encoding=\"utf8\")\n",
    "del GOLD[u\"Unnamed: 0\"]\n",
    "goldCases=GOLD.columns.tolist()\n",
    "goldCases.remove(u\"lexeme\")\n",
    "for case in goldCases:\n",
    "    GOLD[case]=GOLD[case].apply(lambda x: recoder(x))\n",
    "    \n",
    "paradigmesGOLD=GOLD[paradigmes.columns.values.tolist()]\n",
    "#paradigmesGOLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sampleCases pour la liste des cases effectivement représentées dans le corpus de départ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampleCases=paradigmes.columns.values.tolist()\n",
    "sampleCases.remove(u\"lexeme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49485"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paradigmes.stack().value_counts(dropna=True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"2015-Data/\"+analysisPrefix+'-Regles.pkl', 'rb') as input:\n",
    "    resultatsLecture = pickle.load(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Comparer les cases analysées avec l'ensemble de toutes les cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analyseCases=list(set([case for (case,autre) in resultatsLecture.keys()]))\n",
    "if sorted(analyseCases)!=sorted(casesTotales):\n",
    "    print (\"Attention l'analyse ne comprend pas toutes les cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class paradigmeDistribution:\n",
    "    '''\n",
    "    Gestion des distributions dans les cases du paradigme\n",
    "    '''\n",
    "\n",
    "    def __init__(self,lexeme):\n",
    "        self.lexeme=lexeme\n",
    "        self.formes={i:{} for i in analyseCases}\n",
    "\n",
    "    def ajouterFormes(self,case,formes,coef=1.0):\n",
    "        for forme in formes:\n",
    "            if not forme in self.formes[case]:\n",
    "                self.formes[case][forme]=0\n",
    "            self.formes[case][forme]+=formes[forme]*coef\n",
    "            \n",
    "    def normaliserDistributions(self,caseListe=analyseCases):\n",
    "        normalesDistributions={i:{} for i in caseListe}\n",
    "        for case in caseListe:\n",
    "            total=0\n",
    "            for element in self.formes[case]:\n",
    "                total+=self.formes[case][element]\n",
    "            for element in self.formes[case]:\n",
    "                normalesDistributions[case][element]=float(self.formes[case][element])/total\n",
    "        return normalesDistributions\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generateForms(lexeme):\n",
    "    candidats=paradigmeDistribution(lexeme)\n",
    "    casesSamples=paradigmes[paradigmes[\"lexeme\"]==lexeme].columns[paradigmes[paradigmes[\"lexeme\"]==lexeme].notnull().iloc[0]].tolist()\n",
    "    casesSamples.remove(\"lexeme\")\n",
    "    for caseDepart in casesSamples:\n",
    "        formeDepart=paradigmes[paradigmes[\"lexeme\"]==lexeme][caseDepart].iloc[0]\n",
    "        if debug: print (caseDepart,formeDepart, file=logfile)\n",
    "#        if formeDepart!=\"nan\":\n",
    "        for case in analyseCases:\n",
    "            if debug: print (case, file=logfile)\n",
    "            if not isinstance(resultatsLecture[(caseDepart, case)],str):\n",
    "                if \",\" in formeDepart:\n",
    "                    formesDepart=formeDepart.split(\",\")\n",
    "                    coef=1.0/len(formesDepart)\n",
    "                    for element in formesDepart:\n",
    "                        candidats.ajouterFormes(case,resultatsLecture[(caseDepart, case)].sortirForme(element),coef)\n",
    "                else:\n",
    "                    candidats.ajouterFormes(case,resultatsLecture[(caseDepart, case)].sortirForme(formeDepart))\n",
    "            else: \n",
    "                if debug: print (\"str\", resultatsLecture[(caseDepart, case)], file=logfile)\n",
    "    return candidats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ajouterPoint(lexeme,forme,case,digraphe,graphe):\n",
    "    pointName=\"%s-%s-%s\"%(lexeme,forme,case)\n",
    "#    if not pointName in digraphe.nodes():\n",
    "    tam=case[:2]\n",
    "    if tam==\"in\": tam=\"inf\"\n",
    "    digraphe.add_node(pointName, tam='\"%s\"'%tam)\n",
    "    graphe.add_node(pointName, tam='\"%s\"'%tam)\n",
    "    return pointName\n",
    "\n",
    "def ajouterFleche(pointDepart,pointSortie,coef,digraphe,graphe):\n",
    "    digraphe.add_edge(pointDepart,pointSortie,weight=float(coef))\n",
    "    if digraphe.has_edge(pointSortie,pointDepart):\n",
    "        coefGraphe=float(digraphe.edge[pointSortie][pointDepart][\"weight\"]+coef)/2\n",
    "        graphe.add_edge(pointDepart,pointSortie,weight=coefGraphe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generateParadigms(generation1,genDigraphe=True):\n",
    "    lexeme=generation1.lexeme\n",
    "    distributionInitiale=generation1.normaliserDistributions()\n",
    "    candidats=paradigmeDistribution(lexeme)\n",
    "    digraphe=nx.DiGraph()\n",
    "    graphe=nx.Graph()    \n",
    "    for caseDepart in analyseCases:\n",
    "        for formeDepart in distributionInitiale[caseDepart]:\n",
    "            if formeDepart:\n",
    "                pointDepart=ajouterPoint(lexeme,formeDepart,caseDepart,digraphe,graphe)\n",
    "                coefDepart=distributionInitiale[caseDepart][formeDepart]\n",
    "                if debug: print (caseDepart,formeDepart, file=logfile)\n",
    "                for caseSortie in analyseCases:\n",
    "                    distributionSortieBrute=resultatsLecture[(caseDepart, caseSortie)].sortirForme(formeDepart)\n",
    "                    if distributionSortieBrute:\n",
    "                        if not genDigraphe:\n",
    "#                            print (\"brute\",distributionSortieBrute)\n",
    "                            distributionSortie={f:distributionSortieBrute[f] for f in distributionSortieBrute if f in distributionInitiale[caseSortie]}\n",
    "                        else:\n",
    "                            distributionSortie=distributionSortieBrute\n",
    "#                        print (\"filtre\",distributionSortie)\n",
    "#                        print (distributionInitiale[caseSortie])\n",
    "                        if debug: print (caseSortie,distributionSortie,distributionInitiale[caseDepart], file=logfile)\n",
    "                        candidats.ajouterFormes(caseSortie,distributionSortie,distributionInitiale[caseDepart][formeDepart])\n",
    "                        for formeSortie in distributionSortie:\n",
    "                            pointSortie=ajouterPoint(lexeme,formeSortie,caseSortie,digraphe,graphe)\n",
    "                            coefSortie=distributionSortie[formeSortie]\n",
    "                            ajouterFleche(pointDepart,pointSortie,float(coefDepart*coefSortie),digraphe,graphe)\n",
    "    return (candidats,digraphe,graphe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate(lexeme,genDigraphe=True):\n",
    "#    print (lexeme,end=\", \")\n",
    "    generation1=generateForms(lexeme)\n",
    "#    print (\"génération 2\",end=\", \")\n",
    "    (generation2,lexDigraphe,lexGraphe)=generateParadigms(generation1,genDigraphe)\n",
    "    lexCliques=list(nx.algorithms.clique.find_cliques(lexGraphe))\n",
    "#    print (lexCliques)\n",
    "#    print (\"génération 3\")\n",
    "    return (generation2,lexDigraphe,lexGraphe,lexCliques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4547"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paradigmes.dropna(thresh=2)[\"lexeme\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44938"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paradigmes.dropna(thresh=2).count().sum()-paradigmes.dropna(thresh=2)[\"lexeme\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####Calculer le score de la clique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cliqueScore(clique,graph):\n",
    "    score=0\n",
    "    for (depart,arrivee) in it.combinations_with_replacement(clique,2):\n",
    "        score+=graph[depart][arrivee][\"weight\"]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Génération des formes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "debug=False\n",
    "#listeTest=[u\"manger\",u\"boire\",u\"dormir\",u\"aller\",u\"neiger\"]\n",
    "listeTest=paradigmes.dropna(thresh=2)[\"lexeme\"].values.tolist()\n",
    "#listeTest=[u\"abasourdir\",u\"évacuer\"]\n",
    "nbVerbes=len(listeTest)\n",
    "print (nbVerbes)\n",
    "globDigraphe=nx.DiGraph()\n",
    "globGraphe=nx.Graph()\n",
    "cliques=[]\n",
    "cliquesScores={}\n",
    "cliquesListes={}\n",
    "numClique=0\n",
    "for i,element in enumerate(listeTest):\n",
    "    if (i%100)==0: print (i, dateheure()[-4:], int(100*float(i)/nbVerbes), end=\", \")\n",
    "    result=generate(element,genDigraphe)\n",
    "    (generation,lexDigraphe,lexGraphe,lexCliques)= result\n",
    "#    print (generation,lexDigraphe,lexGraphe,lexCliques)\n",
    "    if genDigraphe:\n",
    "        globDigraphe=nx.union(globDigraphe,lexDigraphe)\n",
    "    if genGraphe:\n",
    "        globGraphe=nx.union(globGraphe,lexGraphe)\n",
    "    cliques.extend(lexCliques)\n",
    "    for clique in lexCliques:\n",
    "        cliquesScores[numClique]=cliqueScore(clique,lexGraphe)\n",
    "        cliquesListes[numClique]=clique\n",
    "        numClique+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "versionStamp=dateheure()\n",
    "if genDigraphe: \n",
    "    nx.write_dot(globDigraphe,u\"2015-Data/digraphe-%s.dot\"%versionStamp)\n",
    "if genGraphe:\n",
    "    nx.write_dot(globGraphe,u\"2015-Data/graphe-%s.dot\"%versionStamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (len(cliques))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "longueurCliques={}\n",
    "for clique in cliques:\n",
    "    longueur=len(clique)\n",
    "    if not longueur in longueurCliques:\n",
    "        longueurCliques[longueur]=1\n",
    "    else:\n",
    "        longueurCliques[longueur]+=1\n",
    "longueurCliques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Faire la liste des cases lexicalisées de l'échantillon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nbFormesLexicales={}\n",
    "casesLexicales={element:paradigmes[paradigmes[\"lexeme\"]==element].columns[paradigmes[paradigmes[\"lexeme\"]==element].notnull().iloc[0]].tolist() for element in listeTest}\n",
    "for element in casesLexicales:\n",
    "    casesLexicales[element].remove(\"lexeme\")\n",
    "    nbFormesLexicales[element]=len(casesLexicales[element])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Comparer la sortie des cliques avec le paradigme de départ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "seuilClique=1\n",
    "#paradigmesCLIQUES=pd.DataFrame(columns=paradigmes.columns.values.tolist())\n",
    "paradigmesListe=[]\n",
    "#for n,clique in enumerate(sorted(cliques,key=lambda x: len(x),reverse=True)):\n",
    "for n,clique in enumerate(cliques):\n",
    "#    if seuilClique==0:\n",
    "#        seuilClique=len(clique)-15\n",
    "    if len(clique)>seuilClique:\n",
    "        paradigmeClique={}\n",
    "        sampleOK=True\n",
    "#        print (n, len(clique))\n",
    "        point=clique[0].split(\"-\")\n",
    "        lPoint=len(point)\n",
    "#        print (point,\"-\".join(point[0:len(point)-2]))\n",
    "        if lPoint==3:\n",
    "            lexeme=point[0]\n",
    "        else:\n",
    "            lexeme=\"-\".join(point[0:len(point)-2])\n",
    "        paradigmeClique[\"lexeme\"]=lexeme\n",
    "        if n%5000==0: print (n,int(100*float(n)/len(cliques)),end=\", \")\n",
    "#        casesLexeme=paradigmes[paradigmes[\"lexeme\"]==lexeme].notnull().columns.tolist()\n",
    "#        casesLexeme=paradigmes[paradigmes[\"lexeme\"]==lexeme].columns[paradigmes[paradigmes[\"lexeme\"]==lexeme].notnull().iloc[0]].tolist()\n",
    "#        casesLexeme.remove(\"lexeme\")\n",
    "        casesLexeme=casesLexicales[lexeme]\n",
    "        nbInitial=len(casesLexeme)\n",
    "        if casesLexeme and len(casesLexeme)<=len(clique):\n",
    "            for element in casesLexeme:\n",
    "#                print (lexeme,element, paradigmes[paradigmes[\"lexeme\"]==lexeme][element])\n",
    "                champForme=paradigmes[paradigmes[\"lexeme\"]==lexeme][element].iloc[0]\n",
    "                if \",\"  in champForme:\n",
    "                    formes=champForme.split(\",\")\n",
    "                    nbInitial+=len(formes)-1\n",
    "                    okFormes=False\n",
    "                    for forme in formes:\n",
    "                        pointCase=u\"%s-%s-%s\"% (lexeme,forme,element)\n",
    "#                        if debug: print (pointCase, clique)\n",
    "                        if pointCase in clique:\n",
    "                            okFormes=True\n",
    "                            print (\"point\",pointCase)\n",
    "#                            print (\"clique\",clique)\n",
    "                            print (\"gold\",GOLD[GOLD[\"lexeme\"]==lexeme][element])\n",
    "                    if okFormes:\n",
    "                        sampleOK=True\n",
    "                    else:\n",
    "                        sampleOK=False\n",
    "                        break\n",
    "                else:\n",
    "                    forme=champForme\n",
    "                    pointCase=u\"%s-%s-%s\"% (lexeme,forme,element)\n",
    "                    if debug: print (pointCase, clique)\n",
    "                    if not pointCase in clique:\n",
    "                        sampleOK=False\n",
    "#                        print (\"point\",pointCase)\n",
    "#                        print (\"clique\",clique)\n",
    "#                        print (\"gold\",GOLD[GOLD[\"lexeme\"]==lexeme][element])\n",
    "                        break\n",
    "        else:\n",
    "            sampleOK=False\n",
    "        if sampleOK:\n",
    "            for element in clique:\n",
    "                elements=element.split(\"-\")\n",
    "                forme=elements[-2]\n",
    "                taminfo=elements[-1]\n",
    "#                try:\n",
    "#                 (lexeme,forme,taminfo)=element.split(\"-\")\n",
    "#                except ValueError:\n",
    "#                    print (element)\n",
    "                paradigmeClique[taminfo]=forme\n",
    "#                if taminfo in paradigmes.columns:\n",
    "#                    if not paradigmes[(paradigmes[\"lexeme\"]==lexeme)][taminfo].isnull().item():\n",
    "#                        if paradigmes[(paradigmes[\"lexeme\"]==lexeme)][taminfo].item()!=forme:\n",
    "#                            sampleOK=False\n",
    "#                            print (paradigmes[(paradigmes[\"lexeme\"]==lexeme)][taminfo].item(),forme,taminfo,end=\", \")\n",
    "#            if n<100: print (clique==cliquesListes[n])\n",
    "            paradigmeClique[\"score\"]=cliquesScores[n]\n",
    "            paradigmeClique[\"ajouts\"]=len(clique)-nbInitial\n",
    "#            print (cliqueScore(clique),clique)\n",
    "            paradigmesListe.append(paradigmeClique)\n",
    "        else:\n",
    "            if debug:\n",
    "                print ()\n",
    "                print (lexeme,clique)\n",
    "                print ()\n",
    "#    else:\n",
    "#        print (\"break\")\n",
    "#        print (n,lexeme,clique)\n",
    "#        break\n",
    "\n",
    "paradigmesCLIQUES=pd.DataFrame(paradigmesListe,columns=GOLD.columns.values.tolist()+[u\"score\",u\"ajouts\"])\n",
    "#print (seuilClique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paradigmeSILVER=paradigmesCLIQUES[paradigmesCLIQUES[\"score\"]==paradigmesCLIQUES.groupby([\"lexeme\"])[\"score\"].transform(max)].reset_index()\n",
    "del paradigmeSILVER[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paradigmeSILVER.to_csv(path_or_buf=\"2015-Data/\"+analysisPrefix+'-Silver.csv',encoding=\"utf8\",sep=\";\")\n",
    "GOLD.to_csv(path_or_buf=\"2015-Data/\"+analysisPrefix+'-Gold.csv',encoding=\"utf8\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compareGOLD(row):\n",
    "    global n\n",
    "#    if row[\"lexeme\"]==\"dodo\": \n",
    "#        debug=True\n",
    "#    else:\n",
    "#        debug=False\n",
    "    if n%250==0: print (n,end=\", \")\n",
    "    n+=1\n",
    "    ligne={k:row[k] for k in row.keys() if not k in [\"lexeme\",\"score\",\"ajouts\"]}\n",
    "    lexeme=row[\"lexeme\"]\n",
    "    score=row[\"score\"]\n",
    "    ajouts=row[\"ajouts\"]\n",
    "    if not lexeme in conjugaisons:\n",
    "        conjugaisons[lexeme]={\"diff\":[],\"miss\":[],\"over\":[],\"overmiss\":[],\"ok\":[]}\n",
    "    if not lexeme in cliquesTypes:\n",
    "        cliquesTypes[lexeme]={\"diff\":[],\"miss\":[],\"over\":[],\"overmiss\":[],\"ok\":[]}\n",
    "    identiques=[]\n",
    "    differents=[]\n",
    "    missing=[]\n",
    "    over=[]\n",
    "    for case in analyseCases:\n",
    "        if debug:    \n",
    "            print (lexeme,case)\n",
    "            print (GOLD[GOLD[\"lexeme\"]==lexeme][case].item())\n",
    "            print ((GOLD[GOLD[\"lexeme\"]==lexeme][case].isnull().iloc[0]))\n",
    "        if not case in row:\n",
    "            if debug: print (\"not case\")\n",
    "            missing.append(u\"%s : Ø ≠ %s\" % (case,GOLD[GOLD[\"lexeme\"]==lexeme][case].item()))\n",
    "            lexical=False\n",
    "            if debug: print (\"absence\",case)\n",
    "        elif case in row[row.isnull()] and not GOLD[GOLD[\"lexeme\"]==lexeme][case].isnull().iloc[0]:\n",
    "            if debug: print (\"not case\")\n",
    "            missing.append(u\"%s : Ø ≠ %s\" % (case,GOLD[GOLD[\"lexeme\"]==lexeme][case].item()))\n",
    "            lexical=False\n",
    "            if debug: print (\"CLIQUES +NaN\",case)\n",
    "        elif not case in row[row.isnull()] and GOLD[GOLD[\"lexeme\"]==lexeme][case].isnull().iloc[0]:\n",
    "            if debug: print (\"not case\")\n",
    "            over.append(u\"%s : %s ≠ Ø\" % (case,row[case]))\n",
    "            lexical=False\n",
    "            if debug: print (\"GOLD -NaN\",case)            \n",
    "        elif (row[case]==GOLD[GOLD[\"lexeme\"]==lexeme][case].item()):\n",
    "            if debug: print (\"egal\")\n",
    "            identiques.append(u\"%s : %s\" % (case,row[case]))\n",
    "            if debug: print (\"valeurs id\")\n",
    "        elif (case in row[row.isnull()]) and (GOLD[GOLD[\"lexeme\"]==lexeme][case].isnull().iloc[0]):\n",
    "            if debug: print (\"NaNs\")\n",
    "            identiques.append(u\"%s : %s\" % (case,u\"ØØØ\"))\n",
    "            if debug: print (\"deux NaN\")\n",
    "        else:\n",
    "            if debug: print (\"else\")\n",
    "            differents.append(u\"%s : %s ≠ %s\" % (case, row[case],GOLD[GOLD[\"lexeme\"]==lexeme][case].item()))\n",
    "            lexical=False\n",
    "            if debug: print (u\"différence\",case)\n",
    "    if differents:\n",
    "        conjugaisons[lexeme][\"diff\"].append(differents)\n",
    "        cliquesTypes[lexeme][\"diff\"].append((ligne,score,ajouts))\n",
    "        if debug: print (\"DIFF\",len(differents),\"=>\", len(identiques), len(identiques)-nombreElements[lexeme], end=saut)\n",
    "        if debug1: print (\", \".join(differents))\n",
    "    if missing and over:\n",
    "        conjugaisons[lexeme][\"overmiss\"].append(over+missing)\n",
    "        cliquesTypes[lexeme][\"overmiss\"].append((ligne,score,ajouts))\n",
    "        if debug: print (\"OVERMISS\", len(over), len(missing),\"=>\", len(identiques), len(identiques)-nombreElements[lexeme], end=saut)\n",
    "        if debug1: \n",
    "            print (\", \".join(missing))\n",
    "            print (\", \".join(over))\n",
    "    elif missing:\n",
    "        conjugaisons[lexeme][\"miss\"].append(missing)\n",
    "        cliquesTypes[lexeme][\"miss\"].append((ligne,score,ajouts))\n",
    "        if debug: print (\"MISS\", len(missing),\"=>\", len(identiques), len(identiques)-nombreElements[lexeme], end=saut)\n",
    "        if debug1: \n",
    "            print (\", \".join(missing))\n",
    "    elif over:\n",
    "        conjugaisons[lexeme][\"over\"].append(over)\n",
    "        cliquesTypes[lexeme][\"over\"].append((ligne,score,ajouts))\n",
    "        if debug: print (\"OVER\", len(over),\"=>\", len(identiques), len(identiques)-nombreElements[lexeme], end=saut)\n",
    "        if debug1: \n",
    "            print (\", \".join(over))\n",
    "    if identiques:\n",
    "        conjugaisons[lexeme][\"ok\"].append(identiques)\n",
    "        cliquesTypes[lexeme][\"ok\"].append((ligne,score,ajouts))\n",
    "        if debug: print (\"OK\", len(identiques), len(identiques)-nombreElements[lexeme],end=saut)\n",
    "        if debug1: print (\", \".join(identiques))\n",
    "#    print ()\n",
    "    return lexical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "debug=False\n",
    "debug1=False\n",
    "saut=\"\\n\"\n",
    "n=0\n",
    "conjugaisons={}\n",
    "cliquesTypes={}\n",
    "print (\", \".join(sampleCases))\n",
    "#paradigmesCLIQUES.apply(compareGOLD,axis=1)\n",
    "paradigmeSILVER.apply(compareGOLD,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "with codecs.open(\"2015-Data/\"+samplePrefix+\".yaml\", 'w', encoding='utf8') as outfile:\n",
    "    outfile.write(yaml.dump(conjugaisons, default_flow_style=True, encoding='utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yaml.safe_dump(conjugaisons, file(\"2015-Data/\"+samplePrefix+dateheure()+\".yaml\",'w'), encoding='utf-8', allow_unicode=True)\n",
    "yaml.safe_dump(cliquesTypes, file(\"2015-Data/\"+samplePrefix+\"cliques-\"+dateheure()+\".yaml\",'w'), encoding='utf-8', allow_unicode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pb=[i for i in conjugaisons if conjugaisons[i][\"diff\"]]\n",
    "print (len(pb))\n",
    "for element in pb:\n",
    "    print (element)\n",
    "    print (\"DIFF\",conjugaisons[element][\"diff\"])\n",
    "    print (\"MISS\",conjugaisons[element][\"miss\"],end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "good=[i for i in conjugaisons if not conjugaisons[i][\"diff\"]]\n",
    "for lexeme in good:\n",
    "    print (lexeme)\n",
    "    for ident in conjugaisons[lexeme]:\n",
    "        for element in conjugaisons[lexeme][ident]:\n",
    "            print (ident)\n",
    "            print (\", \".join(element))\n",
    "    print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "precisions={\"bon\":0,\"mauvais\":0}\n",
    "for verbe in cliquesTypes:\n",
    "    if debug: print (verbe)\n",
    "    for cle in cliquesTypes[verbe]:\n",
    "        if debug: print (cle)\n",
    "        for element in cliquesTypes[verbe][cle]:\n",
    "            if debug: print (element[1],element[2])\n",
    "            if cle in [\"ok\"]:\n",
    "                precisions[\"bon\"]+=element[2]\n",
    "            elif cle in [\"diff\"]:\n",
    "                precisions[\"mauvais\"]+=element[2]\n",
    "precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "float(precisions[\"bon\"])/(precisions[\"bon\"]+precisions[\"mauvais\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "basesMesures={\"total\":0,\"bon\":0,\"mauvais\":0}\n",
    "for verbe in conjugaisons:\n",
    "    for cat in conjugaisons[verbe]:\n",
    "        if conjugaisons[verbe][cat]:\n",
    "#            print (verbe,cat,len(conjugaisons[verbe][cat][0]))\n",
    "            if cat==\"miss\":\n",
    "                basesMesures[\"total\"]+=len(conjugaisons[verbe][cat][0])\n",
    "            elif cat==\"ok\":\n",
    "                basesMesures[\"bon\"]+=len(conjugaisons[verbe][cat][0])\n",
    "                basesMesures[\"total\"]+=len(conjugaisons[verbe][cat][0])\n",
    "            elif cat==\"diff\":\n",
    "                basesMesures[\"mauvais\"]+=len(conjugaisons[verbe][cat][0])\n",
    "                basesMesures[\"total\"]+=len(conjugaisons[verbe][cat][0])\n",
    "            elif cat==\"overmiss\":\n",
    "                basesMesures[\"mauvais\"]+=len(conjugaisons[verbe][cat][0])\n",
    "                basesMesures[\"total\"]+=len(conjugaisons[verbe][cat][0])\n",
    "basesMesures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "precisionManip=float(basesMesures[\"bon\"])/(basesMesures[\"bon\"]+basesMesures[\"mauvais\"])\n",
    "precisionManip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rappelManip=float(basesMesures[\"bon\"])/(basesMesures[\"total\"])\n",
    "rappelManip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
