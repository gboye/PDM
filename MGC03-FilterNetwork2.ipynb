{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importations\n",
    "- codecs pour les encodages\n",
    "- pandas et numpy pour les calculs sur tableaux\n",
    "- matplotlib pour les graphiques\n",
    "- itertools pour les itérateurs sophistiqués (paires sur liste, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf8 -*-\n",
    "import codecs\n",
    "import features\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it\n",
    "import pickle\n",
    "import networkx as nx\n",
    "#%pylab inline\n",
    "#pd.options.display.mpl_style = 'default'\n",
    "debug=False\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.html.widgets import FloatProgress\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "def dateheure():\n",
    "    return datetime.datetime.utcnow().strftime('%y%m%d%H%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saut=\"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des matrices de traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features.add_config('bdlexique.ini')\n",
    "fs=features.FeatureSystem('phonemes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampleNumber=\"01-N\"\n",
    "genDigraphe=False\n",
    "genGraphe=False\n",
    "#samplePrefix=\"MGC-150916-extend-%s-paradigmes\"%sampleNumber\n",
    "#samplePrefix=\"MGC-160104-%s-VerbesActions-SILVER\"%sampleNumber\n",
    "#samplePrefix=\"MGC-160104-%s-ext3-paradigmes\"%sampleNumber\n",
    "samplePrefix=\"MGC-160104-%s-ext3-derivations-SILVER\"%sampleNumber\n",
    "#samplePrefix=\"MGC-160104-derivation2-%s-SILVER\"%sampleNumber\n",
    "#samplePrefix=\"MGC-160104-derivation2-derives2\"\n",
    "#samplePrefix=\"MGC-160104-%s-basesDerives\"%sampleNumber\n",
    "sampleFile=samplePrefix+\".csv\"\n",
    "#goldFile=\"MGC-160104-01-N-VerbesActions-GOLD.csv\"\n",
    "#goldFile=\"MGC-160104-01-N-Gold.csv\"\n",
    "#analysisPrefix=\"MGC-150916-extend-%s\"%sampleNumber\n",
    "#analysisPrefix=\"MGC-160104-%s-VerbesActions-SILVER\"%sampleNumber\n",
    "#analysisPrefix=\"MGC-160104-%s-ext3-paradigmes\"%sampleNumber\n",
    "analysisPrefix=\"MGC-160104-%s-ext3-derivations-SILVER\"%sampleNumber\n",
    "#analysisPrefix=\"MGC-160104-derivation2-%s-SILVER\"%sampleNumber\n",
    "logfile_name=analysisPrefix+samplePrefix+\".log\"\n",
    "logfile = codecs.open(\"2015-Data/\"+logfile_name,mode='w',encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paradigmes=pd.read_csv(\"2015-Data/\"+sampleFile,sep=\";\",encoding=\"utf8\")\n",
    "del paradigmes[u\"Unnamed: 0\"]\n",
    "paradigmes=paradigmes.dropna(axis=1,how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phonologicalMap=analysisPrefix[-2:]\n",
    "if debug: print(phonologicalMap)\n",
    "neutralisationsNORD=(u\"6û\",u\"9ê\")\n",
    "neutralisationsSUD=(u\"e2o\",u\"E9O\")\n",
    "if phonologicalMap==\"-N\":\n",
    "    neutralisations=neutralisationsNORD\n",
    "elif phonologicalMap==\"-S\":\n",
    "    neutralisations=neutralisationsSUD\n",
    "else:\n",
    "    neutralisations=(u\"\",u\"\")\n",
    "    phonologicalMap=(\"-X\")\n",
    "bdlexiqueIn = unicode(u\"èò\"+neutralisations[0])\n",
    "bdlexiqueNum = [ord(char) for char in bdlexiqueIn]\n",
    "neutreOut = unicode(u\"EO\"+neutralisations[1])\n",
    "neutralise = dict(zip(bdlexiqueNum, neutreOut))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cliqueFile=\"2015-Data/\"+analysisPrefix+'-Network.pkl'\n",
    "#paradigmes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recoder(chaine,table=neutralise):\n",
    "    if type(chaine)==str:\n",
    "        temp=unicode(chaine.decode('utf8')).translate(table)\n",
    "        result=temp.encode('utf8')\n",
    "    elif type(chaine)==unicode:\n",
    "        result=chaine.translate(table)\n",
    "    else:\n",
    "        result=chaine\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "goldCases=paradigmes.columns.tolist()\n",
    "goldCases.remove(\"lexeme\")\n",
    "#goldCases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sampleCases pour la liste des cases effectivement représentées dans le corpus de départ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampleCases=paradigmes.columns.values.tolist()\n",
    "sampleCases.remove(u\"lexeme\")\n",
    "#sampleCases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition des objets pour la gestion des règles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class paireClasses:\n",
    "    def __init__(self,case1,case2):\n",
    "        self.case1=case1\n",
    "        self.case2=case2\n",
    "        self.nom=case1+\"-\"+case2\n",
    "        self.classes1=classesPaire(case1,case2)\n",
    "        self.classes2=classesPaire(case2,case1)\n",
    "\n",
    "    def ajouterPatron(self,n,patron,motif):\n",
    "        if n==1:\n",
    "            self.classes1.ajouterPatron(patron,motif)\n",
    "        elif n==2:\n",
    "            self.classes2.ajouterPatron(patron,motif)\n",
    "        else:\n",
    "            print (\"le numéro de forme n'est pas dans [1,2]\",n,file=logfile)\n",
    "\n",
    "    def ajouterPaire(self,forme1,forme2):\n",
    "        self.classes1.ajouterPaire(forme1,forme2)\n",
    "        self.classes2.ajouterPaire(forme2,forme1)\n",
    "        \n",
    "    def calculerClasses(self):\n",
    "        return(self.classes1,self.classes2)\n",
    "\n",
    "    \n",
    "class classesPaire:\n",
    "    '''\n",
    "    Gestion des patrons, des classes et des transformations\n",
    "    \n",
    "    ajouterPatron : ajoute un patron et son motif associé (MGL)\n",
    "    ajouterPaire : ajoute une paire de formes, calcule la classe de la forme1 et la règle sélectionnée\n",
    "    sortirForme : cacule les formes de sortie correspondant à la forme1 avec leurs coefficients respectifs\n",
    "    '''\n",
    "    def __init__(self,case1,case2):\n",
    "        self.case1=case1\n",
    "        self.case2=case2\n",
    "        self.nom=case1+\"-\"+case2\n",
    "        self.classe={}\n",
    "        self.nbClasse={}\n",
    "        self.patrons={}\n",
    "        self.entree={}\n",
    "        self.sortie={}\n",
    "    \n",
    "    def ajouterPatron(self,patron,motif):\n",
    "        self.patrons[patron]=motif\n",
    "        (entree,sortie)=patron.split(\"-\")\n",
    "        self.entree[patron]=entree.replace(u\".\",u\"(.)\")\n",
    "        self.sortie[patron]=remplacementSortie(sortie)\n",
    "    \n",
    "    def ajouterPaire(self,forme1,forme2):\n",
    "        '''\n",
    "        on calcule la classe de la paire idClasseForme et la règle sélectionnée\n",
    "        on incrémente le compteur de la classe et celui de la règle sélectionnée à l'intérieur de la classe\n",
    "        '''\n",
    "        classeForme=[]\n",
    "        regleForme=\"\"\n",
    "        for patron in self.patrons:\n",
    "            if re.match(self.patrons[patron],forme1):\n",
    "                classeForme.append(patron)\n",
    "                '''\n",
    "                le +\"$\" permet de forcer l'alignement à droite pour les transformations suffixales\n",
    "                '''\n",
    "                if forme2==re.sub(self.entree[patron]+\"$\",self.sortie[patron],forme1):\n",
    "                    regleForme=patron\n",
    "        idClasseForme=\", \".join(classeForme)\n",
    "        if not idClasseForme in self.classe:\n",
    "            self.classe[idClasseForme]={}\n",
    "            self.nbClasse[idClasseForme]=0\n",
    "        if not regleForme in self.classe[idClasseForme]:\n",
    "            self.classe[idClasseForme][regleForme]=0\n",
    "        self.nbClasse[idClasseForme]+=1\n",
    "        self.classe[idClasseForme][regleForme]+=1\n",
    "\n",
    "    def sortirForme(self,forme):\n",
    "        classeForme=[]\n",
    "        sortieForme={}\n",
    "        for patron in self.patrons:\n",
    "            if re.match(self.patrons[patron],forme):\n",
    "                classeForme.append(patron)\n",
    "        if classeForme:\n",
    "            idClasseForme=\", \".join(classeForme)\n",
    "            if idClasseForme in self.nbClasse:\n",
    "                nTotal=self.nbClasse[idClasseForme]\n",
    "                for patron in self.classe[idClasseForme]:\n",
    "                    sortie=re.sub(self.entree[patron]+\"$\",self.sortie[patron],forme)\n",
    "                    sortieForme[sortie]=float(self.classe[idClasseForme][patron])/nTotal\n",
    "            else:\n",
    "                if debug:\n",
    "                    print (forme, file=logfile)\n",
    "                    print (\"pas de classe\",idClasseForme, file=logfile)\n",
    "                    print (\"%.2f par forme de sortie\" % (float(1)/len(classeForme)), file=logfile)\n",
    "                nTotal=len(classeForme)\n",
    "                for patron in classeForme:\n",
    "                    sortie=re.sub(self.entree[patron]+\"$\",self.sortie[patron],forme)\n",
    "                    sortieForme[sortie]=float(1)/nTotal\n",
    "        else:\n",
    "            print (forme, file=logfile) \n",
    "            print (\"pas de patron\", file=logfile)\n",
    "        return sortieForme\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparer les cases analysées avec l'ensemble de toutes les cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"2015-Data/\"+analysisPrefix+'-Regles.pkl', 'rb') as input:\n",
    "    resultatsLecture = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'FP', u'FS', u'ai1P', u'ai1S', u'ai2P', u'ai2S', u'ai3P', u'ai3S', u'fi1P', u'fi1S', u'fi2P', u'fi2S', u'fi3P', u'fi3S', u'ii1P', u'ii1S', u'ii2P', u'ii2S', u'ii3P', u'ii3S', u'inf', u'is1P', u'is1S', u'is3P', u'is3S', u'pI1P', u'pI2P', u'pI2S', u'pP', u'pc1P', u'pc1S', u'pc2P', u'pc2S', u'pc3P', u'pc3S', u'pi1P', u'pi1S', u'pi2P', u'pi2S', u'pi3P', u'pi3S', u'ppFP', u'ppFS', u'ppMP', u'ppMS', u'ps1P', u'ps1S', u'ps2P', u'ps2S', u'ps3P', u'ps3S']\n"
     ]
    }
   ],
   "source": [
    "analyseCases=list(set([case for (case,autre) in resultatsLecture.keys() if autre in [\"FP\"]]))\n",
    "print (sorted(analyseCases))\n",
    "#    analyseCases=sampleCases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculer le score de la clique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cliqueScore(clique,graph):\n",
    "    score=0\n",
    "    for (depart,arrivee) in it.combinations_with_replacement(clique,2):\n",
    "        score+=graph[depart][arrivee][\"weight\"]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération des formes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "basesDerives=pd.read_csv(\"2015-Data/MGC-160104-01-N-basesDerives.csv\",sep=\";\",encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"2015-Data/\"+analysisPrefix+'-Network.pkl', 'rb') as input:\n",
    "    infoCliques=pickle.load(input)\n",
    "cliques=infoCliques[\"cliques\"]\n",
    "cliquesScores=infoCliques[\"cliquesScores\"]\n",
    "cliquesListes=infoCliques[\"cliquesListes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cliques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listeTest=list(set(case[0].split(\"-\")[0] for case in cliques))\n",
    "len(listeTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analyseCases=list(set(case.split(\"-\")[-1] for clique in cliques for case in clique ))\n",
    "#sorted(analyseCases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 448,\n",
       " 3: 796,\n",
       " 4: 923,\n",
       " 5: 1437,\n",
       " 6: 1942,\n",
       " 7: 2101,\n",
       " 8: 1982,\n",
       " 9: 1918,\n",
       " 10: 2179,\n",
       " 11: 2022,\n",
       " 12: 1847,\n",
       " 13: 1732,\n",
       " 14: 1747,\n",
       " 15: 1500,\n",
       " 16: 1480,\n",
       " 17: 1600,\n",
       " 18: 1605,\n",
       " 19: 1761,\n",
       " 20: 1501,\n",
       " 21: 1504,\n",
       " 22: 1932,\n",
       " 23: 2204,\n",
       " 24: 1721,\n",
       " 25: 1129,\n",
       " 26: 773,\n",
       " 27: 574,\n",
       " 28: 578,\n",
       " 29: 463,\n",
       " 30: 254,\n",
       " 31: 209,\n",
       " 32: 133,\n",
       " 33: 45,\n",
       " 34: 24,\n",
       " 35: 26,\n",
       " 36: 30,\n",
       " 37: 12,\n",
       " 38: 1,\n",
       " 39: 9,\n",
       " 40: 2,\n",
       " 44: 1}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longueurCliques={}\n",
    "for clique in cliques:\n",
    "    longueur=len(clique)\n",
    "    if not longueur in longueurCliques:\n",
    "        longueurCliques[longueur]=1\n",
    "    else:\n",
    "        longueurCliques[longueur]+=1\n",
    "longueurCliques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faire la liste des cases lexicalisées de l'échantillon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nbFormesLexicales={}\n",
    "casesLexicales={element:paradigmes[paradigmes[\"lexeme\"]==element].columns[paradigmes[paradigmes[\"lexeme\"]==element].notnull().iloc[0]].tolist() for element in listeTest}\n",
    "for element in casesLexicales:\n",
    "    casesLexicales[element].remove(\"lexeme\")\n",
    "    nbFormesLexicales[element]=len(casesLexicales[element])\n",
    "#nbFormesLexicales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cliques2Tableau(cliques):\n",
    "    paradigmesListe=[]\n",
    "    for n,clique in enumerate(cliques):\n",
    "        paradigmeClique={}\n",
    "        for element in clique:\n",
    "            elements=element.split(\"-\")\n",
    "            lexeme=elements[0]\n",
    "            nbInitial=len(casesLexicales[lexeme])\n",
    "            forme=elements[-2]\n",
    "            taminfo=elements[-1]\n",
    "            paradigmeClique[taminfo]=forme\n",
    "        paradigmeClique[\"lexeme\"]=lexeme\n",
    "        paradigmeClique[\"score\"]=cliquesScores[n]\n",
    "        paradigmeClique[\"ajouts\"]=len(clique)-nbInitial\n",
    "        paradigmesListe.append(paradigmeClique)\n",
    "    return pd.DataFrame(paradigmesListe,columns=[\"lexeme\"]+analyseCases+[u\"score\",u\"ajouts\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cliquesPANDAS=cliques2Tableau(cliques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtreDERIVE=~(cliquesPANDAS[\"FS\"].isnull() & cliquesPANDAS[\"FP\"].isnull())\n",
    "cliquesDERIVES=cliquesPANDAS[filtreDERIVE]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "for n,derive in enumerate(set(cliquesDERIVES[\"lexeme\"].dropna().tolist())):\n",
    "    print (n,derive)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#cliquesDERIVES\n",
    "for lexeme in listeTest:\n",
    "    print (paradigmes[paradigmes[\"lexeme\"]==lexeme].to_dict(orient=\"list\")[\"pi3S\"])\n",
    "    for index,row in cliquesDERIVES[cliquesDERIVES[\"lexeme\"]==lexeme].iterrows():\n",
    "#        print (index,row)\n",
    "        print (row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fideliteLexique(numero,clique):\n",
    "    formesLexicales=[]\n",
    "    paradigmeClique={}\n",
    "    formesPresentes=[]\n",
    "    formesAbsentes=[]\n",
    "    #####################\n",
    "    #Prépararer la représentation lexicale\n",
    "    #####################\n",
    "    #\n",
    "    # transformer les cases lexicales en points\n",
    "    # au format clique pour comparaison\n",
    "    #\n",
    "    #####################\n",
    "\n",
    "    #####################\n",
    "    #Identifier le lexème\n",
    "    #####################\n",
    "    point=clique[0].split(\"-\")\n",
    "    lPoint=len(point)\n",
    "    if lPoint==3:\n",
    "        lexeme=point[0]\n",
    "    else:\n",
    "        lexeme=\"-\".join(point[0:len(point)-2])\n",
    "    paradigmeClique[\"lexeme\"]=lexeme\n",
    "    #####################\n",
    "    #Nombre de cases lexicales\n",
    "    #####################\n",
    "    casesLexeme=casesLexicales[lexeme]\n",
    "    nbCasesLexicales=len(casesLexeme)\n",
    "    nbFormesLexicales=nbCasesLexicales\n",
    "    #####################\n",
    "    #Transformation des cases lexicales\n",
    "    #####################\n",
    "    if casesLexeme:\n",
    "        for element in casesLexeme:\n",
    "            champForme=paradigmes[paradigmes[\"lexeme\"]==lexeme][element].iloc[0]\n",
    "            if \",\"  in champForme:\n",
    "                formes=champForme.split(\",\")\n",
    "                nbFormesLexicales+=len(formes)-1\n",
    "                for forme in formes:\n",
    "                    pointCase=u\"%s-%s-%s\"% (lexeme,forme,element)\n",
    "                    formesLexicales.append(pointCase)\n",
    "                    if pointCase in clique:\n",
    "                        formesPresentes.append(pointCase)\n",
    "                    else:\n",
    "                        formesAbsentes.append(pointCase)\n",
    "            else:\n",
    "                forme=champForme\n",
    "                pointCase=u\"%s-%s-%s\"% (lexeme,forme,element)\n",
    "                formesLexicales.append(pointCase)\n",
    "                if pointCase in clique:\n",
    "                    formesPresentes.append(pointCase)\n",
    "                else:\n",
    "                    formesAbsentes.append(pointCase)\n",
    "\n",
    "    #######################################\n",
    "    #\n",
    "    # Compter les formes fidèles\n",
    "    # Préparer le résultat\n",
    "    #\n",
    "    #######################################\n",
    "    for element in clique:\n",
    "        elements=element.split(\"-\")\n",
    "        forme=elements[-2]\n",
    "        taminfo=elements[-1]\n",
    "        paradigmeClique[taminfo]=forme\n",
    "    paradigmeClique[\"score\"]=cliquesScores[numero]\n",
    "    paradigmeClique[\"ajouts\"]=len(clique)-len(formesPresentes)\n",
    "    paradigmeClique[\"lexOk\"]=len(formesPresentes)\n",
    "    paradigmeClique[\"lexMiss\"]=len(formesAbsentes)\n",
    "    return (paradigmeClique,formesPresentes,formesAbsentes,formesLexicales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({u'ai1S': u'akrwasi',\n",
       "  u'ai3P': u'akrwasir',\n",
       "  'ajouts': 11,\n",
       "  u'ii1S': u'akrwasE',\n",
       "  u'ii2S': u'akrwasE',\n",
       "  u'ii3P': u'akrwasE',\n",
       "  u'ii3S': u'akrwasE',\n",
       "  u'inf': u'akrwasr',\n",
       "  'lexMiss': 4,\n",
       "  'lexOk': 1,\n",
       "  'lexeme': u'accro\\xeetre',\n",
       "  u'pI1P': u'akrwas\\xf4',\n",
       "  u'pI2P': u'akrwase',\n",
       "  u'pP': u'akrwas\\xe2',\n",
       "  u'pi2P': u'akrwase',\n",
       "  u'pi3P': u'akrwas',\n",
       "  'score': 13.94690794387567},\n",
       " [u'accro\\xeetre-akrwasE-ii3S'],\n",
       " [u'accro\\xeetre-akry-ppMS',\n",
       "  u'accro\\xeetre-akrwatr-inf',\n",
       "  u'accro\\xeetre-akrwa-pi3S',\n",
       "  u'accro\\xeetre-akry-ai3S'],\n",
       " [u'accro\\xeetre-akry-ppMS',\n",
       "  u'accro\\xeetre-akrwasE-ii3S',\n",
       "  u'accro\\xeetre-akrwatr-inf',\n",
       "  u'accro\\xeetre-akrwa-pi3S',\n",
       "  u'accro\\xeetre-akry-ai3S'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=204\n",
    "fideliteLexique(n,cliques[n])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparer la sortie des cliques avec le paradigme de départ"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "%%time\n",
    "seuilClique=1\n",
    "#paradigmesCLIQUES=pd.DataFrame(columns=paradigmes.columns.values.tolist())\n",
    "paradigmesListe=[]\n",
    "#for n,clique in enumerate(sorted(cliques,key=lambda x: len(x),reverse=True)):\n",
    "progressBar = FloatProgress(min=0, max=len(cliques))\n",
    "display(progressBar)\n",
    "for n,clique in enumerate(cliques):\n",
    "    progressBar.value=n\n",
    "#    if seuilClique==0:\n",
    "#        seuilClique=len(clique)-15\n",
    "    if len(clique)>seuilClique:\n",
    "        paradigmeClique={}\n",
    "        sampleOK=True\n",
    "#        print (n, len(clique))\n",
    "        point=clique[0].split(\"-\")\n",
    "        lPoint=len(point)\n",
    "#        print (point,\"-\".join(point[0:len(point)-2]))\n",
    "        if lPoint==3:\n",
    "            lexeme=point[0]\n",
    "        else:\n",
    "            lexeme=\"-\".join(point[0:len(point)-2])\n",
    "        paradigmeClique[\"lexeme\"]=lexeme\n",
    "#        if n%5000==0: print (n,int(100*float(n)/len(cliques)),end=\", \")\n",
    "#        casesLexeme=paradigmes[paradigmes[\"lexeme\"]==lexeme].notnull().columns.tolist()\n",
    "#        casesLexeme=paradigmes[paradigmes[\"lexeme\"]==lexeme].columns[paradigmes[paradigmes[\"lexeme\"]==lexeme].notnull().iloc[0]].tolist()\n",
    "#        casesLexeme.remove(\"lexeme\")\n",
    "        casesLexeme=casesLexicales[lexeme]\n",
    "        nbInitial=len(casesLexeme)\n",
    "        if casesLexeme and len(casesLexeme)<=len(clique):\n",
    "            for element in casesLexeme:\n",
    "#                print (lexeme,element, paradigmes[paradigmes[\"lexeme\"]==lexeme][element])\n",
    "                champForme=paradigmes[paradigmes[\"lexeme\"]==lexeme][element].iloc[0]\n",
    "                if \",\"  in champForme:\n",
    "                    formes=champForme.split(\",\")\n",
    "                    nbInitial+=len(formes)-1\n",
    "                    okFormes=False\n",
    "                    for forme in formes:\n",
    "                        pointCase=u\"%s-%s-%s\"% (lexeme,forme,element)\n",
    "#                        if debug: print (pointCase, clique)\n",
    "                        if pointCase in clique:\n",
    "                            okFormes=True\n",
    "                            if debug: print (\"point\",pointCase)\n",
    "#                            print (\"clique\",clique)\n",
    "                            if debug: print (\"gold\",GOLD[GOLD[\"lexeme\"]==lexeme][element])\n",
    "                    if okFormes:\n",
    "                        sampleOK=True\n",
    "                    else:\n",
    "                        sampleOK=False\n",
    "                        break\n",
    "                else:\n",
    "                    forme=champForme\n",
    "                    pointCase=u\"%s-%s-%s\"% (lexeme,forme,element)\n",
    "                    if debug: print (pointCase, clique)\n",
    "                    if not pointCase in clique:\n",
    "                        sampleOK=False\n",
    "#                        print (\"point\",pointCase)\n",
    "#                        print (\"clique\",clique)\n",
    "#                        print (\"gold\",GOLD[GOLD[\"lexeme\"]==lexeme][element])\n",
    "                        break\n",
    "        else:\n",
    "            sampleOK=False\n",
    "        if sampleOK:\n",
    "            for element in clique:\n",
    "                elements=element.split(\"-\")\n",
    "                forme=elements[-2]\n",
    "                taminfo=elements[-1]\n",
    "#                try:\n",
    "#                 (lexeme,forme,taminfo)=element.split(\"-\")\n",
    "#                except ValueError:\n",
    "#                    print (element)\n",
    "                paradigmeClique[taminfo]=forme\n",
    "#                if taminfo in paradigmes.columns:\n",
    "#                    if not paradigmes[(paradigmes[\"lexeme\"]==lexeme)][taminfo].isnull().item():\n",
    "#                        if paradigmes[(paradigmes[\"lexeme\"]==lexeme)][taminfo].item()!=forme:\n",
    "#                            sampleOK=False\n",
    "#                            print (paradigmes[(paradigmes[\"lexeme\"]==lexeme)][taminfo].item(),forme,taminfo,end=\", \")\n",
    "#            if n<100: print (clique==cliquesListes[n])\n",
    "            paradigmeClique[\"score\"]=cliquesScores[n]\n",
    "            paradigmeClique[\"ajouts\"]=len(clique)-nbInitial\n",
    "#            print (cliqueScore(clique),clique)\n",
    "            paradigmesListe.append(paradigmeClique)\n",
    "        else:\n",
    "            if debug:\n",
    "                print ()\n",
    "                print (lexeme,clique)\n",
    "                print ()\n",
    "#    else:\n",
    "#        print (\"break\")\n",
    "#        print (n,lexeme,clique)\n",
    "#        break\n",
    "\n",
    "#paradigmesCLIQUES=pd.DataFrame(paradigmesListe,columns=GOLD.columns.values.tolist()+[u\"score\",u\"ajouts\"])\n",
    "paradigmesCLIQUES=pd.DataFrame(paradigmesListe,columns=[\"lexeme\"]+analyseCases+[u\"score\",u\"ajouts\"])\n",
    "#print (seuilClique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 43s, sys: 13.8 s, total: 13min 57s\n",
      "Wall time: 14min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seuilClique=1\n",
    "#paradigmesCLIQUES=pd.DataFrame(columns=paradigmes.columns.values.tolist())\n",
    "paradigmesListe=[]\n",
    "#for n,clique in enumerate(sorted(cliques,key=lambda x: len(x),reverse=True)):\n",
    "progressBar = FloatProgress(min=0, max=len(cliques))\n",
    "display(progressBar)\n",
    "for n,clique in enumerate(cliques):\n",
    "    progressBar.value=n\n",
    "#    if seuilClique==0:\n",
    "#        seuilClique=len(clique)-15\n",
    "    if len(clique)>seuilClique:\n",
    "        (paradigmeClique,formesPresentes,formesAbsentes,formesLexicales)=fideliteLexique(n,clique)\n",
    "        paradigmesListe.append(paradigmeClique)\n",
    "#paradigmesCLIQUES=pd.DataFrame(paradigmesListe,columns=GOLD.columns.values.tolist()+[u\"score\",u\"ajouts\"])\n",
    "paradigmesCLIQUES=pd.DataFrame(paradigmesListe,columns=[\"lexeme\"]+analyseCases+[u\"score\",u\"ajouts\",u\"lexOk\",u\"lexMiss\"])\n",
    "#print (seuilClique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paradigmesCLIQUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtreCLIQUES=~(paradigmesCLIQUES[\"FS\"].isnull() & paradigmesCLIQUES[\"FP\"].isnull())\n",
    "paradigmesFILTRES=paradigmesCLIQUES[filtreCLIQUES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def maxColonne(table,listeGroupe,colonne):\n",
    "    return table[table.groupby(listeGroupe)[colonne].transform(max)==table[colonne]]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "paradigmeMAX=paradigmesFILTRES[paradigmesFILTRES[\"score\"]==paradigmesFILTRES.groupby([\"lexeme\"])[\"score\"].transform(max)].reset_index()\n",
    "del paradigmeMAX[\"index\"]\n",
    "paradigmeSILVER=paradigmeMAX.groupby(\"lexeme\").agg(lambda x: \",\".join(list(set(x.dropna().values)))).reset_index()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "paradigmeMAX=paradigmesCLIQUES[paradigmesCLIQUES[\"score\"]==paradigmesCLIQUES.groupby([\"lexeme\"])[\"score\"].transform(max)].reset_index()\n",
    "del paradigmeMAX[\"index\"]\n",
    "paradigmeSILVER=paradigmeMAX.groupby(\"lexeme\").agg(lambda x: \",\".join(list(set(x.dropna().values)))).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lexeme</th>\n",
       "      <th>FS</th>\n",
       "      <th>FP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>absoudre</td>\n",
       "      <td>absut</td>\n",
       "      <td>absut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>accalmir</td>\n",
       "      <td>akalmire</td>\n",
       "      <td>akalmire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>accroître</td>\n",
       "      <td>akrwat</td>\n",
       "      <td>akrwat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>agonir</td>\n",
       "      <td>agOnit</td>\n",
       "      <td>agOnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>aller</td>\n",
       "      <td>vat</td>\n",
       "      <td>vat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>arriver</td>\n",
       "      <td>arive</td>\n",
       "      <td>arive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>asseoir</td>\n",
       "      <td>aswat</td>\n",
       "      <td>aswat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>astreindre</td>\n",
       "      <td>astrêt</td>\n",
       "      <td>astrêt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1558</th>\n",
       "      <td>atteindre</td>\n",
       "      <td>atêt</td>\n",
       "      <td>atêt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1735</th>\n",
       "      <td>attendre</td>\n",
       "      <td>atât</td>\n",
       "      <td>atât</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1869</th>\n",
       "      <td>avancer</td>\n",
       "      <td>avâse</td>\n",
       "      <td>avâse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>battre</td>\n",
       "      <td>bat</td>\n",
       "      <td>bat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179</th>\n",
       "      <td>branler</td>\n",
       "      <td>brâlet</td>\n",
       "      <td>brâlet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260</th>\n",
       "      <td>briser</td>\n",
       "      <td>brize</td>\n",
       "      <td>brize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290</th>\n",
       "      <td>buer</td>\n",
       "      <td>bHe</td>\n",
       "      <td>bHe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2408</th>\n",
       "      <td>buter</td>\n",
       "      <td>bytet</td>\n",
       "      <td>bytet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>charpir</td>\n",
       "      <td>Sarpit</td>\n",
       "      <td>Sarpit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2666</th>\n",
       "      <td>chevaucher</td>\n",
       "      <td>S9vOSe</td>\n",
       "      <td>S9vOSe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2709</th>\n",
       "      <td>choir</td>\n",
       "      <td>Syt</td>\n",
       "      <td>Syt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2740</th>\n",
       "      <td>complaindre</td>\n",
       "      <td>kôplêt</td>\n",
       "      <td>kôplêt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>conduire</td>\n",
       "      <td>kôdHit</td>\n",
       "      <td>kôdHit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3758</th>\n",
       "      <td>conquérir</td>\n",
       "      <td>kôkEt</td>\n",
       "      <td>kôkEt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4005</th>\n",
       "      <td>contraindre</td>\n",
       "      <td>kôtrêt</td>\n",
       "      <td>kôtrêt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007</th>\n",
       "      <td>couler</td>\n",
       "      <td>kulet</td>\n",
       "      <td>kulet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4143</th>\n",
       "      <td>courir</td>\n",
       "      <td>kurs</td>\n",
       "      <td>kurs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4216</th>\n",
       "      <td>couver</td>\n",
       "      <td>kuve</td>\n",
       "      <td>kuve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4493</th>\n",
       "      <td>couvrir</td>\n",
       "      <td>kuvrt</td>\n",
       "      <td>kuvrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4671</th>\n",
       "      <td>craindre</td>\n",
       "      <td>krêt</td>\n",
       "      <td>krêt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5098</th>\n",
       "      <td>crier</td>\n",
       "      <td>krit</td>\n",
       "      <td>krit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>croiser</td>\n",
       "      <td>krwaze</td>\n",
       "      <td>krwaze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36313</th>\n",
       "      <td>surtondre</td>\n",
       "      <td>syrtôt</td>\n",
       "      <td>syrtôt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36403</th>\n",
       "      <td>survenir</td>\n",
       "      <td>syrvjêt</td>\n",
       "      <td>syrvjêt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36579</th>\n",
       "      <td>survivre</td>\n",
       "      <td>syrvive</td>\n",
       "      <td>syrvive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36748</th>\n",
       "      <td>tabasser</td>\n",
       "      <td>tabase</td>\n",
       "      <td>tabase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36799</th>\n",
       "      <td>teindre</td>\n",
       "      <td>têt</td>\n",
       "      <td>têt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36968</th>\n",
       "      <td>tendre</td>\n",
       "      <td>tât</td>\n",
       "      <td>tât</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37254</th>\n",
       "      <td>tenir</td>\n",
       "      <td>tjêt</td>\n",
       "      <td>tjêt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37350</th>\n",
       "      <td>tomber</td>\n",
       "      <td>tôbet</td>\n",
       "      <td>tôbet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37456</th>\n",
       "      <td>tondre</td>\n",
       "      <td>tôt</td>\n",
       "      <td>tôt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37891</th>\n",
       "      <td>torcher</td>\n",
       "      <td>tOrSet</td>\n",
       "      <td>tOrSet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37915</th>\n",
       "      <td>touer</td>\n",
       "      <td>tut</td>\n",
       "      <td>tut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38139</th>\n",
       "      <td>traire</td>\n",
       "      <td>trEt</td>\n",
       "      <td>trEt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38241</th>\n",
       "      <td>trancher</td>\n",
       "      <td>trâSe</td>\n",
       "      <td>trâSe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38383</th>\n",
       "      <td>traverser</td>\n",
       "      <td>travErset</td>\n",
       "      <td>travErset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38833</th>\n",
       "      <td>trouer</td>\n",
       "      <td>trut</td>\n",
       "      <td>trut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38860</th>\n",
       "      <td>téter</td>\n",
       "      <td>tEtet</td>\n",
       "      <td>tEtet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39118</th>\n",
       "      <td>veiller</td>\n",
       "      <td>vEje</td>\n",
       "      <td>vEje</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39201</th>\n",
       "      <td>vendre</td>\n",
       "      <td>vât</td>\n",
       "      <td>vât</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39538</th>\n",
       "      <td>venir</td>\n",
       "      <td>vjêt</td>\n",
       "      <td>vjêt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39661</th>\n",
       "      <td>virer</td>\n",
       "      <td>vire</td>\n",
       "      <td>vire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40012</th>\n",
       "      <td>viser</td>\n",
       "      <td>vize</td>\n",
       "      <td>vize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40541</th>\n",
       "      <td>vivre</td>\n",
       "      <td>vive</td>\n",
       "      <td>vive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40770</th>\n",
       "      <td>voir</td>\n",
       "      <td>vwat</td>\n",
       "      <td>vwat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40817</th>\n",
       "      <td>voler</td>\n",
       "      <td>vOlet</td>\n",
       "      <td>vOlet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40938</th>\n",
       "      <td>échapper</td>\n",
       "      <td>ESapet</td>\n",
       "      <td>ESapet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41353</th>\n",
       "      <td>éclaircir</td>\n",
       "      <td>EklErsit</td>\n",
       "      <td>EklErsit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41564</th>\n",
       "      <td>émouvoir</td>\n",
       "      <td>Em2t</td>\n",
       "      <td>Em2t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41750</th>\n",
       "      <td>étendre</td>\n",
       "      <td>Etât</td>\n",
       "      <td>Etât</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42053</th>\n",
       "      <td>étreindre</td>\n",
       "      <td>Etrêt</td>\n",
       "      <td>Etrêt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42141</th>\n",
       "      <td>étuver</td>\n",
       "      <td>Etyve</td>\n",
       "      <td>Etyve</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            lexeme         FS         FP\n",
       "41        absoudre      absut      absut\n",
       "98        accalmir   akalmire   akalmire\n",
       "160      accroître     akrwat     akrwat\n",
       "400         agonir     agOnit     agOnit\n",
       "586          aller        vat        vat\n",
       "900        arriver      arive      arive\n",
       "1143       asseoir      aswat      aswat\n",
       "1376    astreindre     astrêt     astrêt\n",
       "1558     atteindre       atêt       atêt\n",
       "1735      attendre       atât       atât\n",
       "1869       avancer      avâse      avâse\n",
       "1960        battre        bat        bat\n",
       "2179       branler     brâlet     brâlet\n",
       "2260        briser      brize      brize\n",
       "2290          buer        bHe        bHe\n",
       "2408         buter      bytet      bytet\n",
       "2582       charpir     Sarpit     Sarpit\n",
       "2666    chevaucher     S9vOSe     S9vOSe\n",
       "2709         choir        Syt        Syt\n",
       "2740   complaindre     kôplêt     kôplêt\n",
       "3608      conduire     kôdHit     kôdHit\n",
       "3758     conquérir      kôkEt      kôkEt\n",
       "4005   contraindre     kôtrêt     kôtrêt\n",
       "4007        couler      kulet      kulet\n",
       "4143        courir       kurs       kurs\n",
       "4216        couver       kuve       kuve\n",
       "4493       couvrir      kuvrt      kuvrt\n",
       "4671      craindre       krêt       krêt\n",
       "5098         crier       krit       krit\n",
       "5226       croiser     krwaze     krwaze\n",
       "...            ...        ...        ...\n",
       "36313    surtondre     syrtôt     syrtôt\n",
       "36403     survenir    syrvjêt    syrvjêt\n",
       "36579     survivre    syrvive    syrvive\n",
       "36748     tabasser     tabase     tabase\n",
       "36799      teindre        têt        têt\n",
       "36968       tendre        tât        tât\n",
       "37254        tenir       tjêt       tjêt\n",
       "37350       tomber      tôbet      tôbet\n",
       "37456       tondre        tôt        tôt\n",
       "37891      torcher     tOrSet     tOrSet\n",
       "37915        touer        tut        tut\n",
       "38139       traire       trEt       trEt\n",
       "38241     trancher      trâSe      trâSe\n",
       "38383    traverser  travErset  travErset\n",
       "38833       trouer       trut       trut\n",
       "38860        téter      tEtet      tEtet\n",
       "39118      veiller       vEje       vEje\n",
       "39201       vendre        vât        vât\n",
       "39538        venir       vjêt       vjêt\n",
       "39661        virer       vire       vire\n",
       "40012        viser       vize       vize\n",
       "40541        vivre       vive       vive\n",
       "40770         voir       vwat       vwat\n",
       "40817        voler      vOlet      vOlet\n",
       "40938     échapper     ESapet     ESapet\n",
       "41353    éclaircir   EklErsit   EklErsit\n",
       "41564     émouvoir       Em2t       Em2t\n",
       "41750      étendre       Etât       Etât\n",
       "42053    étreindre      Etrêt      Etrêt\n",
       "42141       étuver      Etyve      Etyve\n",
       "\n",
       "[185 rows x 3 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paradigmesMaxLex=maxColonne(paradigmesFILTRES,[\"lexeme\"],\"lexOk\")\n",
    "paradigmesMaxScore=maxColonne(paradigmesMaxLex,[\"lexeme\"],\"score\")\n",
    "paradigmeMAX=paradigmesMaxScore\n",
    "paradigmeMAX[[\"lexeme\",\"FS\",\"FP\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paradigmeSILVER=pd.merge(paradigmes,paradigmeMAX,on=[\"lexeme\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lexeme</th>\n",
       "      <th>FS_y</th>\n",
       "      <th>FP_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>absoudre</td>\n",
       "      <td>absut</td>\n",
       "      <td>absut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accalmir</td>\n",
       "      <td>akalmire</td>\n",
       "      <td>akalmire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accroître</td>\n",
       "      <td>akrwat</td>\n",
       "      <td>akrwat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>agonir</td>\n",
       "      <td>agOnit</td>\n",
       "      <td>agOnit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aller</td>\n",
       "      <td>vat</td>\n",
       "      <td>vat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>asseoir</td>\n",
       "      <td>aswat</td>\n",
       "      <td>aswat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>astreindre</td>\n",
       "      <td>astrêt</td>\n",
       "      <td>astrêt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>atteindre</td>\n",
       "      <td>atêt</td>\n",
       "      <td>atêt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>avancer</td>\n",
       "      <td>avâse</td>\n",
       "      <td>avâse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>battre</td>\n",
       "      <td>bat</td>\n",
       "      <td>bat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>branler</td>\n",
       "      <td>brâlet</td>\n",
       "      <td>brâlet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>briser</td>\n",
       "      <td>brize</td>\n",
       "      <td>brize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>buer</td>\n",
       "      <td>bHe</td>\n",
       "      <td>bHe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>buter</td>\n",
       "      <td>bytet</td>\n",
       "      <td>bytet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>charpir</td>\n",
       "      <td>Sarpit</td>\n",
       "      <td>Sarpit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>complaindre</td>\n",
       "      <td>kôplêt</td>\n",
       "      <td>kôplêt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>conduire</td>\n",
       "      <td>kôdHit</td>\n",
       "      <td>kôdHit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>conquérir</td>\n",
       "      <td>kôkEt</td>\n",
       "      <td>kôkEt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>couler</td>\n",
       "      <td>kulet</td>\n",
       "      <td>kulet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>couver</td>\n",
       "      <td>kuve</td>\n",
       "      <td>kuve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>couvrir</td>\n",
       "      <td>kuvrt</td>\n",
       "      <td>kuvrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>crier</td>\n",
       "      <td>krit</td>\n",
       "      <td>krit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>croiser</td>\n",
       "      <td>krwaze</td>\n",
       "      <td>krwaze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>croître</td>\n",
       "      <td>krwat</td>\n",
       "      <td>krwat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>cueillir</td>\n",
       "      <td>k9jit</td>\n",
       "      <td>k9jit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>cuire</td>\n",
       "      <td>kHit</td>\n",
       "      <td>kHit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>desservir</td>\n",
       "      <td>dEsErvit</td>\n",
       "      <td>dEsErvit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>devoir</td>\n",
       "      <td>dwat</td>\n",
       "      <td>dwat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>dicter</td>\n",
       "      <td>diktet</td>\n",
       "      <td>diktet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>durer</td>\n",
       "      <td>dyre</td>\n",
       "      <td>dyre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>saillir</td>\n",
       "      <td>sajit</td>\n",
       "      <td>sajit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>saisir</td>\n",
       "      <td>sEzit</td>\n",
       "      <td>sEzit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>saucer</td>\n",
       "      <td>sOse</td>\n",
       "      <td>sOse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>secouer</td>\n",
       "      <td>s9kut</td>\n",
       "      <td>s9kut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>seringuer</td>\n",
       "      <td>s9rêget</td>\n",
       "      <td>s9rêget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>sortir</td>\n",
       "      <td>sOrt</td>\n",
       "      <td>sOrt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>souquer</td>\n",
       "      <td>suket</td>\n",
       "      <td>suket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>suer</td>\n",
       "      <td>syt</td>\n",
       "      <td>syt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>surtondre</td>\n",
       "      <td>syrtôt</td>\n",
       "      <td>syrtôt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>survenir</td>\n",
       "      <td>syrvjêt</td>\n",
       "      <td>syrvjêt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>survivre</td>\n",
       "      <td>syrvive</td>\n",
       "      <td>syrvive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>tabasser</td>\n",
       "      <td>tabase</td>\n",
       "      <td>tabase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>tenir</td>\n",
       "      <td>tjêt</td>\n",
       "      <td>tjêt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>tomber</td>\n",
       "      <td>tôbet</td>\n",
       "      <td>tôbet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>tondre</td>\n",
       "      <td>tôt</td>\n",
       "      <td>tôt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>torcher</td>\n",
       "      <td>tOrSet</td>\n",
       "      <td>tOrSet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>touer</td>\n",
       "      <td>tut</td>\n",
       "      <td>tut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>traverser</td>\n",
       "      <td>travErset</td>\n",
       "      <td>travErset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>trouer</td>\n",
       "      <td>trut</td>\n",
       "      <td>trut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>téter</td>\n",
       "      <td>tEtet</td>\n",
       "      <td>tEtet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>vendre</td>\n",
       "      <td>vât</td>\n",
       "      <td>vât</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>venir</td>\n",
       "      <td>vjêt</td>\n",
       "      <td>vjêt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>viser</td>\n",
       "      <td>vize</td>\n",
       "      <td>vize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>vivre</td>\n",
       "      <td>vive</td>\n",
       "      <td>vive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>voir</td>\n",
       "      <td>vwat</td>\n",
       "      <td>vwat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>voler</td>\n",
       "      <td>vOlet</td>\n",
       "      <td>vOlet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>échapper</td>\n",
       "      <td>ESapet</td>\n",
       "      <td>ESapet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>éclaircir</td>\n",
       "      <td>EklErsit</td>\n",
       "      <td>EklErsit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>étendre</td>\n",
       "      <td>Etât</td>\n",
       "      <td>Etât</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>étuver</td>\n",
       "      <td>Etyve</td>\n",
       "      <td>Etyve</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          lexeme       FS_y       FP_y\n",
       "0       absoudre      absut      absut\n",
       "1       accalmir   akalmire   akalmire\n",
       "2      accroître     akrwat     akrwat\n",
       "3         agonir     agOnit     agOnit\n",
       "4          aller        vat        vat\n",
       "6        asseoir      aswat      aswat\n",
       "7     astreindre     astrêt     astrêt\n",
       "8      atteindre       atêt       atêt\n",
       "10       avancer      avâse      avâse\n",
       "11        battre        bat        bat\n",
       "12       branler     brâlet     brâlet\n",
       "13        briser      brize      brize\n",
       "14          buer        bHe        bHe\n",
       "15         buter      bytet      bytet\n",
       "16       charpir     Sarpit     Sarpit\n",
       "19   complaindre     kôplêt     kôplêt\n",
       "20      conduire     kôdHit     kôdHit\n",
       "21     conquérir      kôkEt      kôkEt\n",
       "23        couler      kulet      kulet\n",
       "25        couver       kuve       kuve\n",
       "26       couvrir      kuvrt      kuvrt\n",
       "28         crier       krit       krit\n",
       "29       croiser     krwaze     krwaze\n",
       "30       croître      krwat      krwat\n",
       "31      cueillir      k9jit      k9jit\n",
       "32         cuire       kHit       kHit\n",
       "34     desservir   dEsErvit   dEsErvit\n",
       "35        devoir       dwat       dwat\n",
       "36        dicter     diktet     diktet\n",
       "37         durer       dyre       dyre\n",
       "..           ...        ...        ...\n",
       "145      saillir      sajit      sajit\n",
       "146       saisir      sEzit      sEzit\n",
       "147       saucer       sOse       sOse\n",
       "148      secouer      s9kut      s9kut\n",
       "149    seringuer    s9rêget    s9rêget\n",
       "150       sortir       sOrt       sOrt\n",
       "151      souquer      suket      suket\n",
       "152         suer        syt        syt\n",
       "155    surtondre     syrtôt     syrtôt\n",
       "156     survenir    syrvjêt    syrvjêt\n",
       "157     survivre    syrvive    syrvive\n",
       "158     tabasser     tabase     tabase\n",
       "161        tenir       tjêt       tjêt\n",
       "162       tomber      tôbet      tôbet\n",
       "163       tondre        tôt        tôt\n",
       "164      torcher     tOrSet     tOrSet\n",
       "165        touer        tut        tut\n",
       "168    traverser  travErset  travErset\n",
       "169       trouer       trut       trut\n",
       "170        téter      tEtet      tEtet\n",
       "172       vendre        vât        vât\n",
       "173        venir       vjêt       vjêt\n",
       "175        viser       vize       vize\n",
       "176        vivre       vive       vive\n",
       "177         voir       vwat       vwat\n",
       "178        voler      vOlet      vOlet\n",
       "179     échapper     ESapet     ESapet\n",
       "180    éclaircir   EklErsit   EklErsit\n",
       "182      étendre       Etât       Etât\n",
       "184       étuver      Etyve      Etyve\n",
       "\n",
       "[138 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtreNouveauxDerivesSILVER=(paradigmeSILVER[\"FS_x\"].isnull() & paradigmeSILVER[\"FP_x\"].isnull())\n",
    "filtreFsLexSILVER=(paradigmeSILVER[\"FS_x\"].notnull() &\n",
    "    (paradigmeSILVER[\"FS_x\"]!=paradigmeSILVER[\"FS_y\"]) \n",
    "    )\n",
    "filtreFpLexSILVER=(paradigmeSILVER[\"FP_x\"].notnull() &\n",
    "    (paradigmeSILVER[\"FP_x\"]!=paradigmeSILVER[\"FP_y\"]) \n",
    "    )\n",
    "paradigmeSILVER[(~filtreNouveauxDerivesSILVER)&(filtreFsLexSILVER)][[\"lexeme\",\"FS_x\",\"FP_x\",\"FS_y\",\"FP_y\"]]\n",
    "paradigmeSILVER[(~filtreNouveauxDerivesSILVER)&(filtreFpLexSILVER)][[\"lexeme\",\"FS_x\",\"FP_x\",\"FS_y\",\"FP_y\"]]\n",
    "paradigmeSILVER[filtreNouveauxDerivesSILVER][[\"lexeme\",\"FS_y\",\"FP_y\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paradigmeSILVER[filtreNouveauxDerivesSILVER][[\"lexeme\",\"FS_y\",\"FP_y\"]].to_csv(path_or_buf=\"2015-Data/\"+sampleFile.replace(\".csv\",\"-NouveauxDerives.csv\"),encoding=\"utf8\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paradigmeSILVER[[\"lexeme\",\"FS_x\",\"FP_x\",\"FS_y\",\"FP_y\"]].to_csv(path_or_buf=\"2015-Data/\"+sampleFile.replace(\".csv\",\"-TousDerives.csv\"),encoding=\"utf8\",sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"2015-Data/\"+sampleFile.replace(\".csv\",\"-TousDerives.pkl\"), 'wb') as output:\n",
    "   pickle.dump(paradigmeSILVER, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "paradigmeSILVER.to_csv(path_or_buf=\"2015-Data/\"+sampleFile.replace(\".csv\",\"-Derive.csv\"),encoding=\"utf8\",sep=\";\")\n",
    "#GOLD.to_csv(path_or_buf=\"2015-Data/\"+analysisPrefix+'-Gold.csv',encoding=\"utf8\",sep=\";\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pd.set_option('display.max_rows', len(paradigmeSILVER))\n",
    "paradigmeSILVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "paradigmeSILVER[(paradigmeSILVER[\"FS\"]!=\"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "derivesFS=set(paradigmesCLIQUES[~(paradigmesCLIQUES[\"FS\"].isnull())][\"FS\"].unique())\n",
    "derivesFP=set(paradigmesCLIQUES[~(paradigmesCLIQUES[\"FP\"].isnull())][\"FP\"].unique())\n",
    "derivesFSFP=derivesFS|derivesFP\n",
    "for n,derive in enumerate(sorted(derivesFSFP)):\n",
    "    print (n,derive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paradigmesCLIQUES[~(paradigmesCLIQUES[\"FP\"].isnull())]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
